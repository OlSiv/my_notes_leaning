
https://stepik.org/lesson/1366352/step/1?unit=1382350

купил 20.04.2025 за 900 р. 



***********************************************

Задать вопросы перед прохождением можно ЗДЕСЬ - телеграм канал слушателей курсов автора (и сам автор там же) - 
https://t.me/+767-K2USQ1szYjBi

О курсе: Полный цикл данных от сырья до инсайтов

Этот курс — ваш билет в мир профессиональной работы с данными. Мы пройдем весь путь, который проходит каждая единица данных в современной компании:

--- Развернем полноценную BI-инфраструктуру с нуля:

Установим и настроим все необходимые инструменты

Научимся их администрировать на базовом уровне

Поймем, как устроена data-экосистема в компаниях

--- Реализуем end-to-end проект:

Развернем инфраструктуру (Docker, ClickHouse, Airflow)

Настроим автоматический сбор данных

Построим ETL-пайплайн

Создадим интерактивные дашборды в Superset/DataLens

--- Поймем логику работы с данными:

Как устроены процессы в реальных компаниях

Какие решения принимают специалисты

Как избегать типичных ошибок

--- Инструменты (изучаем ровно то, что нужно для работы):

Docker — для развертывания

ClickHouse — для хранения и обработки

Airflow — для оркестрации

Superset/DataLens — для визуализации

--- Почему этот курс эффективен?

Никакой лишней теории — только практика

Оптимальный объем (5.5 часов) для быстрого старта

Можно освоить за 2-3 дня

Дает достаточные навыки для позиций:

    - Junior Data Engineer

    - Junior BI Developer

Итог: Вы не просто узнаете технологии — вы поймете, как они работают вместе и сможете создавать работающие data-решения.

Это не просто обучение — это ваш быстрый старт в data-профессии!

В бесплатной части оставлены инструкции по установке необходимой инфраструктуры с помощью Docker - перед покупкой пройдите ее, чтобы понять, достаточно ли ресурсов вашего ПК. Также прочитайте необходимые начальные навыки - требуется знание Python/SQL на базовом уровне.

--- Что предстоит делать

Изучать текстовые/видеоматериалы

Выполнять интересные, приближенные к реальным задачи на локально развернутой инфраструктуре

Читать полезные статьи, которые будут приложены к курсу

--- Как устроен курс

Лекция в формате видеозаписи + текстовые инструкции, если необходимо

Выполнение тестовых заданий по лекции

Разработка, приближенная к реальной

--- Какие темы затронем

все, что связано с данными, кроме ML

--- Для кого этот курс

Данный курс предназначен для всех, кто так или иначе работает / планирует работать с данными.

--- Начальные требования - Для успешного прохождения курса необходимо:

Знание Docker, либо быть готовым повторить всё за преподавателем

Знания SQL обязательно (select, where, group by, having, order by, join и т.д.). Вы умеете писать SQL-запросы. Вы понимаете, что такое база данных, и что различных систем управления базой данных (СУБД) очень много (Postgres, ClickHouse, MySQL и т.д.). Вы готовы работать с SQL, так как в курсе очень много будет связано именно с БД.

Знания Python обязательно - вы знакомы с типами данных, функциями. Знаете про библиотеки - панды ваши друзья. Желательно знать какую-либо IDE (PyCharm, VSCode), но не обязательно.

--- Рекомендуемые системные требования Docker:

Процессор: Intel Core i5 8400 Coffee Lake или лучше (в реальности достаточно и i3)

Память: 8 ГБ оперативной памяти (в реальности достаточно и 4-5ГБ)

Хранение: 20 ГБ SSD (в реальности не менее 10ГБ)

Для того, что вы могли понять, достаточно ли ресурсов вашего компьютера для прохождения курса, уроки с установкой Docker, DataLens, Superset, ClickHouse и Airflow будут доступны бесплатно.



***********************************************

1.1 Знакомство с BI/инжинирингом данных, структурой курса

Интересующие вас вопросы можно задать перед прохождением курса в нашем комьюнити - ссылка -
https://t.me/+767-K2USQ1szYjBi

 Если кратко - в курсе будет все, от установки инструментов в Docker до дашборда. Обязательно нужны знания SQL, Python. Финальный проект будет выглядеть так:
- парсим данные с источника в хранилище (ETL)
- отрисовываем дашборд

Абсолютно все (кроме источника данных, он, конечно же, внешний) будет сделано на наших машинах, поэтому и изучим все - от установки и администрирования до конечного дашборда.



Давайте кратко разберемся, что такое бизнес-аналитика и инжиниринг данных, и почему одно без другого не существует. Начнем с основ бизнес-аналитики.

В цифровом мире, где данные - "новая нефть", подавляющее большинство бизнес-решений принимается на основе данных. 

Бизнес-аналитика (BI) — это работа с данными, направленная на получение конкретных метрик, позволяющих получить информацию о состоянии бизнеса. Приведем конкретный пример процесса BI на примере электронной коммерции (e-com):
- получение данных о бизнесе - например, историю заказов (запомним этот момент)
- изучение данных - ищем зависимости, закономерности, логику
- визуализация данных - строим графики, таблички (если нужно). Делаем из этого дашборд (отчёт)

Готовыми отчётами пользуются различные структуры компании, в зависимости от информации, содержащейся в отчёте. Один и тот же отчёт может быть полезен генеральному директору, менеджеру по продажам, маркетологу и т.д.

Посмотрим на пример отчёта, составленного в DataLens (взято с официального сайта) -
https://datalens.tech/

Это касательно бизнес-аналитики. Теперь об инжиниринге данных.

Дата инжиниринг (Data Engineering) - это процесс сбора, обработки, хранения и анализа больших объёмов данных с целью предоставления подходящей информации для аналитиков данных, машинного обучения и других областей, связанных с данными.

В нашем примере был пункт "получение данных о бизнесе" - так вот, люди, занимающиеся аналитикой, не занимаются непосредственно добычей данных. Этим занимаются, как раз, дата-инженеры. Их задача - предоставить аналитикам таблицу с историей заказов. А задача аналитиков - запросить у дата-инженеров такую таблицу. Одно без другого не существует.

сейчас нахожусь в поиске работы, и на должности "Аналитик / Разработчик BI" у меня спрашивают знание условного Airflow, GIT, умение создавать хранилище данных,  SQL (триггеры и тд). Про DAX, Power Query, связи, SQL для ad-hoc, дизайн (UX/UI) вопросов минимум, зато из смежных профессий вопросов куча. Многие лиды BI направлений не знают зачем использовать Power Point или Figma с работой в Power BI) зато требуют от кандидата знание программ для ETL процессов. В итоге люди заходят на курс по BI и лишний раз убеждаются, что BI - это делать все шаги по работе с данными, что, как по мне, неверно

просто это более современный стек - Airflow + БД (желательно ClickHouse) + визуализация (Datalens/Superset). Airflow + ClickHouse - варите витрину, кидаете в условный слой datamart, далее пишете SQL-запрос к витрине и кидаете его в Datalens/Superset - отчет готов. Дальше в курсе все это будет. DAX, PowerBI и их окружение - это все-таки не про большие данные и современные ETL-процессы. Знание этих инструментов ничем не поможет, если стек технологий Airflow + БД + Datalens/Superset или ему подобный



--- В данном курсе мы научимся всему:

парсить источники данных

преобразовывать данные

загружать преобразованные данные в хранилище (ClickHouse)

изучим возможности ClickHouse (частично)

собственно, создадим хранилище (DWH) по методологии Ральфа Кимбалла

прокачаем хранилище (сделаем его многослойным, разберемся, что это и зачем)

изучим администрирование (частично) DWH

изучим Yandex DataLens

изучим Apache Superset

сравним их, разберем отличия

изучим, как Yandex DataLens и Apache Superset взаимодействуют с ClickHouse (да и в принципе с любой БД, с которой они работают)

Изучим Apache Airflow



Полезные ссылки:

Курс по Docker
https://stepik.org/course/123300/syllabus
- бесплатно - записался

Курс по SQL
https://stepik.org/course/63054/syllabus
- бесплатно - записался

Курс по оптимизации SQL запросов (от автора текущего курса)
https://stepik.org/course/215412/promo
- бесплатно - записался



Курс будет структурирован по принципу: один урок - изучение одной темы с конкретной конечной целью. Материал будет даваться сразу в двух форматах: сначала видеоматериал (лекция), затем краткая выжимка по ней в текстовом виде (если это необходимо). По результатам лекции (не обязательно после каждой) будет задание (или несколько заданий) в виде теста. 

Преподаватель (он же автор) будет помогать вам в случае трудностей. Все возникающие вопросы пишите в комментариях к уроку или в комьюнити в тг, отвечу как только освобожусь, так как являюсь действующим разработчиком.

Напомню, что основная задача курса - дать учащимся необходимые знания, которые повсеместно нужны на работе в любой крупной (а уже и в маленькой) IT-компании. Именно поэтому курс сделан так, чтобы учащиеся были независимыми и умели пользоваться Docker. На практике - без знания Docker в IT будет очень трудно. К тому же, Docker не нужно знать полностью, в большинстве случаев достаточно уметь поднимать различные инструменты в нём - DataLens, ClickHouse, Postgres и т.д. И это абсолютно несложно, например Postgres поднимается всего лишь одной командой (которую нужно просто скопировать, внеся минимальные изменения, с крупнейшего хранилища готовых образов - 
Docker Hub Container Image Library | App Containerization) -
https://hub.docker.com/
--
docker run --name my_pg -p 5432:5432 -e POSTGRES_PASSWORD=my_password -d postgres
----



***********************************************

2.1 Знакомство с Docker

В данном модуле будет объяснение технологии Docker. Постарался сделать максимально кратко. Но, если вы уже знакомы с технологией, то можете без просмотра видео перейти к установке ClickHouse и DataLens. Инструкции по установке есть в текстовом варианте в соответствующем по названию уроке.



устанавливает приложение и его окружение в виде одной сущьности 

докер-имейдж - это образ, как .exe или установочный файл 

докер-контейнер - это уже как установленный exe-файл 

докер-десктоп - это приложение 

докер-компоуз - запускает сразу несколько контейнеров 



Docker — это платформа, которая позволяет упаковать в контейнер приложение со всем необходимым для его работы (окружение). Окружением может быть что угодно - от языка программирования до переменных среды. Сразу к примеру для понимания.

Вы написали мини-сайт на JavaScript. Затем вы хотите поделится этим прекрасным событием со своим другом и идёте к нему в гости, предварительно скопировав весь написанный код на usb-носитель. Вы приходите, загружаете файлы с написанным кодом на компьютер друга, пытаетесь поднять сайт - но ничего не работает. А причина очень проста - на компьютере вашего друга не установлен JavaScript.

Установив JavaScript вы решите проблему и запустите сайт. Так вот JavaScript - и есть окружение. 

- Docker image (образ) — это неизменяемый образ, из которого разворачивается контейнер. Собственно, это один большой по размеру файл (зачастую не более 2Гб), в котором содержится всё необходимое для работы приложения. В нашем случае - код сайта и JavaScript. Более простая аналогия - это установочный файл.   

- Docker container (контейнер) — это развёрнутое и запущенное приложение. Контейнеры создаются строго из образа. Более простая аналогия - контейнер, это все файлы, которые появляются после установки приложения (допустим Excel), закинутые в одну папку. Эта папка и есть контейнер.   

- Docker Desktop — непосредственно к Docker не относится, можно работать и без него. Это приложение, которое позволяет взаимодействовать с сущностями Docker (GUI - Graphical user interface или графический интерфейс пользователя). Крайне рекомендую использовать его, чтобы минимизировать количество ошибок и операций в командной строке.

Более подробно рассматривать Docker в рамках данного не будем. Этого достаточно, чтобы начать работать. Переходим к установке Docker.



DataLens - нельзя установить на операционную систему, только через Docker 

Как начать работать с DataLens - 
https://datalens.tech/docs/ru/quickstart.html



Теперь, когда мы кратко познакомились с Docker, понимаем, что нам необходимо:
- установить Docker и Docker Desktop
- взять готовый образ DataLens
- создать контейнер из образа
- запустить контейнер

Разработчики современных приложений понимают, что Docker - это устоявшийся стандарт. А значит, для удобства использования приложения нужно предоставить пользователям уже готовый образ. Теперь приступим к установке.



***********************************************

2.2 Установка Docker

=






























