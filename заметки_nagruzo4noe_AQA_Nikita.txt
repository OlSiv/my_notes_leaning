
*****************************************************************

Прямая ссылка на курс:
https://stepik.org/242935

https://stepik.org/course/242935/promo

https://stepik.org/course/242935/syllabus

В курс входят -
74 урока
50 часов 9 минут видео
640 тестов
44 интерактивные задачи



stepik - 16-07-2025
~ 6_250 р.

на компе с монитором дома каталог для програм - 
C:\my_\my_p\

+

заметки по курсу по Docker от karpov.curses - 
строка в этом файле - примерно 2500



Не задавайте вопросы, которые можно легко найти в сети. Если что-то непонятно, постарайтесь сначала найти ответ самостоятельно. Если же неясно, с чего начать, обратитесь ко мне через урок Поддержка преподавателя и вопросы -
https://stepik.org/lesson/1677142/step/1



Если у вас возникают вопросы в процессе прохождения курса и вы не можете найти на них ответы, вы можете задать вопрос преподавателю в Telegram по адресу -
@sound_right
Преподаватель постарается ответить вам в течение трех рабочих дней



папка для GitHub на диске С -
load_testing_from_my_work



******************************************

1.1 Знакомимся

Нагрузочное тестирование — глубокая, системная дисциплина, которая требует понимания:
- ресурсов системы (CPU, RAM, IO),
- сетевых протоколов (HTTP/gRPC),
- устройства БД,
- очередей и кешей,
- архитектуры приложений (монолит vs микросервисы),
- работы со стендом, сидинга данных и CI/CD.

Это не просто «открыть браузер и нажать кнопку», как в UI-автотестах. Здесь каждый тест — это инженерная гипотеза, которая проверяет прочность всей системы под реальной нагрузкой.

Что будем изучать в курсе?
Прежде всего — у нас будет отдельный тестовый стенд, и это не просто CRUD API и база данных под ним. Вы будете работать с настоящей учебной банковской системой, построенной по принципам микросервисной архитектуры. В ней есть всё, что используется в современных production-системах:
- Kafka — для асинхронных очередей,
- S3-совместимое файловое хранилище (MinIO) — для работы с документами и вложениями,
- Redis — для кеширования,
- PostgreSQL — как основная реляционная БД,
- Поддержка двух протоколов: HTTP и gRPC.

Это максимально приближённый к боевым условиям стенд, а не «игрушка с /ping» в блокноте. Мы будем не просто «посылать запросы», а тестировать поведение сложной системы под реальной нагрузкой.

С первых шагов вы будете работать руками. Первые модули курса посвящены настройке окружения и изучению инфраструктуры, чтобы вы понимали:
- как устроен стенд,
- как взаимодействуют сервисы,
- какие метрики важны,
- какие системные ресурсы участвуют в нагрузке.

Вы освоите и будете использовать вживую:
- docker, docker-compose,
- PostgreSQL и утилиту pgAdmin,
- Kafka UI для работы с очередями,
- MinIO как облачное хранилище,
- Grafana для метрик и анализа,
- Postman для ручного взаимодействия с API,
и многое другое.

В этом курсе вы будете работать сразу с двумя протоколами — HTTP и gRPC. Когда мы пишем функциональные тесты, разница между ними может быть не столь заметна — формат запроса разный, но бизнес-логика одна и та же. А вот в нагрузочном тестировании отличия становятся принципиальными.
- gRPC работает поверх HTTP/2, использует бинарную сериализацию (protobuf) и куда эффективнее в плане скорости и сетевых затрат.
- HTTP проще, но медленнее — особенно при большом количестве пользователей и высокой конкуренции за ресурсы.

Моки: создаём собственные сервисы для нагрузки
В курсе мы не просто «попробуем», а создадим собственный мок-сервис с нуля — и сразу в двух вариантах: для HTTP и для gRPC. Зачем это нужно?
- Во-первых, моки — это важнейший инструмент в нагрузочном тестировании, особенно при проверке систем, где реальные зависимости либо нестабильны, либо ресурсоёмки.
- Во-вторых, вы научитесь отделять нагрузку на конкретный компонент от нагрузки на всю систему.
- В-третьих, эти навыки полезны не только в нагрузке, но и в интеграционном, изоляционном и контрактном тестировании.

Мы реализуем мок-сервис с использованием FastAPI и grpcio, и это даст вам в руки ещё один универсальный инструмент, который пригодится как QA-инженеру, так и performance-инженеру.

Нагрузочное тестирование без анализа метрик — это просто цифры. Поэтому мы научимся работать с Grafana — одним из самых мощных инструментов для визуализации и анализа системных метрик. Вы не просто будете «смотреть графики», а разбираться в происходящем под капотом:
- Какой сервис даёт пиковую нагрузку?
- Куда уходит CPU?
- Что расходует память?
- Где реальное узкое место?
- Почему RPS начал падать?

Мы самостоятельно настроим Grafana-дэшборд, чтобы вы могли анализировать нагрузку не вслепую, а как инженер-исследователь, принимающий решения на основе объективных данных.

Нагрузочное тестирование начинается не с кода и не с графика. Оно начинается с понимания бизнес-контекста. Мы научимся:
- не просто «влепить 1000 виртуальных пользователей»,
- а проанализировать реальные сценарии поведения пользователей,
- рассчитать нагрузочные пики, типичные RPS, время активной сессии,
- построить реалистичный профиль нагрузки, отражающий реальную работу системы в проде.

Locust — наш основной инструмент нагрузочного тестирования, и мы разберём его на атомы. Вы научитесь:
- запускать базовые сценарии,
- использовать TaskSet, SequentialTaskSet, веса, тайминги,
- интегрировать кастомные HTTP и gRPC клиенты,
собирать единую архитектуру фреймворка, подходящую под разные типы API и сценариев.

Итогом станет универсальный нагрузочный фреймворк, который вы сможете:
- развернуть с нуля в любом проекте,
- адаптировать под любую систему,
- аргументировать его архитектуру перед командой или на собеседовании.

Сидинг — это то, о чём не говорят в большинстве курсов. И очень зря. Система не живёт в вакууме. На проде она работает с миллионами уже существующих пользователей, аккаунтов, историй операций. А значит — и в нагрузочных тестах база должна быть реалистично наполнена. В курсе вы научитесь:
- писать сидинг-сценарии,
- подготавливать начальные данные: пользователей, счета, документы,
- сохранять эти данные в JSON-файлы и использовать повторно,
- восстанавливать состояние базы перед каждым прогоном.

Это один из самых критически важных шагов, потому что нагрузка на пустую систему даёт ложные результаты.

В курсе мы активно будем использовать настоящие инструменты, с которыми работают инженеры в реальных проектах:
- Git — для версионирования кода,
- Docker и Docker Compose — для поднятия микросервисного стенда,
- Postman — для ручной работы с HTTP и gRPC API,
- MinIO — как S3-совместимое файловое хранилище,
- PostgreSQL + pgAdmin — для работы с базой,
- Kafka UI — для мониторинга и отправки сообщений в очереди.

Вы не просто «увидите их», вы будете использовать их каждый день: запускать контейнеры, подключаться к брокеру, писать запросы, читать логи. Например, вы научитесь:
- отправлять gRPC-запросы через Postman,
- смотреть состояние Kafka-топиков,
- визуализировать структуру БД через pgAdmin.

Интеграция с CI/CD — автоматизация нагрузки

Нагрузочные тесты не должны жить «в локалке». Я покажу, как:
- интегрировать нагрузочное тестирование в CI/CD-процессы,
- настроить запуск тестов по кнопке,
- автоматически поднимать тестовый стенд с помощью Docker и Docker Compose.

Цель — добиться того, чтобы любой член команды мог:
- запустить нужный сценарий,
- получить метрики,
- увидеть результат в Grafana или отчёте.

Вы научитесь создавать гибкие, универсальные API-клиенты как для HTTP, так и для gRPC. Причём речь не о «заглушках для одного теста», а о полноценных клиентах, которые можно использовать в разных целях:
- в нагрузочном тестировании (как часть сценариев Locust),
- в сидинге — для генерации данных,
- в автоматизированных API-тестах, если вы захотите использовать тот же клиент за пределами курса.

Клиенты будут построены по принципу модульности и переиспользуемости: их легко масштабировать, адаптировать под другие проекты или команды. Это навык, который пригодится вам вне зависимости от вашей роли: QA, перформанс-инженер, automation, SDET — все работают с API, и грамотный API-клиент — это основа продуктивной работы.

В курсе мы также разберёмся в терминологии и видах тестирования производительности, потому что тут важно понимать нюансы. Часто можно услышать: «нагрузим систему до упора — будет нагрузочное тестирование». Но на самом деле — это упрощение, и часто приводит к неправильным выводам. Мы научимся отличать:
- нагрузочное тестирование (load testing) — чтобы понять, выдерживает ли система ожидаемую нагрузку;
- стресс-тестирование — когда мы проверяем, на сколько система способна выйти за пределы нормы;
- тестирование отказоустойчивости — когда эмулируются сбои, ошибки сервисов, падение компонентов;
- резилианс-тестирование — способность восстанавливаться после сбоев без потери данных и целостности;



******************************************

1.2 Советы по изучению материала

урок состоит из - 
- видео 
- теория 
- тесты 
- практическое задание 

смотреть сначала текст (+ схемы, ссылки и т.п.) а потом видео 

делать самому всё что автор делает в видео 

смотреть все ссылки и рекомендации, которые дает автор 



Изучение Python -

Этот курс предполагает базовые знания Python. Если вы не уверены в следующих темах, рекомендую сначала их повторить:

Переменные -
https://www.w3schools.com/python/python_variables.asp

Типы данных -
https://www.w3schools.com/python/python_datatypes.asp

Функции -
https://www.w3schools.com/python/python_functions.asp

Логические операторы -
https://www.w3schools.com/python/python_conditions.asp

Циклы -
https://www.w3schools.com/python/python_for_loops.asp

Lambda-функции -
https://www.w3schools.com/python/python_lambda.asp

Классы -
https://www.w3schools.com/python/python_classes.asp

Знакомство с пакетным менеджером pip -
https://www.w3schools.com/python/python_pip.asp

Работа со строками и форматирование строк -
https://www.w3schools.com/python/python_string_formatting.asp



Для закрепления основ Python, рекомендую следующие бесплатные курсы, которые можно пройти за одну-две недели:

Бесплатный курс по Python от W3Schools -
https://www.w3schools.com/python/default.asp

Бесплатный курс по Python от Metanit -
https://metanit.com/python/tutorial/

Эти ресурсы помогут вам уверенно работать с нагрузочным тестами.



******************************************

1.3 Инструкции по отправке заданий на проверку

Инструкция по отправке на проверку -
1 - Выполните задание и опубликуйте результат на GitHub.

- Решение задания должно быть зафиксировано в одном коммите, если это возможно.
- Название коммита должно соответствовать следующему шаблону: {название урока}. {название шага}. Например, для задания ниже коммит должен быть назван так: 
"Введение в HTTPX. Практическое задание: работа с HTTPX"

- Если задание не получилось выполнить в одном коммите, это не критично. В этом случае просто добавьте еще один коммит с тем же названием, чтобы сохранить логическую структуру.

2 - Вставьте ссылку на GitHub репозиторий в поле ответа:
https://github.com/Nikita-Filonov/performance-tests

3 - Вы получите баллы за задание после его рецензирования

Важно! Если сейчас вам непонятны термины "репозиторий", "коммит" и структура GitHub, не беспокойтесь. Вы сможете пропустить данный шаг и вернуться к нему позже, после изучения основ работы с Git в уроке Начало работы с Git -
https://stepik.org/lesson/1799578/step/1?unit=1825311

- Обратите внимание, что задание не будет принято к оценке, если оно не соответствует указанному формату
- Отправить решение на рецензию можно только один раз!



Текстовый ответ -

Инструкция по отправке на проверку

1 - Составьте текстовый ответ:
- Напишите подробный ответ, следуя требованиям задания.
- Убедитесь, что ваш ответ содержит все необходимые шаги и пояснения.

2 - Вставьте решение в поле ответа

3 - Вы получите баллы за задание после его рецензирования



проверять ответы на задания, если ошибся - создать коммит с таким же названием 



******************************************

1.4 Поддержка от преподавателя и вопросы

Задавать вопросы рекомендуется в следующих ситуациях:
- Если при выполнении практического задания возникли трудности с пониманием условий и вы не уверены, как его выполнить.
- Если при изучении материала курса вы столкнулись с проблемой, которую не удается решить самостоятельно.
- Если вам непонятен процесс отправки домашнего задания на проверку.
- Если вы наткнулись на тему, в которой хотите разобраться глубже, и хотите получить дополнительные материалы для изучения.
- В любых других ситуациях, когда вам не удалось самостоятельно найти ответ, и вы исчерпали доступные ресурсы.



******************************************

2.1 Виды тестирования производительности

Виды тестирования производительности (Performance Testing)
Ссылки:

Performance Testing -
https://glossary.istqb.org/en_US/term/performance-testing
- Тип теста для определения эффективности работы компонента или системы.


Load Testing (нагрузочное тестирование) -
https://glossary.istqb.org/en_US/term/load-testing
- Тип тестирования производительности, проводимый для оценки поведения компонента или системы при различных нагрузках, обычно в интервале между ожидаемыми условиями низкой, типичной и пиковой нагрузки.
-
- что это - стандартная нагрузка, увеличенная в 2-3-5-6 раз 
- цель - нагрузить систему и собрать определенные метрики 
- когда проводится - после добавления новой функциональности или изменения старой (рефакторинга), либо перед каждым релизом и сравнивать метрики с предидущими релизами  


Stress Testing (стресс-тестирование) -
https://glossary.istqb.org/en_US/term/stress-testing
- Тип тестирования производительности, проводимый для оценки системы или компонента на пределе ожидаемых или указанных рабочих нагрузок или за их пределами, или при ограниченной доступности ресурсов, таких как доступ к памяти или серверам.
-
- что это - каждый раз повышаем нагрузку, пока система не откажет - 100-200-300-400-......
- цель - узнать максимальную нагрузку и увидеть какой компонент первым выходит из строя и как система будет восстанавливаться после сбоя, и вообще восстановится ли она 
- когда проводится - никогда не проводить на продакшине, только на тестовых стендах, проводится например при черной пятницей, акциями, когда ожидается большая пиковая нагрузка и нужно понять предел системы 


Soak Testing/Endurance Testing (тестирование выносливости) -
https://glossary.istqb.org/en_US/term/endurance-testing
- Тестирование для определения стабильности системы под значительной нагрузкой в течение значительного периода времени в контексте эксплуатации системы.
-
- что это - подаём ту же нагрузку что и обычно, но в течении нескольких часов или дней 
- цель - выявление утечек ресурсов либо накопительных эффектов - например есть система где кэшируются данные, и мы несколько часов или суток держим её под стандартной постоянной нагрузкой, и смотрим как ведут себя ресурсы, например каждый час по немногу возрастает нагрузка на память, то есть кэш не очищается и остается в памяти, и т.п. При обычном нагрузочном тестировании это может быть незаметно, а при долгом тестировании уже заметно 
- когда проводится - в системах которые долгое время работают под нагрузкой (банковские системы, телеком, чарты, биржи)


Spike Testing (тестирование всплесков) -
https://glossary.istqb.org/en_US/term/spike-testing
- Тестирование для определения способности системы восстанавливаться после внезапных скачков пиковых нагрузок и возвращаться в устойчивое состояние.
-
- что это - здесь нагрузка подаётся резким всплеском, например со 100 до 3000 
- цель - посмотреть как система переживает пик и как восстанавливается после этого, будет ли использоваться кэширование, будут ли увеличиваться ресурсы, масштабироваться система, либо вернутся ошибки, как при DDOS-атаке или когда клиент сразу отправляет очень много запросов на сервер 


Scalability Testing (тестирование масштабируемости) -
https://glossary.istqb.org/en_US/term/scalability-testing
- Тестирование для определения масштабируемости программного продукта.
-
- что это - подаем нагрузку и потихоньку её увеличиваем (тестируем вертикальное масштабирование(количество пользователей растет и соответственно растут потребляемые ресурсы) и горизонтальное масштабирование(растет количество инстансов, до 20-30 штук может расти (копий системы, контейнеров)))
- цель - снять метрики и посмотреть как система масштабируется (будет ли вообще масштабироваться) и что для нас выгоднее - рост ресурсов (вертикальное) или рост количества инстансов системы (горизонтальное) 
- когда проводится - когда поменяли инфраструктуру, настройки или переехали в облачное хранилище 


Failover / Resilience Testing (тестирование отказоустойчивости) -
-
- что это - подаём нагрузку, которая постоянно увеличивается, и смотрим как ведут себя компоненты системы на предмет отказоустойчивости, например есть сервис, который должен быть всегда доступен, сервер должен сам определить когда начинает давать сбой и включить механизм Circuit Breaker, при котором наша система начинает чуть медленее отвечать либо тротлить, то есть этот механизм защищает сервер от отказа (падения) при непомерной нагрузке  

Circuit Breaker распределяет - эти запросы в очередь, эти я замедляю, а эти я отклоняю 

Иногда мы сами можем отключить какой-то сервис, или иммитировать отказ БД, кэширования и посмотреть как себя ведет система, насколько наш сервис отказоустойчивый 


Chaos Testing (хаос-тестирование) -
-
- что это - подаем нагрузку на стенд и начинаем отключать или замедлять сервисы, уменьшать их ресурсы, не позволять им масштабироваться и т.д. 
- цель - Смотрим насколько система устойчивая и надежная. 


Circuit Breaker Design Pattern -
https://en.wikipedia.org/wiki/Circuit_breaker_design_pattern

Тестирование производительности (Performance Testing) включает в себя несколько подвидов, каждый из которых фокусируется на определённой характеристике системы: скорости отклика, устойчивости, масштабируемости и способности к восстановлению. Далее мы рассмотрим ключевые виды такого тестирования.



И ещё раз про то же самое -



1. Load Testing (нагрузочное тестирование)

Цель:
- Проверка, как система работает под нормальной и увеличенной ожидаемой нагрузкой в течение продолжительного времени.

Особенности:
- Эмулируется реалистичная пользовательская активность (например, 100–500 одновременных пользователей).
- Проверяются: производительность, стабильность, скорость отклика, throughput.
- Используется на этапе подготовки к реальному продакшену.

Типичные метрики:
- Время отклика (Response Time)
- Пропускная способность (Requests per Second, Throughput)
- Утилизация CPU / памяти / сети
- Количество ошибок

Когда использовать:
- Перед релизом или масштабированием
- Для выявления узких мест при ожидаемой нагрузке



2. Stress Testing (стресс-тестирование)

Цель:
Определить максимальную нагрузку, которую система может выдержать до деградации или сбоя. Проверяется поведение за пределами нормальных условий.

Особенности:
- Нагрузка постепенно или резко увеличивается выше проектной нормы.
- Цель — увидеть, когда и как "ломается" система, и как она восстанавливается после сбоя.
- Тестируется устойчивость и деградация, а не стабильная работа.

Нюансы:
- Может привести к серьёзным сбоям, поэтому не проводится в продакшене.
- Важно отслеживать, какие компоненты первыми выходят из строя.

Когда использовать:
- При оценке пределов масштабируемости
- При подготовке к резким пиковым нагрузкам (распродажи, маркетинговые кампании)



3. Soak Testing / Endurance Testing (тестирование выносливости)

Цель:
Проверить стабильность системы при продолжительной нагрузке (несколько часов или даже дней) с целью выявления утечек ресурсов и накопительных эффектов.

Особенности:
- Нагрузка может быть на уровне Load Testing, но важно время: часы, сутки.
- Ищутся памятные утечки, утечка соединений, ухудшение времени отклика со временем.
- Выявляются проблемы, которые не видны при коротком тестировании.

Когда использовать:
- В критических системах с длительной работой (банкинг, телеком)
- После обновлений, которые могут повлиять на сборку мусора, кеширование и пр.



4. Spike Testing (тестирование всплесков)

Цель:
Оценить реакцию системы на резкий, кратковременный всплеск нагрузки.

Особенности:
- В отличие от Stress Testing, нагрузка скачет внезапно и резко, а не нарастает.
- Имитируется ситуация, например, когда внезапно заходит 10 000 пользователей за 1 секунду.
- Проверяется, как система "переживает" пик и восстанавливается.

Когда использовать:
- Для оценки реакции на DDoS, флешмобы, баги в клиентском ПО
- Для тестирования автоскейлинга и кэширования



5. Scalability Testing (тестирование масштабируемости)

Цель:
Проверить, насколько хорошо система масштабируется при увеличении:
- числа пользователей,
- объёма данных,
- количества узлов и ресурсов (CPU, памяти и т.д.)

Особенности:
- Может проводиться как в вертикальном (увеличение ресурсов), так и в горизонтальном масштабе (добавление инстансов).
- Анализируется эффективность масштабирования: линейное, сублинейное или деградирующее.

Когда использовать:
- При выборе между горизонтальным и вертикальным масштабированием
- При тестировании облачных или распределённых архитектур



6. Failover / Resilience Testing (тестирование отказоустойчивости)

Цель:
Оценить, как система реагирует на сбой компонентов (сервисов, БД, сети, дисков), и способна ли она восстановиться.

Особенности:
- Имитируются реальные сбои: отключение узла, отказ БД, network partition, и т.д.
- Часто сочетается с Chaos Testing.
- Проверяются механизмы репликации, автоматического переключения, circuit breaker'ы и пр.

Когда использовать:
- При построении отказоустойчивых систем
- Для валидации резервирования и механизмов восстановления



Circuit Breaker

Circuit Breaker (в контексте распределённых систем и отказоустойчивости) — это паттерн устойчивости, который предотвращает повторяющиеся попытки обращения к зависимому (часто внешнему) компоненту, если он уже не отвечает или работает с ошибками. Другими словами это программный механизм, который временно блокирует вызовы к ресурсу (например, микросервису или базе данных), если обнаружено, что он находится в ошибочном или нестабильном состоянии. Это помогает избежать избыточной нагрузки на зависимость и позволяет системе восстанавливаться более эффективно.

Circuit Breaker имеет три состояния:

1 - Closed (закрыт):
- Всё работает нормально.
- Запросы проходят к целевому компоненту.
- При ошибках считает количество/частоту неудач.

2 - Open (открыт):
- Когда число неудач превышает порог — "перегорает".
- Запросы не отправляются, а сразу получают ошибку.
- Даёт целевому компоненту "время на восстановление".

3 - Half-Open (полуоткрыт):
- Через некоторое время позволяет отправить ограниченное количество пробных запросов.
- Если они успешны — возвращается в Closed.
- Если снова ошибка — возвращается в Open.

Зачем нужен:
- Защищает систему от каскадных сбоев.
- Улучшает восстанавливаемость и устойчивость.
- Избегает перегрузки зависимого сервиса в момент, когда он уже не работает.

Примеры применения:
- Между микросервисами, где один сервис зависит от другого.
- При работе с нестабильной внешней API.
- В связке с retry и fallback логикой.



7. Chaos Testing (хаос-тестирование)

Цель:
- Преднамеренно вносить хаос и неопределённость в систему, чтобы проверить её устойчивость и надёжность в условиях неожиданных сбоев.

Особенности:
- Выключение случайных сервисов, сетевых подключений, подмена данных.
- Нестабильность создаётся преднамеренно, часто в продакшене.
- Используется инструментами типа Chaos Monkey, Gremlin.

Нюансы:
- Требует зрелой инфраструктуры, мониторинга и автоматического восстановления.
- Очень мощный инструмент, но опасен без должного контроля.



Сводная таблица сравнения:

Вид теста         - Load Testing
Цель              - Проверить стабильность
Нагрузка          - В норме
Продолжительность - Средняя	
Пример метрик     - Время отклика, ошибки

Вид теста         - Stress Testing
Цель              - Найти пределы	
Нагрузка          - Сверх нормы
Продолжительность - Кратковременная
Пример метрик     - Точка отказа, деградация

Вид теста         - Soak Testing
Цель              - Найти утечки, дрейф
Нагрузка          - В норме	
Продолжительность - Долгая
Пример метрик     - Утечки памяти, рост latency

Вид теста         - Spike Testing	
Цель              - Проверить на всплески	
Нагрузка          - Резкие пики
Продолжительность - Кратковременная
Пример метрик     - Пиковое поведение, отклик

Вид теста         - Scalability Testing	
Цель              - Проверить масштабируемость	
Нагрузка          - Растущая
Продолжительность - Любая	
Пример метрик     - Throughput на ресурс

Вид теста         - Resilience Testing
Цель              - Проверить восстановление
Нагрузка          - Любая	
Продолжительность - По сценарию
Пример метрик     - Восстановление, ошибки

Вид теста         - Chaos Testing
Цель              - Проверить устойчивость к сбоям
Нагрузка          - Нестабильная
Продолжительность - Любая
Пример метрик     - Выживаемость, самовосстановление


Мы в рамках этого курса будем работать с Load Testing (нагрузочным тестированием) - время ответа, количество запросов в секунду, процессор, память, диск, сеть - то есть будем делать снятие всяких метрик 

Также в этом уроке мы разобрали все виды тестирования производительности 



******************************************

2.2 Системные ресурсы: CPU и память

Ссылки:

CPU -
https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80

RAM -
https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BF%D0%BE%D0%BC%D0%B8%D0%BD%D0%B0%D1%8E%D1%89%D0%B5%D0%B5_%D1%83%D1%81%D1%82%D1%80%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%BE_%D1%81_%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%BB%D1%8C%D0%BD%D1%8B%D0%BC_%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%BE%D0%BC

Любое нагрузочное тестирование в итоге сводится к вопросу: хватает ли системе ресурсов, чтобы справиться с текущей и будущей нагрузкой.

Два ключевых ресурса:
- CPU (центральный процессор) — обрабатывает инструкции, выполняет код, принимает сетевые соединения и т.д.
- Память (RAM) — хранит данные, к которым требуется быстрый доступ: объекты, кэши, соединения, промежуточные результаты.

Понимание их работы, поведения под нагрузкой и типичных "узких мест" помогает точно интерпретировать результаты тестов. Ошибки, заниженные или переоценённые ожидания от CPU и памяти могут:
- искажать результаты тестов,
- приводить к ложным выводам,
- вызывать непредсказуемое поведение в продакшене.



Процессор: CPU (Central Processing Unit)

Что такое CPU? CPU — мозг системы. Его задачи:
- Выполнение инструкций программ,
- Планирование потоков,
- Обработка сетевых соединений,
- Шифрование, сериализация, маршрутизация.

Масштаб нагрузки на CPU зависит от:
- количества одновременных пользователей,
- характера операций (IO-bound или CPU-bound),
- архитектуры приложения (однопоточное/многопоточное),
- языка программирования и рантайма.



Метрики CPU - 
(Метрика -- Описание) -

CPU Usage (%) -- Доля занятости процессора. Суммируется по всем ядрам.

Load Average (Linux) -- Количество процессов, ожидающих CPU. Сравнивается с числом ядер.

Context Switches -- Количество переключений между задачами. Много — признак проблем с многопоточностью.

CPU Steal (в виртуальных машинах) -- Сколько времени CPU "украдено" хостом (например, в облаке).



Примеры проблем с CPU -
(Симптом -- Возможная причина -- Как диагностировать)

CPU 100% -- Узкое место в алгоритме или сервисе -- top, htop, flamegraph

Высокий Load Avg > ядер -- Перегрузка, очереди -- uptime, w, vmstat

Неравномерная загрузка ядер -- Неоптимальное распараллеливание -- инструменты профилирования

Слишком много context switches -- Нестабильная многопоточность -- pidstat, perf



Что важно в нагрузочных тестах?
- Наращивая нагрузку (stress), определяем точку деградации CPU.
- В endurance тестах оцениваем устойчивость CPU к длительной нагрузке.
- При spike test'ах смотрим, как быстро CPU восстанавливается после всплеска.
- Анализируем: какое число пользователей/запросов система выдерживает до перегрузки CPU?
	

	
Оперативная память: RAM (Random Access Memory)
Что такое оперативная память? RAM используется для:
- хранения промежуточных данных (объекты, сессии, буферы),
- работы garbage collector'а (в языках с автоматическим управлением памятью),
- кэширования (например, баз данных, API-ответов),
- работы ОС (файловые кэши, очереди, сетевые буферы).



Метрики памяти -
(Метрика -- Описание) -

RSS (Resident Set Size) -- Сколько физической памяти использует процесс.

VSZ (Virtual Size) -- Виртуальный объём адресного пространства.

Heap / Non-Heap -- Память, выделенная для объектов / остальная служебная память.

Page Faults -- Обращения к диску при нехватке памяти.

GC Activity -- Количество и длительность сборок мусора.



Примеры проблем с памятью -
(Симптом -- Возможная причина -- Диагностика) -

Утечка памяти (leak) -- Объекты не освобождаются -- Профайлер, heap dump

Частые паузы GC -- Недостаток памяти, плохая настройка GC -- метрики GC, pause time

Рост latency со временем -- Кеши не сбрасываются, ресурсы накапливаются -- endurance test

OOM (Out Of Memory) -- Превышение лимитов памяти -- лог OOM Killer, мониторинг



Что важно в нагрузочных тестах -

- Soak/Endurance Testing позволяет найти медленные утечки, не видимые за 5 минут.

- Load Testing показывает объём памяти, необходимый при стабильной нагрузке.

- Stress Testing помогает проверить, как система ведёт себя при превышении лимитов.

- Resilience Testing проверяет, как приложение реагирует на OOM, падения GC и пр.



Инструменты мониторинга и анализа - 
(Инструмент	--- Назначение) -

top, htop, atop, dstat, vmstat	--- Общая загрузка ресурсов

pidstat, iostat, mpstat	--- Диагностика процессов

pmap, smem	--- Анализ памяти процессов

Prometheus + Grafana --- Визуализация метрик в реальном времени

valgrind, VisualVM, gperftools, Flamegraph --- Глубокий анализ и профилирование



Связь с видами нагрузочного тестирования -
(Вид тестирования -- CPU и память — ключевые аспекты) -

Load Testing -- Следим за стабильной утилизацией

Stress Testing -- Где "ломается" CPU или память

Soak Testing -- Проверка на утечки, усталость системы

Spike Testing -- Моментальная реакция ресурсов

Scalability Testing -- Как ресурсы реагируют на рост нагрузки

Resilience Testing -- Устойчивость к деградации и восстановление

Chaos Testing -- Проверка на сбои: OOM, CPU starvation и пр.



нагрузка на процессор измеряется в процентах 

одно ядро - это 100% 

соответственно если 5 ядер, то будет 500% всего в Grafana

нагрузка на память измеряется в гигабайтах, но нужно оценивать динамику загрузки оперативной памяти  

при анализе памяти учитывать что могут быть утечки, например не очищается кэш 

весь смысл работы и анализа с оперативной памятью сводится к тому, что нужно выявить утечки, так как оперативная память должна очищаться 

когда оперативная память кончается, она начинает делать свап, то есть перемещать часть данных из оперативной памяти на жесткий диск, но запись на жесткий диск достаточно долгая, то на несколько секунд всё подвисает 

в Grafana посмотреть объем свапа можно на графике - Memory Swap per Container

не путать понятия -
- оперативная память 
- HDD
- SSD 

нагрузочное тестирование без анализа системных ресурсов смысла не имеет 



******************************************

2.3 Метрики нагрузочного тестирования

Метрики можно условно разделить на несколько групп:
- Метрики производительности приложения (Response Time, RPS, ошибки)
- Метрики нагрузки (кол-во пользователей, concurrency, throughput)
- Метрики инфраструктуры (CPU, RAM, диски, сеть)
- Метрики распределения и статистики (percentiles, медиана и др.)



1. Основные метрики отклика

- Response Time (время отклика) -
Определение: время между отправкой запроса и получением полного ответа от сервера.

Варианты:
- Average Response Time – среднее время отклика (может быть искажено пиками).
- Min / Max Response Time – минимальное и максимальное время отклика.
- Median Response Time (P50) – время, за которое половина запросов завершилась (менее чувствительно к выбросам).
- Percentiles (P90, P95, P99) – процентиль — значение, ниже которого находится заданный процент всех измерений.

Пример:
- P95 = 1500 мс означает, что 95% запросов завершились быстрее, чем за 1,5 секунды.
- P99 важен в SLA, особенно для UI и API-интерфейсов.

Percentiles vs Average - Среднее значение может быть обманчивым: если 9 запросов по 100 мс и 1 запрос за 5 сек → среднее = 590 мс, но большинство пользователей имели отличный опыт.



2. Метрики нагрузки

RPS (Requests per Second) -
Определение: количество обрабатываемых запросов в секунду.

Важно для:
- оценки throughput (пропускной способности),
- тестирования серверной части под реальной нагрузкой.

Пример: если у API 100 RPS, а 95% запросов укладываются в 300 мс — это хороший показатель.



Throughput -
Близкий к RPS, но иногда трактуется шире: как объём данных, проходящих через систему в единицу времени (например, MB/s).

Concurrent Users (одновременные пользователи) -
Сколько виртуальных пользователей (VUs) одновременно активны в сценарии (например, делают запрос, ожидают ответа, или "зависают" в think time).



Virtual Users (VUs) -
Количество имитируемых пользователей в нагрузочном тесте. Может не совпадать с "активными" пользователями (не все делают запросы одновременно).

Важно! Если 100 VU делают по 1 запросу каждые 10 секунд → это лишь 10 RPS.

Latency vs Response Time
- Latency — задержка между отправкой запроса и первым байтом ответа.
- Response Time — полное время получения ответа.
- Иногда путаются, особенно в сетевых метриках.



3. Метрики ошибок


Error Rate -
Процент завершившихся с ошибкой запросов (например, 5xx, timeout, network error и т.д.)

Пример: если было 10000 запросов, а из них 50 неуспешных, error rate = 0.5%

HTTP status code distribution -
Полезно отслеживать, сколько 200, 4xx, 5xx и пр. Это помогает отличить клиентские ошибки от серверных проблем.

Timeouts / Connection Errors -
- Таймауты: запросы, которые превысили лимит времени.
- Connection Errors: проблемы при установке TCP/SSL соединения.

Failures per Second - запросы, которые завершились с ошибкой (штук в секунду)



4. Продвинутые метрики


Think Time / Pacing -
- Think Time - имитация "времени раздумий" пользователя между действиями (сколько думает один средний пользователь между запросами) - измеряется в секундах 
- Pacing — задержка между итерациями одного и того же VU.
- Позволяет избежать нереалистичной нагрузки.

Dropped Requests / Retries -
- Dropped — сервер сбрасывает соединение под нагрузкой.
- Retries — количество повторных запросов после неудачи.

CPU Time per Request -
Время CPU, затраченное на обработку одного запроса (можно оценивать через профилировщик или APM).



Сводная таблица: часто используемые метрики -
Метрика	-- Тип -- Комментарий

Response Time (avg)	-- Время -- Среднее время отклика

Response Time (P95, P99) -- Время -- Более точный показатель UX

RPS -- Нагрузка -- Кол-во запросов в секунду

VUs -- Нагрузка -- Сколько пользователей

Error Rate -- Ошибки -- % запросов с ошибкой

Min/Max Response Time -- Время -- Для выявления пиков

CPU / RAM Usage -- Системные ресурсы -- Инфраструктурная метрика

Throughput -- Нагрузка -- Пропускная способность

Timeout Count -- Ошибки -- Количество таймаутов

Connection Failures -- Ошибки -- Проблемы сети / API Gateway

Percentiles -- Статистика -- P50, P90, P95, P99

Latency -- Время -- Особенно важно в сетевых API



Пример интерпретации - Допустим, после запуска теста:
RPS = 200
P95 Response Time = 950 мс
P99 = 1800 мс
Error Rate = 0.7%
CPU = 90%
RAM = 65%

Интерпретация:
- Производительность в целом хорошая, но есть проблемы на пике (P99 высокое).
- CPU почти на пределе → возможный кандидат на масштабирование.
- Нужно разобраться с 0.7% ошибок: возможно, таймауты.



Извините, а скриншот графика с Percentiles (P90, P95, P99) из locust или используется стороннее приложение?
"Из коробки", кажется, в locust такого не видела.
-
Да, в locust такого нет. Данный скриншот взят из системы аналитики load-testing-hub, можно почитать подробнее тут https://habr.com/ru/articles/871154/



******************************************

2.4 Клиент-серверная архитектура

Ссылки - Клиент-серверная архитектура -
https://en.wikipedia.org/wiki/Client%E2%80%93server_model

Клиент-серверная архитектура — это модель, в которой взаимодействуют два типа компонентов: клиент и сервер. Она широко используется в разработке приложений, особенно тех, что требуют взаимодействия с удаленными системами, будь то веб-сервисы, базы данных, файлы или другие ресурсы.



Основные компоненты клиент-серверной архитектуры:

1 - Клиент: Это приложение или устройство, которое инициирует запросы. Клиент может быть веб-браузером, мобильным приложением, десктопной программой или другим компонентом, который взаимодействует с сервером для получения или отправки данных.

2 - Сервер: Это система, которая обрабатывает запросы от клиента и возвращает результаты. Сервер может быть программным или аппаратным обеспечением, которое выполняет операции, связанные с хранением данных, вычислениями, и обеспечивает доступ к различным ресурсам.



Взаимодействие между клиентом и сервером:

- Запрос: Клиент отправляет запрос на сервер, используя стандартный протокол, такой как HTTP, FTP, WebSocket и другие.

- Ответ: Сервер обрабатывает запрос, выполняет необходимые операции и отправляет клиенту результат (например, данные, статус, ошибку).

Пример: Когда вы заходите на веб-сайт, ваш браузер (клиент) отправляет запрос на веб-сервер, который возвращает веб-страницу, отображаемую на вашем экране.



Преимущества клиент-серверной архитектуры:

1 - Масштабируемость: Серверы могут быть настроены для обработки множества запросов от клиентов.

2 - Централизация: Вся логика и данные могут быть централизованы на сервере, что упрощает управление и безопасность.

3 - Безопасность: Сервер может быть настроен для проверки прав доступа и защиты данных.



Виды клиент-серверной архитектуры:

1 - Одноуровневая архитектура (1-tier architecture):
- Вся логика (клиент и сервер) находится в одном месте, обычно на одном устройстве или сервере.
- Пример: Простое приложение, где клиент и сервер совмещены (например, локальные программы).

2 - Двухуровневая архитектура (2-tier architecture):
- В этой модели есть два компонента: клиент и сервер.
- Пример: Веб-приложение с веб-сервером, который обрабатывает запросы от клиента (браузера).

3 - Многоуровневая архитектура (N-tier architecture):
- Это расширенная модель, в которой могут быть несколько слоев: например, клиент, веб-сервер, приложение и база данных.
- Пример: Большие веб-приложения, которые используют серверы приложений, базы данных и другие компоненты для обработки данных. 



Пример двухуровневой архитектуры (клиент-сервер):
- Клиент: Браузер, который отправляет HTTP-запросы на сервер.
- Сервер: Веб-сервер, который обрабатывает запросы и взаимодействует с базой данных.

Пример:
- Пользователь открывает браузер и вводит URL, например, https://example.com.
- Браузер отправляет HTTP GET-запрос на сервер, который находится по этому адресу.
- Сервер обрабатывает запрос, извлекает данные из базы данных или выполняет другую логику, а затем отправляет ответ обратно.
- Браузер получает HTML, CSS и JavaScript и отображает веб-страницу пользователю.



Примеры использования клиент-серверной архитектуры:

1 - Веб-приложения:
- Веб-браузер отправляет запросы на сервер, который обрабатывает их и возвращает результаты в виде веб-страниц (HTML, CSS, JS).
- Примеры: Gmail, Facebook, банковские приложения.

2 - Мобильные приложения:
- Мобильное приложение может работать как клиент, а сервер обрабатывает запросы и возвращает данные, которые отображаются на устройстве.
- Примеры: WhatsApp, Instagram, приложения для заказа еды.

3 - Игры:
- Онлайн-игры используют клиент-серверную архитектуру для отправки и получения данных о состоянии игры между клиентом (игроком) и сервером.
- Пример: Fortnite, World of Warcraft.



Клиент-серверная архитектура является основой для большинства современных приложений и сервисов. Она позволяет централизовать обработку данных на сервере, обеспечивать масштабируемость и безопасность, а также упрощает управление логикой приложения.

Этот подход играет важную роль в автоматизации тестирования, поскольку тесты могут быть направлены на проверку взаимодействия между клиентом и сервером, включая запросы и ответы, обработку ошибок и производительность.



протоколы для -

- web-приложение (браузер) - HTTP, HTTPS

- десктопное приложение и мобильное приложение - gRPS



******************************************

2.5 Монолитная архитектура

Ссылки:

Сравнение микросервисной и монолитной архитектур -
https://www.atlassian.com/ru/microservices/microservices-architecture/microservices-vs-monolith

В чем разница между монолитной архитектурой и архитектурой микросервисов? -
https://aws.amazon.com/ru/compare/the-difference-between-monolithic-and-microservices-architecture/



Монолитная архитектура — это архитектурный стиль, при котором всё приложение разрабатывается, разворачивается и масштабируется как единое целое.

В монолите все компоненты приложения — пользовательский интерфейс, бизнес-логика, доступ к данным и взаимодействие с внешними сервисами — находятся в одном исполняемом процессе.



Структура монолитного приложения -
Обычно монолитное приложение включает в себя следующие слои:

- Представление (UI Layer). Отвечает за взаимодействие с пользователем (например, HTML-страницы, REST API, графический интерфейс).

- Бизнес-логика (Business Logic Layer). Основные правила и логика обработки данных, расчетов, валидации и принятия решений.

- Доступ к данным (Data Access Layer). Работа с базами данных, кэшами, файлами и другими хранилищами.

- Интеграции (Integration Layer). Если монолит взаимодействует с внешними API или сервисами, этот слой обрабатывает вызовы.

Все эти слои разворачиваются как единый модуль, зачастую в одном контейнере или на одном сервере.



Примеры монолитных приложений -

- Приложения, написанные в Java EE / Spring Boot с использованием Tomcat или JBoss, где всё приложение — один .war или .jar файл.

- Приложения, написанные на Python и использующие Django фреймворк.

- Старые веб-приложения на PHP, где бизнес-логика, шаблоны и SQL-запросы находятся в одном проекте.

Примеры:
- WordPress
- CRM-системы типа 1С:Предприятие
- Внутренние ERP-программы крупных компаний до перехода к микросервисам



Преимущества монолитной архитектуры -

Преимущество -
Объяснение

Простота разработки	- 
Один проект, одна точка входа. Удобно начинать с монолита на ранних этапах.

Единый деплой -
Всё приложение деплоится как единый артефакт. Нет необходимости в настройке множества сервисов.

Проще отлаживать и тестировать -
Вся система в одном процессе, легче использовать отладчик, писать юнит-тесты.

Проще локальная разработка -
Нет необходимости поднимать множество сервисов или использовать Docker/Orchestrator.



Недостатки монолитной архитектуры -

Недостаток -
Объяснение

Плохая масштабируемость по частям -
Нельзя масштабировать только “узкие места” — масштабируется всё приложение.

Сложность изменений в больших системах -
Малейшее изменение требует пересборки и перезапуска всего приложения.

Сложности с командами -
Несколько команд, работающих над одним проектом, могут мешать друг другу.

Ограниченная гибкость технологий -
Все части должны использовать одну и ту же технологическую версию, библиотеку, стек.

Риск полного отказа -
Ошибка в одном месте может “уронить” всё приложение.



Когда выбирать монолит?
Монолитная архитектура подходит в следующих случаях:

- Вы создаёте MVP или первый прототип, который нужно быстро запустить.

- Команда небольшая, проще сосредоточиться на одной кодовой базе.

- Вы работаете в условиях ограниченного бюджета, и инфраструктура микросервисов избыточна.

- Приложение по определению не будет масштабироваться (например, внутренние инструменты).



Эволюция: от монолита к микросервисам
Монолитное приложение со временем может:
- “распухнуть” — превратиться в громоздкий и трудноизменяемый код;
- начать испытывать трудности с масштабированием;
- требовать разделения команд и внедрения микросервисной архитектуры.

Этот процесс называют модульным рефакторингом — вынос функциональности из монолита в отдельные сервисы.



Монолитная архитектура — это простая и эффективная модель для начальной разработки и небольших команд. Однако при росте нагрузки и сложности системы появляются ограничения, требующие перехода к более гибким архитектурам, таким как микросервисы или модульные монолиты.



******************************************

2.6 Микросервисная арихтекутра

Ссылки:

Микросервисная архитектура -
https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0

Микросервисная архитектура статья от atlassian -
https://www.atlassian.com/ru/microservices/microservices-architecture

Сравнение микросервисной и монолитной архитектур -
https://www.atlassian.com/ru/microservices/microservices-architecture/microservices-vs-monolith

В чем разница между монолитной архитектурой и архитектурой микросервисов? -
https://aws.amazon.com/ru/compare/the-difference-between-monolithic-and-microservices-architecture/



Микросервисная архитектура (microservice architecture) — это подход к проектированию программных систем как набора небольших, автономных сервисов, каждый из которых реализует отдельную бизнес-функцию, взаимодействуя с другими сервисами через лёгкие протоколы (обычно HTTP/REST, gRPC, AMQP и др.).

Каждый микросервис:
- Развивается и деплоится независимо
- Обладает собственной логикой и хранением данных
- Может быть написан на своём языке программирования



Основные характеристики микросервисов -

Характеристика -
Описание

Изоляция -
Каждый сервис — отдельный процесс. Ошибка одного сервиса не должна ломать всю систему.

Независимое масштабирование -
Можно масштабировать только “узкие” сервисы (в отличие от монолита).

Автономность разработки -
Команды могут независимо разрабатывать, тестировать и деплоить отдельные сервисы.

Свои данные -
Каждый микросервис владеет своей БД (или схемой в общей БД) — “Database per service”.

Коммуникация по сети -
Взаимодействие идёт через сетевые вызовы, обычно по API.

Обработка сбоев -
Часто применяются: Circuit Breaker, Retry, Timeout, Load Balancer.

DevOps и автоматизация -
Нужна зрелая CI/CD-инфраструктура, наблюдаемость, логирование.



Коммуникации между микросервисами -

- Синхронные: HTTP/REST, gRPC. Быстро, просто, но чувствительно к сбоям

- Асинхронные: через очереди сообщений (RabbitMQ, Kafka). Повышает устойчивость, снижает связанность



Преимущества микросервисной архитектуры -

- Масштабируемость. Горизонтальное масштабирование отдельных компонентов

- Независимость разработки. Меньше конфликтов между командами, проще CI/CD

- Гибкость технологий. Возможность использовать разные языки, базы, фреймворки

- Отказоустойчивость. Локализация проблем: сбой одного сервиса ≠ падение всей системы

- Лучшая поддержка DevOps/Cloud. Хорошо сочетается с Kubernetes, контейнерами, облаками



Недостатки и сложности -

Недостаток -
Почему это проблема

Сложность инфраструктуры -
Нужен сервис-меш (например, Istio), оркестратор (K8s), мониторинг

Сетевые накладные расходы -
Больше запросов по сети → latency, ошибки

Трудности отладки -
Сервис может "ломаться" в связке с другим

Согласованность данных -
Труднее обеспечить ACID и транзакции между сервисами

Сложное управление версиями -
Необходима контрактная совместимость API

DevOps-зрелость обязательна -
Нужны CI/CD, логирование, трассировка, автоматизация



Когда стоит использовать микросервисы? -

Подходят:
- Для крупных распределённых систем
- Когда есть несколько команд разработки
- Если бизнес-логика чётко делится на независимые домены
- При высоких требованиях к масштабируемости и доступности

Не рекомендуются:
- Для маленьких или средних проектов
- Если нет опыта в CI/CD, облаках и Kubernetes
- Когда проще использовать модульный монолит



Пример микросервиса - Банковская система -
- AccountService — управление счетами
- TransactionService — перевод средств
- ReportingService — отчёты
- FraudDetectionService — выявление подозрительной активности



Отличие от монолита -
Признак - Монолит - Микросервисы -

Масштабируемость - Только целиком - По частям

Разработка - Одним блоком - Независимыми командами

Развёртывание - Общее - Независимое

Надёжность - Уязвим к сбою одного модуля - Локализация проблем

Работа с данными - Единая БД - Базы у каждого сервиса

Производительность - Быстрее (внутренние вызовы) - Зависит от сети, требует кеширования

Тестирование - Проще - Сложнее, нужны контракты и трассировка



Связанные архитектурные шаблоны -

- API Gateway — единая точка входа, маршрутизация к микросервисам (грубо говоря - это прокси)

- Service Discovery — динамическое обнаружение сервисов

- Sidecar — вспомогательные контейнеры для логирования, трейсинга

- CQRS / Event Sourcing — раздельная обработка чтения и записи

- SAGA Pattern — распределённые транзакции



Микросервисы — это мощный, но не бесплатный архитектурный подход. Их внедрение требует зрелости как в инженерной культуре, так и в технической инфраструктуре. Для крупных систем это может дать огромные преимущества: гибкость, отказоустойчивость и масштабируемость. Но для небольших — избыточная сложность.



мы в этом курсе позже будем работать со стендом, где используется микросервисная архитектура

для каждого микросервиса - запускается отдельный процесс 

микросервисы можно масштабировать независимо друг от друга (точечно, то есть добавлять ресурсы только микросервису, которому они нужны, а не всему приложению, как в монолите)

каждый микросервис владеет своей БД (или схемой в общей БД) - "Database per service"

gRPS - самый быстрый синхронный протокол взаимосвязи между микросервисами 



******************************************

2.7 Инструменты нагрузочного тестирования

Введение: Зачем нужны инструменты нагрузочного тестирования

Когда приложение или сервис разрабатывается, важно не только убедиться в его корректной работе (функциональное тестирование), но и понять, как он будет вести себя под нагрузкой: сможет ли выдерживать большое количество пользователей, насколько быстро будет отвечать, не упадёт ли при высоком трафике. Именно для этого и применяется нагрузочное тестирование.



Тестирование производительности — это обобщающее понятие, включающее в себя несколько подвидов:

- Load Testing — проверка системы при ожидаемой нагрузке;

- Stress Testing — проверка пределов, когда нагрузка превышает норму;

- Spike Testing — оценка реакции на резкие всплески трафика;

- Soak Testing — длительное тестирование для выявления деградации;

- Scalability Testing — анализ способности масштабироваться при росте нагрузки.



Но возникает вопрос: Как сымитировать поведение сотен, тысяч или даже миллионов пользователей, чтобы проверить систему?



Решением являются специальные инструменты нагрузочного тестирования. Они позволяют:

- Имитировать запросы от пользователей (HTTP, WebSocket, gRPC и др.)

- Создавать настраиваемую нагрузку — например, 1000 пользователей в течение 10 минут

- Оценивать производительность — время ответа, количество ошибок, RPS, процентильные задержки и другие метрики

- Автоматизировать тесты и интегрировать их в CI/CD

- Настраивать сценарии поведения пользователей, включая сложные последовательности действий



Как работают эти инструменты - 

1 - Сценарий теста описывает поведение пользователей:
Например: 
"Открыть страницу → Войти → Получить список товаров → Добавить товар в корзину".

2 - Инструмент запускает множество виртуальных пользователей (VUs), которые параллельно и многократно выполняют этот сценарий.

3 - Запросы отправляются к серверу, как если бы это делали настоящие пользователи.

4 - Инструмент собирает метрики: время ответа, количество запросов в секунду (RPS), процент ошибок, поведение под пиковыми нагрузками.

5 - Результаты визуализируются в виде графиков или отчётов — это помогает принимать архитектурные и бизнес-решения.

Виртуальные пользователи (Virtual Users, VUs) — это программные сущности, имитирующие действия реальных пользователей. Каждый такой пользователь выполняет заданный сценарий, посылает запросы к серверу и участвует в генерации нагрузки.



Типовые цели использования инструментов:

- Проверить, сколько пользователей может выдержать система

- Найти узкие места в производительности (например, медленные запросы)

- Сравнить поведение разных версий (до и после оптимизации)

- Тестировать SLA (время ответа, стабильность, доступность)

- Подготовиться к реальным пиковым нагрузкам (Black Friday, акции, релизы)



Примеры использования на практике:

- Интернет-магазин проверяет, выдержит ли он 10 000 пользователей во время распродажи

- Банк тестирует обработку тысяч транзакций в минуту

- Мобильное приложение проверяет API при подключении 5000 одновременных клиентов

- Онлайн-игра моделирует игровую сессию с 3000 игроками на сервере



Нагрузочное тестирование — это обязательный этап для любого серьёзного продукта. А инструменты для нагрузочного тестирования — это основной способ смоделировать поведение пользователей, зафиксировать метрики и убедиться, что система будет работать быстро, стабильно и предсказуемо даже под высокими нагрузками.

В этом курсе мы сделаем акцент на open-source решениях, которые легко использовать локально, интегрировать в пайплайны и применять даже в небольших командах. Особое внимание уделим Locust — современному инструменту на Python, который легко осваивается и при этом подходит как для обучения, так и для промышленных нагрузочных сценариев.



Инструменты нагрузочного тестирования: подробный обзор и сравнение -



Locust: 

Официальный сайт -
https://locust.io/

Официальная документация -
https://docs.locust.io/en/stable/

Репозиторий -
https://github.com/locustio/locust



JMeter:

Официальный сайт -
https://jmeter.apache.org/

Официальная документация -
https://jmeter.apache.org/usermanual/index.html

Репозиторий -
https://github.com/apache/jmeter



K6:

Официальный сайт -
https://k6.io/

Официальная документация -
https://grafana.com/docs/k6/latest/

Репозиторий -
https://github.com/grafana/k6



Gatling:

Официальный сайт -
https://gatling.io/

Официальная документация -
https://docs.gatling.io/

Репозиторий -
https://github.com/gatling/gatling



Artillery:

Официальный сайт -
https://www.artillery.io/

Официальная документация -
https://www.artillery.io/docs

Репозиторий -
https://github.com/artilleryio/artillery



1. Locust

Locust — это современный инструмент нагрузочного тестирования с открытым исходным кодом, в котором сценарии описываются на чистом Python. Он отлично подходит для моделирования поведения пользователей с высокой степенью реалистичности и гибкости. Благодаря удобному API, простому запуску и поддержке популярных протоколов, Locust стал выбором многих команд разработки и тестирования.



Основные характеристики:

- Язык сценариев: Python

- Подход: Поведение пользователей описывается как Python-классы

- Протоколы: HTTP/HTTPS, WebSocket, gRPC (через сторонние расширения)

- Интерфейс: Web-интерфейс для управления нагрузкой + CLI для автоматизации

- Масштабирование: Поддержка master/worker модели (distributed mode)

- Мониторинг: Встроенная web-панель, интеграция с Prometheus и Grafana

- Установка: pip install locust



Преимущества:

- Написание тестов на чистом Python — просто, читаемо, удобно для разработчиков

- Поддержка реалистичного пользовательского поведения — задержки, веса, последовательности

- Лёгкая интеграция с любыми Python-библиотеками (requests, httpx, grpcio, pydantic и др.)

- Быстрый вход в инструмент — идеален для обучения и прототипирования

- Активное сообщество, расширения и хорошая документация -
github.com/locustio/locust



Ограничения:

- Меньше встроенных визуальных инструментов, чем у JMeter или k6

- Не предназначен для экстремально высоких нагрузок (млн+ RPS), но работает стабильно до сотен тысяч при правильной настройке



Кому подойдёт: Python-разработчикам, QA-инженерам, DevOps-специалистам, которым важна гибкость сценариев, хорошая читаемость и простая интеграция в пайплайны CI/CD.

Пример простого сценария на Locust:
--
from locust import HttpUser, task, between

class WebsiteUser(HttpUser):
    wait_time = between(1, 5)  # Пауза между действиями (в секундах)

    @task
    def load_homepage(self):
        self.client.get("/")

    @task
    def view_products(self):
        self.client.get("/products")

    @task
    def make_purchase(self):
        self.client.post("/purchase", json={"item_id": 42})
----
- В этом примере:

- Класс WebsiteUser описывает поведение виртуального пользователя.

- Методы, помеченные @task, представляют действия, которые он выполняет.

- self.client используется для отправки HTTP-запросов.

- wait_time задаёт паузу между действиями, моделируя поведение настоящего пользователя.



2. Apache JMeter

JMeter — один из самых известных инструментов для нагрузочного тестирования. Он предлагает визуальный интерфейс для создания сценариев без программирования и поддерживает широкий спектр протоколов, включая не только HTTP, но и FTP, SOAP, JDBC, JMS и другие. JMeter активно используется в корпоративной среде, особенно в крупных организациях, где важна поддержка legacy-систем.



Основные характеристики:

- Язык сценариев: GUI-инструмент (визуальная сборка) + JMX/XML-конфигурации (опционально Groovy)

- Подход: Сценарии собираются через графический интерфейс, можно сохранять и редактировать в виде конфигурационных файлов

- Протоколы: HTTP, JDBC, FTP, SOAP, JMS и др.

- Интерфейс: Графический интерфейс (GUI) + командная строка (CLI) для запуска без UI

- Масштабирование: Есть поддержка distributed mode, но настройка сложнее, чем в Locust

- Мониторинг: Через встроенные или сторонние плагины; возможен экспорт метрик в Prometheus, InfluxDB и др.

- Установка: Скачивание с сайта Apache JMeter -
https://jmeter.apache.org/
+
github.com/apache/jmeter



Преимущества:

- Богатая поддержка различных протоколов и конфигураций — удобно для нестандартных или legacy-сценариев

- Возможность создавать тесты без программирования — через визуальный интерфейс

- Часто используется в больших компаниях, хорошо известен в индустрии

- Поддержка широкого набора плагинов и расширений



Ограничения:

- Интерфейс довольно тяжёлый и устаревший, особенно при работе с большими сценариями

- Сценарии хранятся в JMX/XML, что делает их сложными для чтения, версионирования и code-review

- Ограниченная гибкость при описании логики поведения пользователей

- Не интегрируется нативно с Python — не лучший выбор для Python-ориентированных команд

- Хотя JMeter широко используется и часто встречается в учебных курсах, его архитектура и интерфейс устарели. Он был создан в начале 2000-х, и с тех пор принципы разработки и тестирования сильно изменились.

- Многие компании используют JMeter из-за исторических причин или внутреннего наследия (legacy). Legacy (наследие) — это устаревший код или инструменты, которые тяжело заменить, но продолжают использоваться.

- На практике это означает: JMeter не лучший выбор для новых проектов, особенно если вы работаете с Python, современными API, CI/CD и микросервисами. Есть более лёгкие, гибкие и удобные инструменты — такие как Locust, k6, Gatling, которые лучше отражают текущие подходы в нагрузочном тестировании.

Кому подойдёт: Тестировщикам и инженерам, работающим с широким спектром протоколов, корпоративными сервисами и legacy-системами. Особенно актуален, если требуется безкодовое создание тестов и поддержка старых технологий (SOAP, JMS и др.).



Пример сценария в JMeter (визуально) - 
Хотя JMeter — это в первую очередь GUI-инструмент, можно описать базовую структуру сценария:
--
Test Plan
├── Thread Group (например, 100 пользователей, 10 циклов)
│   ├── HTTP Request (GET https://example.com)
│   ├── HTTP Request (POST https://example.com/login)
│   ├── Assertions (проверка кода ответа, текста)
│   └── Timers (задержки между действиями)
└── Listeners (отчёты: графики, таблицы, лог-файлы)
----

Визуально вы собираете такой сценарий как блок-схему в JMeter GUI, задавая параметры через формы



Почему мы не делаем акцент на JMeter в этом курсе?
Хотя JMeter по-прежнему встречается в крупных компаниях и старых системах, мы намеренно не делаем его основным инструментом. Он плохо подходит для гибкой автоматизации, плохо читается в виде кода, требует ручного конфигурирования и не вписывается в современные пайплайны.

Вместо этого мы сосредоточимся на инструментах нового поколения, которые легко использовать в CI/CD, удобно писать как код и масштабировать — например, Locust и k6.



3. k6

k6 — это современный и лёгкий инструмент для нагрузочного тестирования, ориентированный на автоматизацию, CI/CD и мониторинг. Сценарии пишутся на JavaScript (ES6), а основной упор сделан на тестирование HTTP и WebSocket API. Инструмент активно развивается и используется в DevOps-среде благодаря своей простоте, скорости и глубокой интеграции с системами мониторинга, особенно с Grafana и InfluxDB.



Основные характеристики:

- Язык сценариев: JavaScript (ES6)

- Подход: Сценарии пишутся как код — экспортируются функции default и setup

- Протоколы: HTTP, WebSocket, gRPC (через отдельные модули)

- Интерфейс: CLI + облачная платформа k6 Cloud (опционально)

- Масштабирование: Поддерживает распределённые запуски, интеграцию с Docker, Kubernetes

- Мониторинг: Встроенный экспорт метрик в Grafana, InfluxDB, Prometheus

- Установка: brew install k6 или скачать с официального сайта -
k6.io



Преимущества:

- Современный, удобный CLI-интерфейс

- Отлично вписывается в CI/CD пайплайны

- Гибкий экспорт метрик в системы мониторинга

- Поддержка k6 Cloud для визуального анализа и запуска из облака

- Быстро запускается, минимальные зависимости



Ограничения:

- Сценарии пишутся на JavaScript без строгой типизации, что делает код уязвимым к скрытым ошибкам: undefined, преобразование типов, ловушки null, непредсказуемые логические выражения — всё это может вызвать сбои в нагрузочном тесте, которые тяжело отловить

- Полноценной поддержки TypeScript нет — возможна только через сторонние сборки и конфигурации (xk6, webpack, esbuild), что усложняет разработку

- В отличие от Python в Locust, меньше гибкости при описании пользовательской логики, особенно при сложных сценариях и интеграциях

- Поддержка gRPC реализована, но через дополнительные модули и требует ручной настройки



Кому подойдёт: DevOps-инженерам, QA-специалистам и разработчикам, которые работают с CI/CD, используют Grafana и хотят быстро интегрировать нагрузочное тестирование в пайплайны. Особенно актуален, если команда уже использует JavaScript или хочет запускать тесты в облаке.

Важно! Несмотря на современный облик и интеграции, выбор JavaScript в чистом виде без типизации делает k6 рискованным инструментом для сложных сценариев, особенно при долгосрочной поддержке. При разработке на Python или в командах с высоким требованием к надёжности кода — Locust может быть предпочтительнее.



Пример простого сценария на k6:
--
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  vus: 50,            // Количество виртуальных пользователей
  duration: '30s',    // Продолжительность теста
};

export default function () {
  const res = http.get('https://test-api.k6.io');
  check(res, { 'статус 200': (r) => r.status === 200 });
  sleep(1);  // Пауза между запросами
----
В этом примере:
- Задаётся 50 VU на 30 секунд
- Пользователи делают GET-запрос к сайту
- Выполняется базовая проверка успешности ответа
- Используется sleep(1) для симуляции пользовательской паузы



4. Gatling

Gatling — это высокопроизводительный инструмент нагрузочного тестирования, ориентированный на разработчиков, особенно тех, кто работает со стеком Scala/Java. Он предлагает декларативный DSL для описания сценариев, хорошую масштабируемость и автоматическую генерацию HTML-отчётов. Gatling часто используют для нагрузки на HTTP API, особенно в проектах, где уже есть JVM-экосистема.

Официальный сайт - 
gatling.io 
+
github.com/gatling/gatling 



Основные характеристики:

- Язык сценариев: Scala (также возможны Kotlin и Java)

- Подход: Сценарии описываются как код с использованием Gatling DSL

- Протоколы: HTTP, WebSocket, JMS, MQTT, gRPC (ограничено)

- Интерфейс: CLI для запуска, HTML-отчёты для анализа

- Мониторинг: Автоматическая генерация подробных графиков (latency, throughput и др.)

- Установка: Через brew, sdkman, Docker или скачивание с gatling.io - https://gatling.io/



Преимущества:

- Очень высокая производительность — подходит для создания серьёзной нагрузки

- Эффективное использование ресурсов благодаря архитектуре на базе Netty

- Чёткие, подробные HTML-отчёты с графиками из коробки

- Хорошо интегрируется с CI/CD и инфраструктурой на базе JVM

- Подходит для стресс-тестирования и длительных soak-тестов



Ограничения:

- Требует знания Scala или Java — для многих команд это барьер

- Меньше гибкости и читаемости, если вы не знакомы с функциональным стилем Scala

- Не так распространён среди Python-сообщества и начинающих QA-инженеров

- Поддержка gRPC и нестандартных протоколов требует дополнительных настроек или расширений



Кому подойдёт: Разработчикам и DevOps-инженерам, работающим в JVM-экосистеме (Java, Scala, Kotlin), которым нужна высокая производительность, строгая структура сценариев и встроенная визуализация результатов. Особенно актуален в крупных продакшн-проектах, где важна скорость генерации нагрузки.

Важно! Gatling — отличный выбор для команд, уже работающих на Scala/Java, или для ситуаций, где нужна максимальная производительность и отчётность, но может быть неудобным для Python- или JavaScript-ориентированных команд из-за высокой кривой обучения.

Пример простого сценария на Gatling (Scala DSL):
--
import io.gatling.core.Predef._
import io.gatling.http.Predef._
import scala.concurrent.duration._

class BasicSimulation extends Simulation {

  val httpProtocol = http
    .baseUrl("https://test-api.gatling.io")

  val scn = scenario("Простой сценарий")
    .exec(http("Загрузка главной страницы")
    .get("/"))
    .pause(1)

  setUp(
    scn.inject(atOnceUsers(50))
  ).protocols(httpProtocol)
}
----
В этом примере:
- Используется 50 виртуальных пользователей
- Каждый выполняет GET-запрос и делает паузу
- Все результаты автоматически попадают в HTML-отчёт после завершения



5. Artillery

Artillery — это лёгкий инструмент для нагрузочного тестирования, ориентированный на разработчиков JavaScript/Node.js. Он позволяет описывать сценарии в YAML-файлах с возможностью подключения кастомной логики на JavaScript. Особенно хорошо подходит для тестирования event-driven систем: WebSocket, Socket.IO, MQTT и REST API.

Официальный сайт - 
artillery.io


Основные характеристики:

- Язык сценариев: YAML + JavaScript (Node.js)

- Подход: Конфигурационные сценарии в YAML + логика на JS-функциях

- Протоколы: HTTP, WebSocket, Socket.IO, MQTT

- Интерфейс: CLI

- Мониторинг: JSON-отчёты, интеграция с Prometheus (через плагин)

- Установка: npm install -g artillery



Преимущества:

- Простая и декларативная структура сценариев на YAML

- Возможность добавлять JS-функции для логики, генерации данных и проверки ответов

- Поддержка event-driven протоколов, включая WebSocket и MQTT

- Быстро разворачивается, не требует сложной инфраструктуры

- Хорошо вписывается в проекты на Node.js



Ограничения:

- YAML плохо подходит для больших сценариев с ветвлениями и сложной логикой — сложно отлаживать, нет автокомплита и контроля типов

- JS-функции ограничены в возможностях по сравнению с полноценными Python-классами (как в Locust)

- Менее активное и зрелое сообщество по сравнению с Locust, JMeter или k6

- Интеграция с системами мониторинга требует ручной настройки и дополнительных плагинов



Кому подойдёт: Командам, уже работающим с Node.js, которым нужно протестировать HTTP/WebSocket/MQTT API без лишней сложности. Подходит для небольших или среднеразмерных нагрузок, особенно когда важна поддержка realtime-протоколов и простота конфигурации. 

Пример простого сценария на Artillery (HTTP + JS check):
--
scenario.yaml:
--
config:
  target: "https://test-api.example.com"
  phases:
    - duration: 30
      arrivalRate: 10
  processor: "./logic.js"
scenarios:
  - flow:
      - get:
          url: "/"
          capture:
            - json: "$.status"
              as: "status"
          afterResponse: "checkStatus"
----
+
--
logic.js:
--
module.exports = {
  checkStatus: function (req, res, context, ee, next) {
    if (res.statusCode !== 200) {
      console.error("Ошибка ответа:", res.statusCode);
    }
    return next();
  }
};
----
В этом примере:
- Сценарий задаёт нагрузку в 10 пользователей/секунду
- Каждый пользователь делает GET-запрос к /
- Ответ анализируется в JS-функции checkStatus

Artillery может быть удобен как лёгкий старт, особенно для тех, кто работает в JavaScript-экосистеме. Но при необходимости сложных сценариев, масштабирования или строгой валидации — лучше рассмотреть Locust или k6 как более мощные и расширяемые инструменты. 



Сравнительная таблица нагрузочных инструментов -

Locust:
Язык сценариев - Python
Подход - Код (классы Python)
Протоколы - Любые: HTTP, WS, gRPC и т.д.
Интерфейс - CLI + Web + HTML-отчёт
Мониторинг - Веб-панель, Prometheus
Производительность - Средняя/высокая
Гибкость логики - Очень высокая (Python)
Порог входа - Низкий
Подходит для CI/CD - Да
Основной недостаток - Меньше визуальных отчётов
Кому подойдёт - Python-командам 



JMeter:
Язык сценариев - GUI + XML/Groovy
Подход - Конфигурация (JMX)
Протоколы - HTTP, SOAP, JMS и др.
Интерфейс - GUI + CLI
Мониторинг - Плагины, Prometheus
Производительность - Средняя
Гибкость логики - Низкая (конфигурации)
Порог входа - Средний
Подходит для CI/CD - Ограниченно
Основной недостаток - Устаревший, громоздкий
Кому подойдёт - Корпоративным системам



k6:
Язык сценариев - JavaScript (ES6)
Подход - Код (JS-функции)
Протоколы - HTTP, WS, gRPC
Интерфейс - CLI
Мониторинг - InfluxDB, Grafana
Производительность - Высокая
Гибкость логики - Средняя (без типизации)
Порог входа - Средний (JS обязателен)
Подходит для CI/CD - Да (встроено)
Основной недостаток - JS без типизации
Кому подойдёт - DevOps, JS-командам



Gatling:
Язык сценариев - Scala / Java / Kotlin
Подход - Код (DSL на Scala)
Протоколы - HTTP, WS, JMS, MQTT
Интерфейс - CLI + HTML-отчёты
Мониторинг - HTML-отчёты
Производительность - Очень высокая
Гибкость логики - Высокая (DSL)
Порог входа - Высокий (Scala/Java)
Подходит для CI/CD - Да
Основной недостаток - Требует Scala/Java
Кому подойдёт - JVM-разработчикам



Artillery:
Язык сценариев - YAML + JavaScript (Node)
Подход - YAML + JS-функции
Протоколы - HTTP, WS, MQTT
Интерфейс - CLI
Мониторинг - JSON, Prometheus
Производительность - Средняя
Гибкость логики - Ограниченная
Порог входа - Низкий для простых задач
Подходит для CI/CD - Да
Основной недостаток - YAML + слабая отладка
Кому подойдёт - Node.js и простые кейсы



Инструмент нагрузочного тестирования — это лишь 5–10% от всего процесса. Он — как молоток: полезный, но бесполезен без плана, чертежей и строительных навыков. Настоящее нагрузочное тестирование включает гораздо больше:

- генерация и подготовка данных (сидинги),

- создание и использование API-клиентов,

- работа с моками и изоляцией окружений,

- настройка отчётности и аналитики,

- запуск тестов в CI/CD,

- управление инфраструктурой, логами, конфигурациями,
интерпретация результатов, выявление узких мест, подготовка отчётов для бизнеса и архитекторов.



Изучая инструмент (например, Locust или JMeter), вы не изучаете всё нагрузочное тестирование. Вы изучаете лишь его инструментальную часть.

В этом курсе мы пойдём значительно дальше: от простого знакомства с инструментом — к построению зрелого, технически обоснованного процесса производительного тестирования.



Клауд-решения сейчас появляются у многих: это тренд, и даже у Locust теперь есть облачная версия, хотя раньше этого не было.

Мы рассматриваем Locust как один из самых гибких и простых инструментов для нагрузочного тестирования. А если хочется действительно красивые графики и удобный просмотр отчётов - можно использовать load-testing-hub (https://github.com/Nikita-Filonov/load-testing-hub-panel), про который я упоминал ранее. Он легко интегрируется с Locust и полностью работает локально.



Задача инструмента - создать нагрузку с определенными сценариями по определенным параметрам, собирает метрики и предоставляет нам отчет



Сопутствующие инструменты: HTTP-клиенты, валидация и контроль версий -


Ссылки:

Работа с HTTP протоколом: 
    httpx - https://www.python-httpx.org/
    requests - https://requests.readthedocs.io/en/latest/


Работа с gRPC протоколом: 
    grpcio - https://grpc.io/docs/languages/python/quickstart/


Работа с данными:
    pydantic - https://docs.pydantic.dev/latest/
    dataclasses - https://docs.python.org/3/library/dataclasses.html
    TypedDict - https://peps.python.org/pep-0589/
    NamedTuple - https://docs.python.org/3/library/collections.html#collections.namedtuple


Система контроля версий:
    GitHub - https://github.com/
    GitLab - https://about.gitlab.com/
    Bitbucket - https://bitbucket.org/product/
    Gerrit - https://www.gerritcodereview.com/



Работа с HTTP протоколом: httpx против requests

Мы будем взаимодействовать с HTTP API. Для этого нам нужен надёжный и удобный HTTP-клиент.



Почему мы выбираем httpx:

- Поддержка синхронного и асинхронного режима. httpx позволяет писать как синхронный, так и async/await-код — это даёт гибкость и масштабируемость.

- Хорошая типизация (type hints). Поддержка type hints повышает читаемость, уменьшает количество ошибок и отлично работает с IDE и mypy.

- Удобный объект Client. С поддержкой base_url, connection pooling и переиспользуемыми настройками.

- Поддержка event hooks. Можно удобно перехватывать запросы и ответы — полезно для логирования, автоматической авторизации, сбора метрик и др.



Почему не requests:

- Нет поддержки async/await и не планируется

- Нет встроенной типизации — сложно отлаживать и поддерживать в больших проектах

- Нет нативного base_url и хуков на запрос/ответ

- Развитие идёт медленно, библиотека фактически заморожена



Почему не aiohttp:

- Только асинхронный — неудобно, если проект частично синхронный

- Основной сценарий — написание серверных приложений

- Не оптимален для нагрузочного тестирования и API-клиентов



В итоге:
httpx — это современный, гибкий и хорошо типизированный HTTP-клиент, который отлично подходит для задач нагрузочного тестирования, где важна читаемость, повторное использование и контроль над запросами. Именно его мы будем использовать в этом курсе.



Работа с gRPC протоколом: grpcio

Если вы пишете нагрузочные тесты для gRPC-сервисов — вам нужен gRPC-клиент для Python. И здесь выбора практически нет: стандартная и единственная зрелая библиотека — это grpcio.



Почему grpcio:

- Официальная реализация от Google

- Поддержка всех типов вызовов: unary, server/client/bidirectional streaming

- Совместимость с .proto-контрактами (через protoc или grpcio-tools)

- Гибкость — можно использовать с любыми клиентами, фреймворками и тестовыми сценариями



Есть ли альтернативы?

Теоретически — grpclib, betterproto, grpclite, но:

- grpclib — только для async-кода

- betterproto — нестабильный, требует своей генерации

- Остальные — не поддерживают все типы вызовов или не подходят для нагрузочного тестирования


В этом курсе мы используем grpcio — как проверенное, стабильное и полностью совместимое решение для работы с gRPC-протоколом в нагрузочных тестах.



Работа с данными: pydantic

В нагрузочном тестировании важно надёжно работать с данными. Нам нужно:

- Валидировать входные данные

- Преобразовывать JSON в объекты и обратно

- Работать с алиасами, датами, enum, вложенными структурами



Для этого мы используем Pydantic — стандарт де-факто для сериализации и валидации данных в Python.



Почему именно pydantic:

- Автоматическая валидация по типам. Ошибки в данных ловятся сразу при создании модели.

Простая сериализация. Методы .dict(), .json() позволяют легко передавать и логировать данные.

Поддержка алиасов, enum, вложенности. Удобно работать с API, где ключи не всегда совпадают с Python-именами.

Читаемый и декларативный стиль. Код с BaseModel читается как документация — особенно полезно в тестах и клиентах.



Альтернативы (и почему нет):

dataclass — только структура, без встроенной валидации и сериализации

TypedDict — статичная структура, нет поведения, валидации и методов

NamedTuple — неизменяемые, неудобны в работе с JSON и вложенностью

Обычные dict — легко ошибиться, нет проверок, трудно сопровождать



В итоге:
Pydantic — это надежный инструмент для описания и валидации данных в нагрузочном тестировании. Он упрощает разработку, делает код предсказуемым и лучше документированным. В этом курсе мы будем активно использовать pydantic для API-клиентов, генерации и валидации данных.



Система контроля версий
Всё, что вы пишете, должно быть под контролем версий.
Особенно если:
- В проекте участвует несколько автоматизаторов
- Требуется история изменений и откат
- Есть CI/CD и код-ревью

Мы используем Git — стандарт в индустрии.



Популярные платформы:

- GitHub — открытые проекты, отличная документация, удобные pull-requests и обсуждения

- GitLab — подходит для приватных репозиториев и встроенных CI/CD (часто используется в корпорациях)

- Bitbucket — менее популярен, но удобен для команд, использующих Atlassian (Jira, Confluence)

- Gerrit — используется в старых или специфических проектах, требует жёсткого контроля ревью



В этом курсе мы будем использовать GitHub — как самую доступную, гибкую и популярную платформу.



отправка запросов одинакова что в httpx что в requests, разница может быть и есть, но минимальная 

pydantic - это стандарт серилизации и валидации данных в python 



******************************************

3.1 Установка и настройка окружения Python



Установка Python

Ссылки:

- Список доступных версий Python -
https://www.python.org/downloads/

- Версия Python 3.12.6 – на момент написания курса это последняя стабильная версия. Рекомендуется скачивать именно ее -
https://www.python.org/downloads/release/python-3126/



В данном уроке мы поговорим об установке интерпретатора языка Python

Установка Python на Windows

1 - Скачивание установщика:
- Перейдите на официальный сайт Python: https://www.python.org/downloads/.
- На главной странице отобразится кнопка Download Python X.X.X (где X.X.X – последняя версия Python). Нажмите на нее, чтобы загрузить установочный файл.

2 - Запуск установщика:
- Откройте загруженный файл python-X.X.X.exe.
- В появившемся окне обязательно установите флажок "Add Python to PATH" внизу окна, чтобы Python автоматически добавился в переменные среды (это упростит запуск Python в командной строке).
- Нажмите Install Now для быстрой установки или Customize installation для выбора дополнительных параметров.

3 - Проверка установки:
- После завершения установки откройте командную строку: нажмите Win + R, введите cmd, и нажмите Enter.
- Введите команду:
--
python --version
----
- Если вы увидите версию Python (например, Python 3.X.X), установка прошла успешно.



Установка Python на Linux

На большинстве дистрибутивов Linux Python уже предустановлен, но возможно, потребуется его обновление или установка новой версии. Инструкции могут отличаться в зависимости от дистрибутива. 



Ubuntu / Debian - 
1 - Обновите список пакетов:
--
sudo apt update
----
2 - Установите Python 3 и pip (менеджер пакетов Python):
--
sudo apt install python3 python3-pip -y
----
3 - Проверка установки:
Введите команду:
--
python3 --version
----
- Если вы увидите версию Python, установка выполнена успешно.



CentOS / Fedora / RHEL
1 - Установка Python 3 (на примере CentOS 8):
Выполните следующую команду:
--
sudo dnf install python3
----
2 - Проверка установки:
Введите команду:
--
python3 --version
----



Установка Python из исходного кода (если нужна последняя версия)
1 - Установите зависимости для сборки:
--
sudo apt update
sudo apt install -y build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev curl
----
2 - Скачайте и установите Python:
--
curl -O https://www.python.org/ftp/python/X.X.X/Python-X.X.X.tgz
tar -xf Python-X.X.X.tgz
cd Python-X.X.X
./configure --enable-optimizations
make
sudo make altinstall
----
- Замените X.X.X на номер версии, которую хотите установить.



Установка Python на macOS
На macOS обычно установлена более старая версия Python. Для установки последней версии рекомендуется использовать Homebrew – пакетный менеджер для macOS.
1 - Установите Homebrew (если еще не установлен):
Откройте Terminal и введите следующую команду:
--
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
----
2 - Установите Python с помощью Homebrew:
--
brew install python
----
3 - Проверка установки:
Введите команду:
--
python3 --version
----
- Должна отобразиться версия Python.
4 - Обновление pip:
Убедитесь, что менеджер пакетов pip обновлен:
--
python3 -m pip install --upgrade pip
----



Проверка переменных окружения (все системы) -
Для запуска Python в терминале или командной строке необходимо убедиться, что путь до Python добавлен в переменные среды (PATH):
1 - Windows: Если выбрано Add Python to PATH при установке, путь будет добавлен автоматически.
2 - Linux и macOS: Обычно путь добавляется автоматически, но можно проверить его в файле .bashrc, .bash_profile, или .zshrc:
--
export PATH="/usr/local/bin/python3:$PATH"
----



автор рекомендует ставить версию python на одну ниже от текущей, допустим если сейчас последняя версия - 3.12, то ставить версию 3.11 



******************************************

3.2 Установка и настройка PyCharm



PyCharm: Что это и зачем он нужен?

PyCharm — это мощная интегрированная среда разработки (IDE) для Python, разработанная JetBrains. Она предлагает множество инструментов для написания, тестирования и отладки кода, что делает его особенно популярным среди разработчиков на Python. PyCharm поддерживает автозавершение кода, отладку, контроль версий и интеграцию с популярными инструментами, такими как Docker (https://www.docker.com/) и Kubernetes (https://kubernetes.io/).

Альтернативы: Среди популярных альтернатив PyCharm можно выделить -
- Visual Studio Code - https://code.visualstudio.com/
- Atom - https://atom-editor.cc/
- Sublime Text - https://www.sublimetext.com/
- Spyder - https://www.spyder-ide.org/

Они предоставляют похожие возможности, но могут различаться по интерфейсу, поддержке плагинов и производительности.



Инструкции по установке PyCharm

Ссылки:

- Установка PyCharm для Windows -
https://www.jetbrains.com/pycharm/download/?section=windows

- Установка PyCharm для macOS - 
https://www.jetbrains.com/pycharm/download/?section=mac

- Установка PyCharm для Linux -
https://www.jetbrains.com/pycharm/download/?section=linux



Существует две версии PyCharm:

- PyCharm Community Edition (бесплатная): предназначена для обучения и разработки с базовым функционалом.

- PyCharm Professional Edition (платная): поддерживает расширенные возможности для профессионалов, такие как работа с веб-фреймворками (Django, Flask), поддержка работы с базами данных, поддержка JavaScript и других языков, а также интеграция с Docker и другими инструментами.



Установка PyCharm Community Edition - 



1 - Windows
- Перейдите на сайт JetBrains (https://www.jetbrains.com/pycharm/download/)
- Выберите версию PyCharm Community Edition и загрузите установочный файл для Windows.
- Запустите установочный файл.
- Следуйте инструкциям установщика, при этом:
    - Укажите путь для установки.
    - Выберите дополнительные опции, такие как создание ярлыка на рабочем столе и добавление PyCharm в PATH.
- По завершении установки запустите PyCharm и завершите настройку, следуя подсказкам на экране.



2 - Linux
- Загрузите архив для Linux с официального сайта (https://www.jetbrains.com/pycharm/download/)
- Распакуйте архив:
--
tar -xzf pycharm-community-*.tar.gz -C /opt/
----
- Перейдите в директорию, где установлен PyCharm:
--
cd /opt/pycharm-community-*/
----
- Запустите PyCharm:
--
./bin/pycharm.sh
----
- Вы можете создать ярлык или добавить путь к запускаемому файлу, чтобы запускать PyCharm из меню приложений.



3 - macOS
- Скачайте установочный файл с сайта JetBrains (выберите версию PyCharm Community Edition) - 
https://www.jetbrains.com/pycharm/download/
- Откройте загруженный .dmg файл.
- Перетащите значок PyCharm в папку Applications.
- Откройте PyCharm через Finder или из Launchpad.



Создание проекта PyCharm

Чтобы создать первый проект в PyCharm, выполните следующие шаги:



1 - Откройте PyCharm: После запуска PyCharm вы окажетесь на начальном экране. Здесь можно создать новый проект или открыть существующий.



2 - Создание нового проекта:
    - Нажмите кнопку "New Project".
    - В появившемся окне настройте параметры проекта:
        - Location: выберите папку для проекта или оставьте путь по умолчанию. Название проекта должно быть performance-tests.
        - Python Interpreter: укажите интерпретатор Python, который будет использоваться в проекте. Можно выбрать существующий интерпретатор или установить новый, если он не настроен.



3 - Конфигурация интерпретатора:

Если у вас ещё нет интерпретатора Python, нажмите "Add Interpreter" и выберите:
- Virtual Environment: PyCharm создаст виртуальное окружение в папке проекта (рекомендуется для изоляции зависимостей).
- System Interpreter: если у вас установлен Python на системе, выберите его.
- Conda Environment: если используете Anaconda, укажите conda-окружение.



4 - Создание проекта:
- Нажмите "Create". PyCharm создаст проект и автоматически запустит его в основном окне.



5 - Первый файл:
- В панели проекта (справа) нажмите правой кнопкой на корневую папку проекта, выберите New > Python File, назовите файл, например main.py, и нажмите Enter.
- Откройте файл и напишите любой код, например:
--
print("Hello, PyCharm!")
----



6 - Запуск проекта:
- Чтобы запустить скрипт, правой кнопкой мыши кликните по файлу и выберите Run 'main'.
- Результаты выполнения появятся внизу в панели консоли.



запустить файл main.py можно через терминал -
--
python -m main 
---- 



******************************************

3.3 Установка и знакомство с Docker



Знакомство с Docker

и пройти бесплатный курс - 
https://karpov.courses/docker

-


























*********************************************************
*********************************************************
*********************************************************
*********************************************************
*********************************************************

Ссылки:

- Официальный сайт Docker -
https://www.docker.com/

- Вводный туториал по работе с Docker - 
https://www.docker.com/101-tutorial/



Docker — это платформа с открытым исходным кодом, которая позволяет создавать, запускать и управлять изолированными средами, называемыми контейнерами. Контейнеры позволяют упаковать приложение со всеми его зависимостями и запускать его в любой операционной системе, где установлен Docker.

Проще говоря: Docker — это способ «запаковать» приложение вместе со всем необходимым (код, библиотеки, окружение, зависимости), чтобы оно запускалось всегда одинаково в любом месте — на вашем компьютере, в облаке, на сервере.



В чём отличие от виртуальных машин? - 
Характеристика	    - Виртуальная машина (VM)	- Docker (контейнер)
Вес	                  Гигабайты             Сотни мегабайт или меньше
Время запуска	            Минуты	        Секунды
Изоляция	    Полная (собственная ОС)	Изоляция на уровне ОС (ядра)
Производительность  Ниже из-за гипервизора	Почти нативная
Использование ресурсов	    Больше	        Меньше
Развёртывание	            Сложнее	        Быстрее и проще



Как это работает?
Контейнер — это как лёгкая виртуальная машина, но без полноценной операционной системы внутри. Вместо этого, контейнер использует ядро хост-системы, но при этом имеет своё файловое окружение, библиотеки и зависимости.



Компоненты Docker:
- Образы (Images) — это шаблоны контейнеров. Как "снимок" приложения и окружения.
- Контейнеры (Containers) — запущенные экземпляры образов.
- Dockerfile — файл с инструкциями, как собрать образ.
- Docker Engine — основной движок, который управляет контейнерами.



Пример -
Допустим, вы разрабатываете FastAPI-приложение (Python), и оно требует:
- Python 3.11
- Pip-пакеты: FastAPI, SQLAlchemy
- PostgreSQL
- nginx

Вместо того чтобы устанавливать это всё на каждый компьютер вручную, вы пишете Dockerfile, в котором описываете:
--
FROM python:3.11
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "app.py"]
----

Затем запускаете:
--
docker build -t my-fastapi-app .
docker run -p 8000:8000 my-fastapi-app
----

И получаете изолированное приложение, которое можно отправить кому угодно — оно будет работать всегда одинаково.



Где используется Docker -
- Разработка ПО — настройка среды единожды, затем клонирование и запуск за секунды
- CI/CD — автотесты и сборки в однотипных контейнерах
- DevOps и администрирование — лёгкое масштабирование, деплой, мониторинг
- Нагрузочное тестирование — изоляция сервисов, симуляция стендов
- Образовательные курсы — создание преднастроенных окружений



Преимущества Docker -
- Изолированность: каждый контейнер работает независимо
- Повторяемость: приложение запускается одинаково на любой машине
- Быстрая разработка и тестирование: всё можно автоматизировать
- Лёгкость: контейнеры весят гораздо меньше, чем виртуалки
- Гибкость: можно запускать несколько версий одного сервиса параллельно
- Упрощённый деплой: образы можно отправить на сервер, в облако, CI/CD



Сценарии использования в нагрузочном тестировании -

Docker — идеальный инструмент для изоляции:
- Системы, которую нужно нагрузить (например, API-сервер)
- Генераторов нагрузки (Locust, k6 и др.)
- Баз данных (PostgreSQL, Redis, MongoDB)
- Мониторинга (Prometheus, Grafana)

Это особенно важно при создании тестовых стендов, которые должны:
- Быстро разворачиваться
- Не зависеть от окружения разработчика
- Легко масштабироваться



Команды Docker:



1 - Образы (Images)

- docker build
Создаёт Docker-образ из Dockerfile.
--
docker build -t my-image:latest .
----                  
-t — задаёт тег образа (имя:тег).
. — путь к папке с Dockerfile.

- docker pull
Скачивает образ из Docker Hub или другого реестра.
--
docker pull nginx:latest
----

- docker images
Показывает список локальных образов.
--
docker images
----

- docker rmi
Удаляет один или несколько образов.
--
docker rmi my-image:latest
----



2 - Контейнеры (Containers)

- docker run
Создаёт и запускает контейнер из образа.
--
docker run -d -p 8080:80 --name my-nginx nginx
----                  
-d — в фоновом режиме.
-p — пробрасывает порт (host:container).
--name — задаёт имя контейнера.

- docker ps 
Показывает список запущенных контейнеров.
--
docker ps
----
                  
- docker ps -a
Показывает все контейнеры, включая остановленные.
--
docker ps -a
----
                  
- docker stop
Останавливает запущенный контейнер.
--
docker stop my-nginx
----

- docker start
Запускает остановленный контейнер.
--
docker start my-nginx
----
                  
- docker restart
Перезапускает контейнер.
--
docker restart my-nginx
----
                  
- docker rm
Удаляет остановленный контейнер.
--
docker rm my-nginx
----

- docker exec
Выполняет команду внутри запущенного контейнера.
--
docker exec -it my-nginx bash
----                  
-it — интерактивный режим с tty.

- docker logs
Показывает логи контейнера.
--
docker logs my-nginx
----



3 - Тома (Volumes)

- docker volume create
Создаёт том для хранения данных.
--
docker volume create my-volume
----

- docker volume ls
Показывает список томов.
--
docker volume ls
----
                  
- docker volume inspect
Показывает подробную информацию о томе.
--
docker volume inspect my-volume
----
                  
- docker volume rm
Удаляет том.
--
docker volume rm my-volume
----



4 - Сети (Networks)

- docker network create
Создаёт пользовательскую сеть.
--
docker network create my-network
----
                  
- docker network ls
Список сетей.
--
docker network ls
----
                  
- docker network inspect
Информация о сети.
--
docker network inspect my-network
----
                  
- docker network connect
Подключает контейнер к сети.
--
docker network connect my-network my-container
----



5 - Служебные и отладочные команды

- docker inspect
Детальная информация об объекте (контейнере, образе, томе, сети).
--
docker inspect my-container
----
                  
- docker stats
Ресурсы, потребляемые контейнерами в реальном времени (CPU, RAM).
--
docker stats
----
                  
- docker top
Показывает процессы внутри контейнера.
--
docker top my-container
----
                  
- docker info
Общая информация о Docker Engine.
--
docker info
----



6 - Очистка системы

- docker system prune
Удаляет все неиспользуемые контейнеры, образы и сети.
--
docker system prune
----
                  
- docker image prune
Удаляет неиспользуемые образы.
--
docker image prune
----
                  
- docker container prune
Удаляет остановленные контейнеры.
--
docker container prune
----



Docker — ключевой инструмент современной разработки и тестирования. Он помогает вам не «настраивать» всё вручную, а собирать окружение как код, сохранять его, переносить и масштабировать. В курсе мы будем использовать Docker, чтобы запускать тестируемые сервисы, а также имитировать нагрузку в отдельных контейнерах с помощью Locust



Установка Docker

Скачать Docker Desktop - 
https://www.docker.com/products/docker-desktop/
- telegram - избранное - 26.09.2025 (10:21)


1 - Установка Docker на Windows

Шаг 1: Требования
- Windows 10 или 11 с Hyper-V (Pro/Enterprise) или Windows 10/11 Home с WSL2
- Включенная виртуализация в BIOS

Шаг 2: Установка Docker Desktop
- Перейдите на сайт: https://www.docker.com/products/docker-desktop
- Скачайте установщик для Windows
- Запустите установку и следуйте инструкциям:
    - Выберите опцию использовать WSL2 (если Windows Home)
    - Docker установит необходимые компоненты

Шаг 3: Убедитесь, что всё работает
- Откройте PowerShell или терминал:
--
docker --version docker run hello-world
----
- Если выводится сообщение об успешном запуске — всё установлено

Возможные проблемы
- Проверьте, что включен WSL2:
--
wsl --list --verbose
----
- Убедитесь, что установлены Ubuntu или другая дистрибуция через Microsoft Store

Зачем устанавливать WSL для Docker на Windows?
На Windows Docker не может нативно использовать Linux-контейнеры, так как ядро Windows отличается от Linux. Поэтому:
- Docker Desktop использует WSL 2 как виртуализированную среду Linux;
- Именно в ней запускаются образы Linux-контейнеров (а таких — подавляющее большинство).

Почему это важно:
- Без WSL 2 Docker не будет работать с Linux-контейнерами;
- WSL 2 обеспечивает более высокую производительность, чем старый Hyper-V режим;
- С WSL 2 можно напрямую использовать Linux-утилиты в Windows (например, bash, curl, apt и т.п.).

Устанавливается ли WSL автоматически с Docker Desktop?
Да, если вы ставите Docker Desktop с нуля — он:
- Проверит наличие WSL 2;
- Если WSL не установлен — предложит установить его;
- Также скачает Linux-дистрибутив (обычно Ubuntu).



Установка Docker на macOS

Шаг 1: Требования -
- macOS Monterey или новее (M1/M2/M3 и Intel поддерживаются)
- 4+ ГБ RAM, включённая виртуализация

Шаг 2: Установка Docker Desktop
- Перейдите на сайт: https://www.docker.com/products/docker-desktop
- Скачайте .dmg файл
- Откройте и перетащите Docker в папку Программы
- Запустите Docker и разрешите все системные запросы (в т.ч. права на сеть)

Шаг 3: Проверка установки
Откройте терминал:
--
docker --version docker run hello-world
----



Установка Docker на Linux:

1 - Ubuntu/Debian -
--
sudo apt update
sudo apt install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Добавление Docker GPG-ключа
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
    sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# Добавление репозитория
echo \
  "deb [arch=$(dpkg --print-architecture) \
   signed-by=/etc/apt/keyrings/docker.gpg] \
   https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) stable" | \
   sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Установка Docker Engine
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Проверка
sudo docker run hello-world

# (Опционально) Запуск без sudo
sudo usermod -aG docker $USER
newgrp docker
----

2 - CentOS/RHEL -
--
sudo yum install -y yum-utils
sudo yum-config-manager \
    --add-repo https://download.docker.com/linux/centos/docker-ce.repo

sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Запуск и автозапуск
sudo systemctl start docker
sudo systemctl enable docker

# Проверка
sudo docker run hello-world
----

3 - Arch Linux / Manjaro -
--
sudo pacman -Syu docker

# Запуск и автозапуск
sudo systemctl enable docker
sudo systemctl start docker

# Проверка
sudo docker run hello-world
----



Проверка установки на всех ОС
После установки Docker должен быть доступен из командной строки:
--
docker --version docker run hello-world
----
- Успешный запуск hello-world означает, что контейнерная платформа работает.

Рекомендации -
- Обновляйте Docker регулярно через интерфейс (на Windows/macOS) или apt/yum/pacman.
- Используйте команду 
docker info 
для диагностики окружения.

Теперь ваша система готова для запуска стендов, сценариев и тестов с использованием Docker. В курсе дальше мы будем использовать команды docker, docker-compose.

создадим докерфайл в корне нашего проекта и назовем его - Dockerfail - без точек и расширений 

как учебная цель - запустим внутри Docker наш main-скрипт - 
--
main.py
--
def print_hi(name):
    print(f"Hi, {name}")


if __name__ == '__main__':
    print_hi('PyCharm')
----

--
Dockerfail
--
FROM python:3.12
WORKDIR /app
COPY . .
CMD ["python", "main.py"]
----

через терминал запустим команду на сборку - 
--
docker build -t test-docker .
----

через терминал запустим контейнер -
--
docker run test-docker
----
Hi, PyCharm
------

теперь другому человеку можно скинуть этот Dockerfile, он у себя сбилдит образ (Image) и на основании него сможет создавать контейнеры, и изменять, настраивать и запускать их - для этого ему нужно выполнить только 2 команды (которые указаны тут выше) - build и run 

весь код содержится в образе и образ можно опубликовать для сторонних пользователей -
в Docker Desktop - Images - в строке справа нажать на три точки - Push to Docker Hub 

чтобы удалить - сначала нужно удалить все контейнеры, где используется образ, а потом уже можно удалить сам образ 

когда образы и контейнеры не нужны - лучше их удалять, чтобы не занимали память и ресурсы компьютера (сервера)



Практика: работа с Docker - 
В этом задании вы самостоятельно создадите Docker-образ, который будет содержать Python-интерпретатор, необходимые зависимости и скрипт docker_example.py. Такой образ можно запустить в любом окружении как изолированное приложение. Это поможет вам закрепить навыки работы с Docker и понять, как упаковываются скрипты вместе с зависимостями.

Цель задания -
- Научиться писать простой Dockerfile;
- Освоить базовые инструкции: FROM, WORKDIR, COPY, RUN, CMD;
- Понять, как упаковывать Python-программы в контейнеры вместе с зависимостями;
- Научиться собирать и запускать образы через CLI.



Шаги выполнения -
1 - В корне проекта performance-tests создайте файл docker_example.py
2 - В этом файле напишите скрипт, который использует стороннюю Python-библиотеку termcolor для вывода цветного текста:
--
docker_example.py
--
from termcolor import colored

print(colored("Привет из контейнера!", "green"))
----
3 - Далее создайте файл Dockerfile.example в той же директории.
4 - Ваша задача — самостоятельно реализовать содержимое Dockerfile так, чтобы при сборке образа и запуске контейнера скрипт отработал корректно.



Требования к Dockerfile.example - 
Ваша реализация Dockerfile должна соответствовать следующим требованиям:
- Используется образ с Python версии 3.11.
- Устанавливается рабочая директория /app внутри контейнера.
- Весь исходный код (включая docker_example.py) копируется в контейнер.
- Устанавливается библиотека termcolor (с помощью pip).
- Контейнер при запуске выполняет файл docker_example.py.

Как проверить?
После реализации Dockerfile выполните в терминале (из корня проекта):
--
docker build -f Dockerfile.example -t docker-example .
docker run docker-example
----                  
- Если всё сделано правильно, вы увидите сообщение в консоли:
Привет из контейнера!
                
Если ваш терминал не поддерживает цветовой вывод, сообщение всё равно должно отобразиться — это означает, что контейнер работает корректно. Цвет — необязательный визуальный эффект.

Формат сдачи задания
Отправьте код решения в следующем виде:
Dockerfile.example
// Тут ваша реализация Dockerfile

Критерии успешного выполнения задания -
1 - В корне проекта создан файл docker_example.py с указанным кодом
2 - Файл Dockerfile.example реализован и соответствует всем требованиям:
- используется базовый образ Python 3.11. Рекомендуется использовать официальный образ python:3.11 или python:3.11-slim. Не используйте alpine — установка зависимостей может потребовать дополнительных шагов.
- установлена рабочая директория /app
- исходный код скрипта скопирован внутрь контейнера
- выполнена установка библиотеки termcolor
- задана команда запуска скрипта
3 - Команды docker build и docker run выполняются без ошибок
4 - При запуске контейнера в консоль выводится фраза Привет из контейнера!

Мой ответ на задание - 
--
Dockerfile.example 
--
FROM python:3.11-slim
WORKDIR /app
RUN pip install termcolor
COPY . /app
CMD ["python", "docker_example.py"]
----



******************************************

3.4 Установка и знакомство с Docker Compose



Знакомство с Docker Compose

Ссылки:

- Официальная документация Docker Compose -
https://docs.docker.com/compose/

- Вводный туториал по работе с Docker Compose -
https://docs.docker.com/compose/gettingstarted/



Docker Compose — это инструмент, который позволяет описывать и запускать многоконтейнерные приложения в Docker с помощью одного конфигурационного файла -
docker-compose.yml

Когда вы работаете с современными приложениями, часто приходится запускать сразу несколько сервисов: например, веб-сервер, базу данных, очередь сообщений, Redis и т.д. Docker Compose автоматизирует это — запускает все эти компоненты одной командой.

Зачем нужен Docker Compose?
- Автоматизация запуска многоконтейнерной среды.
- Упрощение настройки окружения.
- Описание зависимостей в одном месте (docker-compose.yml).
- Возможность быстро разворачивать и останавливать инфраструктуру.
- Используется в CI/CD, тестировании, разработке.

Пример: из чего состоит проект - Допустим, у нас есть веб-приложение на Python (FastAPI) + PostgreSQL. Чтобы его запустить, нужны:
- Контейнер с FastAPI-приложением.
- Контейнер с PostgreSQL.
- Связь между ними.
- Настройки окружения.
С Docker Compose всё это описывается в одном файле — docker-compose.yml

Пример docker-compose.yml -
--
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgres://user:password@db:5432/appdb
    depends_on:
      - db

  db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: appdb
    volumes:
      - db_data:/var/lib/postgresql/data

volumes:
  db_data:
----



Что здесь происходит:

services - Определяет контейнеры (например, web, db)

build или image - Как собрать контейнер: build из Dockerfile или image из Docker Hub

ports - Пробрасывает порты

environment - Переменные окружения

depends_on - Указывает порядок запуска

volumes - Постоянное хранилище данных (например, для БД)



Команды Docker Compose -

docker compose up	
- Запустить все контейнеры

docker compose down
- Остановить и удалить контейнеры, сеть, тома

docker compose build	
- Сборка образов

docker compose ps	
- Показать состояние контейнеров

docker compose logs	
- Логи всех контейнеров

docker compose exec <service> bash	
- Зайти внутрь контейнера

docker compose restart	
- Перезапустить все сервисы



Примеры использования - 

1. Разработка
Вы можете локально запускать целую инфраструктуру (API + БД + Redis) одной командой:
--
docker compose up --build
----

2. Тестирование
- Тестовые базы данных
- Очереди сообщений (RabbitMQ, Kafka)
- Песочницы для e2e-тестов

3. CI/CD
Docker Compose используется в GitHub Actions, GitLab CI и других пайплайнах для поднятия временного окружения.

4. Нагрузочное тестирование
Сценарий: вы хотите протестировать нагрузку на систему. С помощью Compose можно быстро поднять нужные сервисы (бэкенд, БД, Locust master/worker) и запустить тест.



Сетевые настройки
- Все сервисы внутри docker compose находятся в одной виртуальной сети.
- Вы можете обращаться к другим контейнерам по имени сервиса:
Пример: контейнер web может подключаться к db по адресу db:5432



Версии Docker Compose -
2.x - Устаревшая, но широко используемая
3.x - Совместима с Docker Swarm
3.8 - Рекомендуемая для большинства приложений
v2 - Современная CLI-реализация (docker compose, а не docker-compose)



Плюсы Docker Compose - 
- Простота в использовании
- Идеален для тестирования
- Легко портировать (один файл можно использовать в любой среде)
- Стандартизирует инфраструктуру
- Используется в проде (в малых и средних системах)
- Отличный выбор для обучения



Минусы -
- Не предназначен для масштабирования (лучше использовать Kubernetes)
- Подходит только для одной хост-машины
- Невозможно тонко настраивать отказоустойчивость и балансировку



Docker Compose — мощный инструмент для локальной разработки, тестирования и автоматизации. Он позволяет легко управлять инфраструктурой, упрощает запуск сложных конфигураций и делает проекты предсказуемыми и переносимыми. Если вы планируете запускать тестовые стенды, поднимать микросервисы, разрабатывать распределенные системы или проводить нагрузочное тестирование — Docker Compose вам обязательно пригодится.



Установка Docker Compose

Нужно ли устанавливать Docker Compose вручную?
Нет, в большинстве случаев устанавливать Docker Compose вручную не требуется.
Современные версии Docker (v20.10.13 и выше) уже включают Docker Compose как встроенный плагин. Начиная с Docker Desktop 2.0+ (Windows и macOS), docker compose идёт в комплекте. Вместо старой команды docker-compose теперь используется новая - docker compose (без дефиса)

Как проверить, установлен ли Docker Compose
Откройте терминал и выполните:
--
docker compose version
----                  
Если вы увидите версию, например:
Docker Compose version v2.24.2
               
Значит, всё работает, и устанавливать ничего не нужно.



Важно: старая vs. новая команда
Версия - Команда - Поддержка -
Новая - docker compose - Рекомендуется
Старая - docker-compose - Устаревшая, не развивается



Пример запуска контейнеров:
--
docker compose up
----



Состояние по операционным системам - 
ОС - Нужно ли устанавливать compose? - Как работает -
Windows	- Нет - Встроено в Docker Desktop
macOS - Нет - Встроено в Docker Desktop
Linux - Да, один пакет - sudo apt install docker-compose-plugin



Установка на Linux (если вдруг не установлен)
Если команда docker compose не работает — установите плагин:
--
sudo apt update
sudo apt install docker-compose-plugin
----              
Затем проверьте:
--
docker compose version
----



Нужно ли устанавливать docker-compose (через curl)? - Нет. Это устаревший подход. Старая утилита docker-compose больше не развивается и не рекомендуется к использованию. Используйте docker compose



Краткая проверка -
--
docker --version          # Проверка Docker
docker compose version    # Проверка Compose
----



Итого -
- Устанавливать Docker Compose отдельно не нужно, если у вас современная версия Docker.
- Используйте новую команду docker compose.
- Устаревшую docker-compose лучше больше не использовать.
- На Linux может потребоваться установить плагин: docker-compose-plugin.



установим Redis через терминал - 
--
pip install redis 
----



в папке нашего проекта создадим файл - 
--
docker_compose_basics.py
--
from redis import Redis 

cache = Redis(host = "redis", port=6379)
cache.incr("times", amount=1)
print(cache.get("times"))
----
- port=6379 - это стандартный порт 


создадим новый докерфайл - Dockerfile.redis - 
--
Dockerfile.redis
-- 
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install redis
CMD ["python", "docker_compose_basics.py"]
----



в директории (папке) проекта создадим новый файл - docker-compose.yaml - 
--
docker-compose.yaml
--
version: '3.9'

services:
  script:
    build:
	  context: .
	  dockerfile: Dockerfile.redis 
	  
  redis:
    image: redis:alpine
----
- на 3331 "redis" это то же имя что и на 3363



теперь выполним команду, которая запустит наш докер-компоуз файл - 
--
docker compose up 
----



согласно этих строк - 
--
  redis:
    image: redis:alpine
----
- образ redis выкачался с DockerHub



Практика: работа с Docker Compose -

В этом задании вы самостоятельно создадите Dockerfile и файл docker-compose, которые поднимают два сервиса: простой Python-скрипт и Redis. Вы закрепите навыки настройки многоконтейнерного окружения и взаимодействия сервисов внутри сети docker-compose.

Цель задания -
- Научиться запускать несколько сервисов с помощью docker-compose;
- Освоить взаимодействие Python-приложения с Redis через внутреннюю сеть Compose;
- Повторить создание собственного образа на основе Dockerfile;
- Практически закрепить запуск и отладку контейнеров в составе единого окружения.



Шаги выполнения -

1 - В корне проекта performance-tests создайте файл docker_compose_example.py

2 - Добавьте в файл следующий код:
--
from redis import Redis

cache = Redis(host="redis", port=6379)
cache.set("example", 5)
print(int(cache.get("example")) ** 2)
----
Этот скрипт подключается к Redis-серверу, устанавливает ключ "example" со значением 5 и выводит в консоль квадрат этого значения (25).

3 - Создайте файл Dockerfile.compose-example в корне проекта performance-tests. Этот файл должен:
- использовать образ Python 3.12;
- установить рабочую директорию /app;
- скопировать весь код в контейнер;
- установить зависимость redis с помощью pip;
- запускать docker_compose_example.py при запуске контейнера.

4 - Создайте файл docker-compose.example.yaml в корне проекта performance-tests. В нём опишите два сервиса:
- script — должен собираться из Dockerfile.compose-example;
- redis — должен использовать официальный образ redis:alpine;
- Оба сервиса должны быть в одной сети по умолчанию, чтобы script мог обратиться к Redis по имени хоста redis

5 - Запустите окружение командой:
--
docker compose -f docker-compose.example.yaml up
----
В результате успешного запуска вы должны увидеть в консоли вывод:
25



Критерии успешного выполнения задания -
- В корне проекта создан файл docker_compose_example.py с корректным кодом
- Реализован Dockerfile.compose-example, который:
    - использует Python 3.12 как базовый образ
    - устанавливает рабочую директорию /app
    - копирует проект внутрь контейнера
    - устанавливает библиотеку redis с помощью pip
    - запускает docker_compose_example.py
- Реализован docker-compose.example.yaml, который:
    - поднимает два сервиса: script (собирается из Dockerfile.compose-example) и redis (образ redis:alpine)
	- обеспечивает доступ контейнера script к Redis по адресу redis:6379
- Команда docker compose -f docker-compose.example.yaml up выполняется без ошибок
- В терминале отображается результат 25



Формат сдачи задания -
Отправьте код решения в следующем виде:

Dockerfile.compose-example
// Тут ваша реализация Dockerfile -
FROM python:3.12
WORKDIR /app
COPY . .
RUN pip install redis
CMD ["python", "docker_compose_example.py"]

docker-compose.example.yaml
// Тут ваша реализация Docker Compose -
version: '3.9'

services:
  script:
    build:
      context: .
      dockerfile: Dockerfile.compose-example

  redis:
    image: redis:alpine



******************************************

3.5 Установка и настройка Postman



Знакомство с Postman

Ссылки:

- Официальный сайт Postman -
https://www.postman.com/

- Официальная документация Postman -
https://learning.postman.com/docs/introduction/overview/

- Вводный туториал по работе с Postman -
https://learning.postman.com/docs/getting-started/first-steps/sending-the-first-request/

Postman — это мощный инструмент для разработки, тестирования и анализа API (Application Programming Interface). Изначально он задумывался как расширение для браузера, но со временем вырос в полноценное десктопное и веб-приложение, активно используемое разработчиками, тестировщиками и инженерами по качеству.

Зачем нужен Postman? - Postman позволяет легко отправлять HTTP-запросы к серверу и просматривать ответы. Он крайне полезен на всех этапах разработки и тестирования, в том числе:
- Проектирование API
- Тестирование API (ручное и автоматическое)
- Документирование API
- Мониторинг доступности и корректности API
- Автоматизация сценариев запросов
- Работа с gRPC (начиная с Postman 10+)
- Создание коллекций запросов для использования в нагрузочных инструментах (например, в тестах Locust)



Основные возможности Postman -

- Поддержка различных типов запросов -
    - HTTP: GET, POST, PUT, PATCH, DELETE, и другие
    - gRPC: вызовы RPC-методов, автоформирование запросов на основе proto-файлов
    - WebSocket и Socket.IO
    - GraphQL
	
- Работа с коллекциями -
Вы можете группировать запросы в коллекции, что особенно удобно при работе с разными сценариями и микросервисами

- Переменные и окружения -
Postman поддерживает переменные ({{base_url}}, {{token}}) и окружения (например, dev/test/prod), что помогает повторно использовать конфигурации.

- Тесты и скрипты -
Можно писать JavaScript-код для автоматической проверки ответов, например:
--
pm.test("Status code is 200", function () {
    pm.response.to.have.status(200);
});
----

- Интеграции -
Postman можно интегрировать с:
    - Jenkins и другими CI/CD-системами
    - Newman (CLI для запуска коллекций)
    - GitHub / GitLab / Bitbucket
    - API Gateway, Swagger, и другими платформами
	
- Экспорт / импорт коллекций -
Коллекции можно экспортировать в JSON и импортировать в другие инструменты (например, использовать в автотестах или Locust)

- Авторизация -
Поддержка всех популярных типов:
    - API Key
    - Bearer Token
    - OAuth 2.0
    - Basic Auth



Зачем Postman нужен в нагрузочном тестировании?

1. Проверка API перед нагрузкой -
Перед тем как запускать нагрузку (например, с помощью Locust), вы можете в Postman:
- проверить, что ручки API работают корректно;
- удостовериться в авторизации и доступности;
- убедиться, что ответы сервера соответствуют ожиданиям.

2. Прототипирование сценариев -
Вы можете «набросать» сценарий взаимодействия клиента с API и затем экспортировать его для автоматизации.

3. gRPC-тестирование -
Postman поддерживает gRPC (начиная с версии 10), что делает его удобным инструментом для проверки микросервисов, использующих бинарные протоколы.

4. Отладка - 
В случае ошибок или нестабильной нагрузки, Postman поможет вручную воспроизвести запрос, чтобы выяснить, проблема в тесте или в бэкенде.



Пример использования Postman -
Сценарий: регистрация и авторизация пользователя -
1. Выполнить POST на /api/register с JSON-телом.
2. Получить токен из ответа.
3. Выполнить GET на /api/user/me с авторизацией.
4. Убедиться, что получен корректный профиль.
Вы можете сделать это вручную, затем записать как коллекцию и переиспользовать или автоматизировать.



Почему Postman часто выбирают? -
- Простота интерфейса и обучения
- Поддержка большинства протоколов и форматов
- Активное развитие и поддержка сообщества
- Возможность совместной работы в команде (в Postman Cloud)
- Прекрасно сочетается с Python-стеком и Locust (через экспорт коллекций)



Здесь важно понимать, что Postman выполняет немного другую роль, чем  requests.

Во-первых, для программных обращений к HTTP API в курсе используется HTTPX, а не requests. Это современная асинхронная библиотека, и мы с ней будем работать в коде.

Во-вторых, такие библиотеки — это уже инструмент для автоматизации и написания сценариев. Чтобы ими пользоваться, нужно заранее понимать, как именно должен выглядеть запрос и что сервер возвращает в ответ. А для ручной отладки и экспериментов на ранних этапах удобнее использовать Postman: он позволяет быстро менять параметры, заголовки, тела запросов, видеть структуру ответа, работать с кодами состояния — всё это без написания кода.

И, наконец, самое важное: Postman поддерживает не только HTTP, но и gRPC, включая работу через Server Reflection. Через requests или даже httpx вы с gRPC напрямую не поработаете — для этого нужны другие инструменты. Поэтому Postman в курсе используется как универсальный ручной клиент для проверки и отладки API до того, как мы начнём автоматизировать работу с ними в коде.



Установка Postman

Ссылки:

Скачать Postman -
https://www.postman.com/downloads/



Установка Postman на Windows



Способ 1: Через официальный сайт
- Перейдите на сайт: https://www.postman.com/downloads/
- Выберите версию для Windows (x64) и скачайте .exe установщик - telegram - избранное - 13.10.2025 (20:56)
- Запустите скачанный файл и следуйте инструкциям.
- После установки Postman можно запустить из меню Пуск или ярлыка на рабочем столе.

токен - telegram - избранное - 13.10.2025 (21:56)



Способ 2: Через Winget (если доступен) -
--
winget install --id Postman.Postman -e
----
Winget — менеджер пакетов от Microsoft. Работает в Windows 10 (>= 1809) и Windows 11.



Установка Postman на macOS



Способ 1: Через официальный сайт
- Перейдите на https://www.postman.com/downloads/
- Скачайте .zip архив для macOS.
- Распакуйте архив и перетащите приложение Postman в папку Applications.
- Запустите Postman через Launchpad или Spotlight (Cmd + Space → Postman).



Способ 2: Через Homebrew -
--
brew install --cask postman
----



Установка Postman на Linux



Универсальный способ: Snap (подходит для большинства дистрибутивов) -
--
sudo snap install postman
----
Требуется установленный Snap (обычно есть в Ubuntu, но можно поставить отдельно).



Установка на Debian / Ubuntu -



Способ 1: Snap (предпочтительно)
--
sudo snap install postman
----



Способ 2: Ручная установка из tar.gz
1 - Скачайте архив с официального сайта, выбрав версию для Linux.

2 - Распакуйте архив:
--
tar -xvzf Postman-linux-x64.tar.gz
----

3 - Переместите в системную папку (по желанию):
--
sudo mv Postman /opt/Postman
----

4 - Добавьте ярлык (опционально):
Создайте файл postman.desktop:
--
sudo nano /usr/share/applications/postman.desktop
----

И вставьте:
--
[Desktop Entry]
Name=Postman
Exec=/opt/Postman/Postman
Icon=/opt/Postman/app/resources/app/assets/icon.png
Type=Application
Categories=Development;
----



Установка на Fedora



Способ 1: Snap
--
sudo dnf install snapd
sudo ln -s /var/lib/snapd/snap /snap
sudo snap install postman
----



Способ 2: Flatpak (если Snap не нравится)
--
flatpak install flathub com.getpostman.Postman
flatpak run com.getpostman.Postman
----



Установка на Arch Linux
--
yay -S postman-bin
----
Или используйте paru, если он у вас установлен



Проверка установки - После установки:

1 - Откройте Postman
2 - Убедитесь, что открывается окно приложения
3 - Проверьте версию:
- Через меню: Help → About
- Либо через командную строку, если установлен через Snap:
​--
snap info postman
----



******************************************

4.1 Начало работы с Git



Знакомство с Git

Ссылки:

- Официальный сайт Git -
https://git-scm.com/

- Игра Learn Git Branching для изучения Git -
https://learngitbranching.js.org/?locale=ru_RU

- Документация на случай, если что-то пошло не так -
https://dangitgit.com/ru
то же самое, с ненормативной лексикой - 
https://ohshitgit.com/ru



Важно! Я настоятельно рекомендую вам пройти интерактивную игру Learn Git Branching (ссылка выше) для изучения принципов работы с Git. Перейдите по ссылке и пройдите игру полностью, вдумчиво читайте теорию и подсказки. Без завершения этого обучения я не рекомендую переходить к следующим шагам - 

курс Learn Git Branching - скриншоты в телеграм - мой канал my_git 



Что такое Git?

Git — это распределенная система контроля версий, которая позволяет разработчикам отслеживать изменения в коде, работать над проектами совместно и управлять различными версиями файлов. Git был создан Линусом Торвальдсом в 2005 году и с тех пор стал одним из самых популярных инструментов для управления исходным кодом.



Основные характеристики Git

Контроль версий: Git хранит историю изменений, что позволяет разработчикам возвращаться к предыдущим версиям кода, если это необходимо. Каждое изменение фиксируется и сопровождается сообщением, описывающим суть изменений.

Распределенность: В отличие от централизованных систем, таких как SVN, в Git каждый разработчик имеет полную копию репозитория на своем компьютере. Это позволяет работать без постоянного подключения к сети и ускоряет процесс работы.

Работа с ветками: Git позволяет создавать ветки (branches) для разработки новых функций или исправления ошибок, не затрагивая основную (master или main) ветку проекта. Это облегчает управление разными направлениями разработки и упрощает слияние изменений.

Слияние (merge): Git предоставляет мощные инструменты для слияния изменений из разных веток. Это позволяет командам эффективно работать над одной и той же кодовой базой, избегая конфликтов.

Поддержка коллаборации: Git позволяет множеству разработчиков одновременно работать над проектом. Благодаря системе контроля версий, каждый может вносить изменения и интегрировать их в общий проект.



Зачем нужен Git?

Отслеживание изменений: Git позволяет легко отслеживать и документировать изменения в коде. Это полезно для анализа, почему были внесены те или иные изменения.

Управление проектами: С помощью Git можно управлять большими проектами, организовывая код в ветках и фиксируя важные версии (релизы).

Обратимость изменений: Если что-то пошло не так, Git позволяет быстро вернуть код к предыдущему состоянию.

Совместная работа: Git обеспечивает эффективное сотрудничество между разработчиками, позволяя работать над одной кодовой базой без конфликтов.

Интеграция с CI/CD: Git интегрируется с различными системами непрерывной интеграции и доставки (CI/CD), что позволяет автоматизировать тестирование и развертывание приложений.



Что такое ветка в Git?

Ветка (branch) в Git — это отдельная "линия" разработки в проекте, которая позволяет вносить изменения в код без воздействия на основную версию проекта. Ветки дают возможность работать над разными задачами (например, новыми функциями, исправлением ошибок или экспериментами) независимо друг от друга. При этом изменения из одной ветки можно сливать с другими ветками, когда работа будет завершена.



Принципы работы с ветками

1 - Изоляция изменений: Ветки позволяют изолировать изменения. Например, основная ветка (master или main) может оставаться стабильной, в то время как разработка новых функций или тестирование изменений выполняется в отдельной ветке.

2 - Совместная работа: Каждый разработчик может работать в своей ветке и затем сливать свои изменения с другими, избегая конфликтов в коде. Это удобно для командной работы, так как изменения не мешают работе других участников.

3 - Упрощение версионного контроля: Ветки позволяют легко вернуться к предыдущим версиям проекта, тестировать изменения и откатывать их при необходимости.



Зачем нужны ветки?

1 - Изоляция работы: Вы можете работать над несколькими задачами одновременно, не мешая друг другу.

2 - Безопасное тестирование: Ветки позволяют тестировать экспериментальные функции или изменения, не затрагивая основную версию кода.

3 - Эффективное управление проектом: Ветки позволяют быстро переключаться между задачами и легко интегрировать готовые изменения в основной проект.



Что такое ветка master в Git?

В Git основная ветка, которая обычно называется master (в некоторых проектах она переименована в main), представляет собой "главную" или "основную" версию вашего проекта. Эта ветка используется для хранения стабильной версии кода, которая готова к развертыванию или публикации.



Основные характеристики ветки master:

1 - Стабильная версия: Ветка master должна содержать код, который проходит все тесты и работает без ошибок. Это позволяет командам легко развертывать именно эту версию кода.

2 - Отправная точка: Ветка master служит отправной точкой для создания других веток. Разработчики могут создавать новые ветки от master, чтобы работать над новыми функциями или исправлениями ошибок.

3 - Слияние изменений: После завершения работы над функцией или исправления ошибки, изменения из соответствующей ветки обычно сливаются обратно в master, чтобы обновить основную версию кода.



Что такое коммит?

Коммит в Git — это "снимок" текущего состояния файлов в проекте. Коммиты позволяют разработчикам фиксировать изменения в коде, создавая своего рода "контрольные точки". Это важный механизм, позволяющий отслеживать, какие изменения были внесены и почему. Каждый коммит сопровождается сообщением, описывающим суть изменений, что делает историю проекта понятной и прозрачной.


Основные особенности коммита

1 - История изменений: Коммиты образуют цепочку изменений в проекте, где каждый новый коммит добавляется поверх предыдущих. Это позволяет легко отслеживать, что изменилось с течением времени.

2 - Уникальный идентификатор: Каждый коммит имеет уникальный идентификатор (хеш) — длинное строковое значение, например a1b2c3d, которое Git использует для точной идентификации изменений.

3 - Сообщение коммита: Каждое изменение сопровождается сообщением, которое поясняет, что было изменено и зачем. Хорошая практика — писать четкие и содержательные сообщения коммитов, чтобы другие разработчики могли понять суть изменений.

4 - Независимость от других изменений: Каждый коммит независим, поэтому вы можете вернуться к конкретному коммиту в любой момент и восстановить состояние проекта на тот момент.



Схема работы с ветками в Git

Git использует ветки для параллельной работы над функциональностью без риска повредить основную стабильную версию проекта. Главная ветка обычно называется master (или main), а для новых задач создаются отдельные ветки, например new-feature.

Вот простая схема, показывающая, как это работает:
--
A---B---C           (master)
         \
          D---E---F (new-feature)
----
Объяснение:
- A, B, C — это последовательные коммиты в основной ветке master.
- От коммита C создаётся новая ветка new-feature.
- В этой ветке ведётся разработка новой функциональности, и появляются коммиты D, E, F.

После завершения работы ветка new-feature сливается обратно в master, и история объединяется:
--
A---B---C--------M   (master)
         \      /
          D----E----F (new-feature)
----
- M — это merge-коммит, в котором объединяются изменения обеих веток.
- Теперь все новые изменения из new-feature стали частью основной ветки.

Такой подход позволяет безопасно вести разработку новых функций, исправлений и экспериментов, не нарушая стабильность основной версии проекта.



Установка Git



Установка Git на Windows - 

1 - Скачайте установочный файл:
- Перейдите на официальный сайт Git для Windows и загрузите последнюю версию.

2 - Запустите установку:
- Откройте загруженный установочный файл и следуйте инструкциям на экране.
- В процессе установки оставьте настройки по умолчанию. Они подходят для большинства случаев.

3 - Настройка среды PATH:
- При установке вы увидите несколько вариантов настройки PATH. Рекомендуется выбрать "Git from the command line and also from 3rd-party software", чтобы Git был доступен как в командной строке Windows, так и в других инструментах.

4 - Выберите текстовый редактор:
- Git предложит выбрать текстовый редактор по умолчанию для редактирования сообщений коммитов. По умолчанию Git предлагает Vim, но вы можете выбрать любой удобный редактор, например VS Code или Notepad++.

5 - Проверьте установку:
- Откройте командную строку (нажмите Win + R, введите cmd, нажмите Enter).
Введите команду:
--
git --version
----                 
Если всё установлено правильно, вы увидите версию Git.



Установка Git на Linux -

Git обычно доступен в репозиториях Linux, поэтому установить его можно через менеджер пакетов.

1 - Установите Git:

- Для Ubuntu/Debian:
--
sudo apt update
sudo apt install git
----

- Для CentOS/Fedora:
--
sudo dnf install git
----

- Для Arch Linux:
--
sudo pacman -S git
----

Проверьте установку:
- Введите команду:
--
git --version
----
Убедитесь, что Git установлен, и отобразилась его версия.



Установка Git на macOS

На macOS можно установить Git несколькими способами:

1 - Через Xcode Command Line Tools (рекомендуется):
- Откройте терминал и выполните команду:
--
xcode-select --install
----
Появится запрос на установку инструментария командной строки Xcode. Подтвердите его и дождитесь завершения установки.

2 - Через Homebrew:
- Если у вас установлен Homebrew, установите Git командой:
--
brew install git
----

3 - Проверка установки:
- В терминале введите:
--
git --version
----                 
Должна отобразиться версия Git.



Основные команды Git:


Начальные настройки - 
Перед началом работы с Git важно выполнить начальные настройки, чтобы Git мог идентифицировать пользователя.
--
# Установка имени пользователя
git config --global user.name "Ваше Имя"

# Установка email
git config --global user.email "ваш.email@example.com"

# Проверка текущих настроек
git config --list
----
Важно! Сейчас данные команды выполнять не нужно, с ними необходимо просто ознакомиться и знать об их существовании


1. Инициализация нового репозитория -
--
git init
----
Команда инициализирует новый локальный репозиторий в текущей папке, добавляя скрытую папку .git, которая будет хранить все изменения и коммиты проекта.


2. Клонирование существующего репозитория -
--
git clone <URL-репозитория>
----
Команда клонирует существующий репозиторий с сервера или другой машины на локальный компьютер. Она копирует все файлы и историю изменений.


3. Добавление файлов в индекс -
--
git add <имя_файла>
----
Эта команда добавляет указанный файл в индекс (или staging area) — временное хранилище перед коммитом.
--
git add .
----
С добавлением . все файлы, изменённые или новые, будут добавлены в индекс.


4. Создание коммита -
--
git commit -m "Сообщение коммита"
----
Коммит фиксирует изменения, которые были добавлены в индекс, в историю проекта. Сообщение коммита должно быть кратким и описывать суть изменений.


5. Просмотр состояния репозитория -
--
git status
----
Эта команда отображает текущие изменения, которые ещё не закоммичены, а также информацию о том, какие файлы находятся в индексе или были изменены.


6. Просмотр истории коммитов -
--
git log
----
git log выводит список коммитов в репозитории с указанием авторов, дат и сообщений. Для более краткого вывода можно использовать:
--
git log --oneline
----


7. Сравнение изменений -
--
git diff
----
Команда git diff показывает различия между текущей версией файлов и последним коммитом. Полезно для анализа изменений перед коммитом.


8. Отмена изменений -
--
git checkout -- <имя_файла>
----
Эта команда отменяет изменения в файле, возвращая его к состоянию последнего коммита. Она полезна, если вы случайно изменили файл и хотите вернуть его оригинальное содержимое из текущей ветки.

Начиная с Git 2.23, была введена новая команда:
--
git restore <имя_файла>
----
Она делает то же самое и считается более современной и наглядной альтернативой. Оба варианта рабочие, вы можете использовать любой в зависимости от версии Git и привычки.

Если вы уже добавили файл в индекс (git add), и хотите отменить это — используйте:
--
git reset <имя_файла>
----
Эта команда уберёт файл из staging-области, но не изменит его содержимое в рабочей директории.

Таким образом:
--
restore/checkout -- — откатывают изменения в файле
reset — откатывает добавление в индекс
----


9. Работа с удалённым репозиторием -

--
git remote add origin <URL-репозитория>
----
- Добавляет ссылку на удалённый репозиторий с именем origin.

--
git push origin <ветка>
----                 
- Отправляет все коммиты из указанной ветки (например, main) в удалённый репозиторий.

--
git pull origin <ветка>
----
- Загружает изменения из указанной ветки удалённого репозитория и объединяет их с текущей веткой.


10. Создание и переключение веток -

--
git branch <имя_ветки>
----
- Создаёт новую ветку.

--
git checkout <имя_ветки>
----
- Переключает вас на другую ветку.

--
git checkout -b <имя_ветки>
----
- Команда, объединяющая создание и переключение на новую ветку.


11. Объединение веток -

--
git merge <имя_ветки>
----
- Объединяет изменения из указанной ветки в текущую ветку. Используется для слияния результатов работы разных разработчиков или задач.


12. Удаление веток -

--
git branch -d <имя_ветки>
----
- Удаляет локальную ветку. Будьте осторожны: перед удалением убедитесь, что вам не нужны данные из этой ветки.


Мы рассмотрели основные команды Git, которые нужны для управления версиями и работы с репозиториями. Для успешного использования Git в командной работе важно регулярно практиковаться, а также помнить о хорошем описании коммитов и соблюдении порядка работы с ветками.



Понятия - 

- репозиторий 

- ветка (main, master и т.д.)

- в GitHub - pull request, в GitLab - merge request

- коммит - это слепок текущего состояния проекта 



******************************************

4.2 Публикация проекта на GitHub



Ссылки:

Официальный сайт GitHub -
https://github.com/

Пример репозитория с кодом -
https://github.com/Nikita-Filonov/sample_api_testing



В этом уроке мы познакомимся с платформой GitHub и научимся публиковать проекты на ней. Мы создадим репозиторий для нашего проекта performance-tests и загрузим его на GitHub, чтобы иметь централизованное хранилище кода и вести отслеживание всех изменений



Основные аспекты и функции GitHub:

1 - Хостинг репозиториев: GitHub хранит исходный код, историю изменений и обеспечивает удобный доступ к ним для команды или широкого круга пользователей. Он поддерживает как публичные (доступные всем), так и частные репозитории.

2 - Контроль версий с помощью Git: GitHub позволяет следить за изменениями кода, видеть его историю, восстанавливать прошлые версии и слияния (merge) веток. Это облегчает ведение проектов, позволяя организовать работу в команде без конфликта версий.

3 - Совместная работа:
- Pull Requests (PR): механизм, который позволяет предложить изменения в коде, обсудить их и объединить с основным кодом при одобрении.
- Issues: система для отслеживания задач, ошибок и улучшений, которые нужны проекту. Это удобно для планирования и организации.
- Code Review: участники проекта могут просматривать и комментировать код до его объединения, что способствует поддержанию высокого качества.
GitHub Actions: встроенная система CI/CD, с помощью которой можно автоматизировать тестирование, сборку и развертывание приложений.

4 - GitHub Pages: функция для создания и хостинга статических веб-страниц прямо из репозиториев, что позволяет быстро делиться документацией, сайтами проектов и другими материалами.

5 - Социальная составляющая: GitHub обладает элементами социальной сети для разработчиков. На платформе можно подписываться на проекты, ставить звезды (Stars) понравившимся репозиториям, создавать форки (Forks) чужих проектов и предлагать свои улучшения.

6 - Безопасность и контроль доступа: GitHub позволяет настраивать права доступа для участников проектов, а также включает автоматическое сканирование кода для поиска уязвимостей.



GitHub — это популярная веб-платформа для управления версиями кода и совместной разработки, построенная на основе системы контроля версий Git. Она предоставляет хостинг для репозиториев Git и множество инструментов для управления проектами, что делает её популярной среди разработчиков и команд.



Создаем репозиторий на GitHub

В этом уроке мы создадим репозиторий для проекта performance-tests на GitHub, чтобы впоследствии вести контроль версий и отслеживать изменения в проекте.


1. Регистрация на GitHub
Первое, что необходимо сделать, — зарегистрироваться на GitHub. Перейдите по ссылке https://github.com/signup и следуйте инструкции для регистрации. При этом обязательно запомните указанные при регистрации электронный адрес, пароль и имя пользователя.

Подтверждение регистрации: для завершения регистрации потребуется решить простую задачу, чтобы подтвердить, что вы не робот.

Подтверждение электронной почты: на указанный электронный адрес придет письмо с кодом. Введите этот код в поле подтверждения на сайте.

Выбор плана: после подтверждения вам нужно будет авторизоваться, используя имя пользователя и пароль. Когда будет предложено выбрать план, выберите Free.

После выбора плана вы окажетесь на главной странице GitHub. Регистрация завершена!


2. Создание репозитория
Переход к созданию репозитория: на главной странице нажмите кнопку Create repository.

Настройка репозитория:
- В поле Repository name введите название performance-tests.
- Выберите видимость репозитория: Public.
- Остальные настройки оставьте без изменений. Всё должно соответствовать примеру на изображении ниже.

Завершение создания репозитория: нажмите кнопку Create repository. Репозиторий будет создан, и вы попадете на его страницу, которая пока еще пустая.

На странице нового репозитория найдите блок …or push an existing repository from the command line. Эти команды помогут синхронизировать локальный проект performance-tests с созданным удаленным репозиторием -
--
git remote add origin https://github.com/......../perfomance-tests.git
git branch -M main 
git push -u origin main
----

Теперь регистрация на GitHub и создание репозитория завершены, и наш проект готов для дальнейшей работы



Синхронизируем проект performance-tests с репозиторием GitHub


Ссылки:

Настройки персональных токенов -
https://github.com/settings/tokens

Инструкция по работе с персональными токенами -
https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens


Теперь нам необходимо синхронизировать локальный проект performance-tests с удалённым репозиторием на GitHub.

1. Инициализация Git-репозитория -
Выполните следующую команду в корневой папке проекта performance-tests, чтобы инициализировать репозиторий:
--
git init
----

2. Настройка имени пользователя и электронной почты
Перед началом работы необходимо настроить Git, указав имя пользователя и email:
--
git config --global user.name "<Ваше имя пользователя на GitHub>"
git config --global user.email "<Ваш электронный адрес на GitHub>"
----

3. Добавление удалённого репозитория
Установите ссылку на ваш репозиторий на GitHub:
--
git remote add origin <Ссылка на репозиторий performance-tests>
----
                 
Для проверки успешной установки выполните:
--
git remote -v
----

4. Создание первого коммита
Проверьте текущие изменения в репозитории:
--
git status
----

Добавьте все файлы в индекс:
--
git add .
----

Убедитесь, что файлы добавлены:
--
git status
----

Создайте коммит с описанием:
--
git commit -m "Initial commit"
----

Проверьте, что коммит создан:
--
git log
----

5. Публикация изменений в удалённый репозиторий

Создайте ветку main, если она ещё не создана:
--
git branch -M main
----

Перед публикацией изменений и выполнением команды git push необходимо авторизоваться в GitHub с использованием персонального токена. Без этого опубликовать изменения в удалённый репозиторий не получится.

Перейдите в раздел Developer Settings и нажмите Generate new token.
Это действие приведёт вас на страницу создания нового токена, как показано на скриншоте

Введите название токена. Название должно кратко отражать назначение токена. Оно не влияет на функциональность, но помогает в будущем идентифицировать токен и избежать случайного удаления. Например, вы можете назвать токен performance-tests или MyProjectToken

Установите срок действия токена (Expiration). Рекомендуется выбрать значение No expiration, чтобы токен не имел срока действия. Если вы установите дату истечения срока действия, то после этой даты токен перестанет работать, и придётся создавать новый. Чтобы избежать подобных неудобств, всегда выбирайте No expiration, особенно для токенов, которые используются для длительных проектов.

Предоставьте права токену. Для этого выберите все необходимые права, отметив соответствующие чекбоксы. Это действие позволяет токену иметь доступ ко всем функциям, которые могут понадобиться для работы с вашим проектом, как показано на скриншоте

Нажмите кнопку Generate token в самом низу страницы, чтобы завершить процесс создания токена

После генерации токена он будет отображён только один раз. Обязательно скопируйте его и сохраните в надёжном месте, так как после перезагрузки страницы вы больше не сможете увидеть его. Если токен будет утерян, его потребуется создать заново

После успешного создания токена выполните команду:
--
git push -u origin main
----

После выполнения команды git push откроется окно авторизации GitHub. Если окно не появилось, выполните команду повторно. В окне авторизации:
- Выберите вкладку Token.
- В поле Personal access token введите токен, который вы сгенерировали ранее.

На скриншоте ниже показано, как выглядит окно авторизации и куда вводить токен

После ввода токена нажмите кнопку Sign in. После успешной авторизации изменения будут опубликованы в удалённый репозиторий на GitHub



Что делать, если окно авторизации GitHub не открылось на Windows?
При выполнении команды:
--
git push -u origin main
----
иногда окно ввода токена GitHub на Windows не появляется автоматически

1. Проверьте, установлен ли Git Credential Manager
Откройте PowerShell или Git Bash и выполните:
--
git credential-manager-core --version
----

Если команда не найдена — установите Git Credential Manager:
--
winget install GitHub.GitCredentialManager
----
или переустановите Git с включенной опцией «Git Credential Manager».

2. Откройте окно авторизации вручную
Выполните:
--
git credential-manager-core store
----
После этого появится то же окно, что и при git push. Выберите вкладку Token и вставьте ваш Personal Access Token.

3. Если окно всё равно не появляется
Можно добавить токен без окна (резервный способ):
--
git config --global credential.helper store
git push https://<USERNAME>@github.com/<USERNAME>/<REPO>.git
----
Когда появится запрос пароля — вставьте токен вместо пароля. Git сохранит данные, и вводить их снова не потребуется.



команды для добавления репозитория и связи с репозиторием в github.com - 
--
git init 
git config --global user.name "OlSiv"
git config --global user.email "sojmoscow@gmail.com"
git remote add origin https://github.com/OlSiv/perfomance-tests.git 
git remote -v
git status
git add .
git status
git commit -m "Initial commit" (для самого первого коммита)
git log 
git branch -M main (создадим новую ветку main)
создать на github бессрочный токен (Settings - Developer settings - Personal access tokens - Tokens(classic) - Generate new token - Generate new token(classic) + проставить галочки во всех квадратах и нажать "Generate token" - обязательно сохранить токен у себя в надежном месте)
git push -u origin main
при необходимости ввести имя пользователя github и токен
exit 
----



******************************************

4.3 Работа с GitHub Desktop



Что такое GitHub Desktop?



Ссылки:

Официальный сайт GitHub Desktop -
https://github.com/apps/desktop?ref_cta=download+desktop&ref_loc=installing+github+desktop&ref_page=docs

Скачать GitHub Desktop -
https://desktop.github.com/download/



GitHub Desktop — это официальное бесплатное приложение от GitHub, которое предоставляет удобный графический интерфейс (GUI) для работы с Git и GitHub. Оно упрощает управление репозиториями для пользователей, которые не хотят или не умеют работать с Git через командную строку. GitHub Desktop доступен для операционных систем Windows и macOS и предназначен как для новичков, так и для опытных разработчиков, которым нужен более визуальный подход к работе с кодом.



Зачем нужен GitHub Desktop?

GitHub Desktop помогает пользователям выполнять задачи, связанные с управлением версиями кода, с минимальными усилиями и без необходимости запоминать команды Git. Основные преимущества использования GitHub Desktop:

1 - Упрощённая работа с Git
GitHub Desktop делает доступными основные функции Git через графический интерфейс, такие как:
- Создание репозиториев.
- Клонирование (копирование) удалённых репозиториев на локальный компьютер.
- Управление ветками (branches).
- Создание, просмотр и применение коммитов.
- Отправка изменений в удалённый репозиторий (push).
- Получение изменений из удалённого репозитория (pull).
- Разрешение конфликтов при слиянии (merge conflicts).

2 - Поддержка GitHub-репозиториев
Приложение оптимизировано для работы с GitHub, предоставляя быстрый доступ к репозиториям, созданным на платформе. Это особенно удобно для пользователей, которые часто работают с GitHub и его функциональностью, такой как pull requests и issues.

3 - Повышение продуктивности для начинающих
Пользователи, которые ещё не освоили команды Git, могут сразу приступить к работе с системой контроля версий, используя понятный интерфейс. Это снижает порог входа для новичков.

4 - Визуализация изменений
GitHub Desktop предоставляет удобные инструменты для:
- Просмотра изменений в коде (diff).
- Отслеживания истории коммитов.
- Сравнения разных веток.

5 - Удобное разрешение конфликтов
При слиянии веток (merge) приложение упрощает процесс выявления и устранения конфликтов, предоставляя понятные подсказки и инструменты.

6 - Поддержка совместной работы
GitHub Desktop интегрируется с функциями GitHub, такими как pull requests и issues, что упрощает взаимодействие между членами команды.

7 - Кроссплатформенность
Приложение работает на Windows и macOS, позволяя командам использовать единый инструмент независимо от операционной системы.



Основные функции GitHub Desktop

1 - Клонирование репозиториев
Позволяет легко загрузить копию существующего репозитория с GitHub на локальный компьютер для работы.

2 - Создание коммитов
Приложение позволяет добавлять изменения в коммит и прикреплять описания через интуитивный интерфейс.

3 - Работа с ветками -
- Создание новых веток.
- Переключение между ветками.
- Удобное слияние веток (merge).

4 - Синхронизация с удалённым репозиторием -
- Отправка изменений (push).
- Получение новых изменений (pull) и обновление локального репозитория.

5 - Интеграция с GitHub
Поддерживает функциональность pull requests, позволяя просматривать и обсуждать изменения в коде.

6 - Просмотр изменений
Подсвечивает разницу между текущей версией файла и его предыдущей версией.



Когда использовать GitHub Desktop?

1 - Новичкам в Git
Если вы только начинаете изучать Git и GitHub, GitHub Desktop станет отличным инструментом для выполнения базовых операций без необходимости изучать команды в терминале.

2 - Для визуализации работы
Программисты, которые предпочитают видеть изменения в графическом формате, найдут GitHub Desktop полезным.

3 - При работе с GitHub
GitHub Desktop идеально подходит для пользователей, которые активно используют GitHub для управления проектами.

4 - Для небольших проектов или индивидуальной работы
GitHub Desktop удобен для локальной работы с репозиториями, особенно если вы работаете без сложных сценариев, таких как конфигурация CI/CD.



Ограничения GitHub Desktop

- Приложение не поддерживает все функции Git, такие как управление подмодулями (submodules) или настройка сложных сценариев, требующих редактирования конфигурационных файлов.
- Работает только с репозиториями, основанными на Git.
- Подходит больше для небольших и средних проектов, а для крупных командных проектов опытные разработчики могут предпочесть командную строку или интеграцию с IDE.

GitHub Desktop — это полезный инструмент для упрощения работы с Git и GitHub, который особенно ценен для начинающих разработчиков или тех, кто предпочитает работать с системой контроля версий через графический интерфейс.



Инструкции по установке GitHub Desktop



Скачивание GitHub Desktop -
1 - Перейдите на официальный сайт GitHub Desktop: https://desktop.github.com/download/.
2 - Нажмите кнопку Download for Windows или Download for macOS, в зависимости от вашей операционной системы.



Установка на Windows

Шаг 1. Запуск установщика
- Откройте скачанный файл установщика, обычно он называется GitHubDesktopSetup.exe (telegram - избранное - 03.11.2025 (21:02))
- В открывшемся окне установщика дождитесь завершения процесса установки. GitHub Desktop автоматически установится на ваш компьютер без необходимости дополнительной настройки.

Шаг 2. Первый запуск
- После завершения установки GitHub Desktop автоматически запустится. Если этого не произошло, найдите приложение в меню Пуск или через поиск в Windows.
- При первом запуске вам будет предложено:
-- Авторизоваться в вашей учётной записи GitHub. Нажмите Sign in to GitHub.com и введите данные для входа (логин и пароль). Если у вас ещё нет аккаунта, создайте его по ссылке https://github.com/signup.
-- При необходимости ввести код подтверждения, отправленный на вашу электронную почту.

Шаг 3. Настройка приложения
- Выберите предпочтительный редактор кода (например, Visual Studio Code) из списка.
- Настройте параметры по умолчанию для работы с репозиториями:
-- Укажите, где будут храниться локальные копии ваших репозиториев.
-- Выберите опцию для автоматической отправки анонимных данных об использовании приложения, если хотите (опционально).



Установка на macOS

Шаг 1. Запуск установщика -
- Откройте скачанный файл, который будет называться GitHubDesktop.zip.
- После распаковки вы увидите приложение GitHub Desktop. Перетащите его в папку Applications (Программы), чтобы установить.

Шаг 2. Первый запуск -
- Перейдите в папку Applications и запустите приложение GitHub Desktop.
- macOS может запросить разрешение на открытие приложения, так как оно было загружено из интернета. Нажмите Open.
- При первом запуске вам будет предложено:
-- Авторизоваться в вашей учётной записи GitHub. Нажмите Sign in to GitHub.com и введите данные для входа (логин и пароль). Если у вас ещё нет аккаунта, создайте его по ссылке https://github.com/signup.
-- Ввести код подтверждения, отправленный на вашу электронную почту, если включена двухфакторная аутентификация.

Шаг 3. Настройка приложения -
- Выберите предпочтительный редактор кода (например, Visual Studio Code или Xcode).
- Укажите местоположение для хранения локальных копий ваших репозиториев.
- Настройте отправку анонимных данных об использовании приложения (опционально).



Проверка установки

1 - Убедитесь, что GitHub Desktop установлен:
- На Windows: найдите приложение в меню Пуск или через поиск.
- На macOS: найдите приложение в папке Applications или через поиск Spotlight.

2 - Запустите GitHub Desktop и убедитесь, что можете:
- Авторизоваться в GitHub.
- Подключиться к существующему репозиторию или создать новый.



Обязательно нужно научиться выполнять команды git через терминал!



******************************************

5.1 Установка и настройка тестового стенда



Установка и настройка тестового стенда

Что мы делаем в этом уроке? - Для прохождения курса мы будем использовать заранее подготовленный тестовый стенд, эмулирующий работу микросервисной банковской платформы. Он разворачивается с помощью Docker Compose и содержит множество компонентов: базы данных, API-сервисы, мониторинг и другое.

В этом уроке мы:
1 - Склонируем проект с GitHub
2 - Настроим виртуальное окружение Python
3 - Установим зависимости
4 - Запустим стенд через docker-compose
5 - Убедимся, что всё работает



Важно: ресурсоёмкость стенда - Стенд включает более 20 контейнеров: микросервисы, базы данных, миграторы, мониторинг (Grafana, Prometheus, cAdvisor), S3-хранилище (MinIO) и прочее.

Это потребляет заметное количество ресурсов. При запуске возможно:
- Повышенная нагрузка на процессор и оперативную память
- Шум вентиляторов (у ноутбуков)
- Временные подтормаживания
Если у вас менее 8 ГБ оперативной памяти — рекомендуется закрыть браузеры и лишние приложения перед запуском.



Что должно быть установлено до начала? - Перед началом убедитесь, что у вас установлены:

Git -
git --version

Python 3.12 и выше -
python --version

Docker -
в окне поиска - docker

Docker Compose (встроен в Docker Desktop) -
+

Рекомендуется: Postman для ручной проверки API -
как работать с браузерной версией - telegram - избранное - 04.11.2025 (15:03)
postman.com 



Если чего-то не хватает — вернитесь к предыдущим шагам курса и установите недостающие компоненты.



Шаг 1. Клонируем репозиторий проекта

Откройте терминал (или командную строку / PowerShell)
перейди сюда - C:\my_\my_p\
и выполните:
--
git clone https://github.com/Nikita-Filonov/performance-qa-engineer-course.git
cd performance-qa-engineer-course
----
После этого вы должны оказаться внутри папки проекта



потом я перекинул этот проект в свой github - 
https://github.com/OlSiv/performance-qa-engineer-course.git



Шаг 2. Настраиваем виртуальное окружение Python

Создадим изолированное окружение, чтобы не устанавливать зависимости глобально.
--
python -m venv venv
----

Активируем окружение:

Windows:
--
venv\Scripts\activate
----

Mac/Linux:
--
source venv/bin/activate
----

Вы должны увидеть префикс (venv) в терминале.



Шаг 3. Устанавливаем зависимости Python

Убедитесь, что вы внутри виртуального окружения. Затем выполните:
--
pip install -r requirements.txt
----

Это установит все зависимости, необходимые для автотестов, генерации данных и взаимодействия с API.



Шаг 4. Запускаем окружение с помощью Docker Compose

Перед тем как запустить тестовый стенд, необходимо собрать базовый Docker-образ, от которого зависят остальные сервисы.

1 -- Сборка базового образа
Выполните следующую команду из корня проекта:
--
docker build -f Dockerfile.base -t base-service .
----

Что делает эта команда:

   -f Dockerfile.base — указывает, что используется Dockerfile.base, а не стандартный Dockerfile.
   
   -t base-service — задаёт имя (тег) для собираемого образа.
   
   . — путь к контексту сборки (текущая директория).
   
Важно! Этот шаг обязателен, иначе последующий docker compose up не сможет корректно собрать сервисы, основанные на base-service.










