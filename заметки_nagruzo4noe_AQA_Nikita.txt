
*****************************************************************

Прямая ссылка на курс:
https://stepik.org/242935

https://stepik.org/course/242935/promo

https://stepik.org/course/242935/syllabus

В курс входят -
74 урока
50 часов 9 минут видео
640 тестов
44 интерактивные задачи



stepik - 16-07-2025
~ 6_250 р.



Не задавайте вопросы, которые можно легко найти в сети. Если что-то непонятно, постарайтесь сначала найти ответ самостоятельно. Если же неясно, с чего начать, обратитесь ко мне через урок Поддержка преподавателя и вопросы -
https://stepik.org/lesson/1677142/step/1



Если у вас возникают вопросы в процессе прохождения курса и вы не можете найти на них ответы, вы можете задать вопрос преподавателю в Telegram по адресу -
@sound_right
Преподаватель постарается ответить вам в течение трех рабочих дней



папка для GitHub на диске С -
load_testing_from_my_work



******************************************

1.1 Знакомимся

Нагрузочное тестирование — глубокая, системная дисциплина, которая требует понимания:
- ресурсов системы (CPU, RAM, IO),
- сетевых протоколов (HTTP/gRPC),
- устройства БД,
- очередей и кешей,
- архитектуры приложений (монолит vs микросервисы),
- работы со стендом, сидинга данных и CI/CD.

Это не просто «открыть браузер и нажать кнопку», как в UI-автотестах. Здесь каждый тест — это инженерная гипотеза, которая проверяет прочность всей системы под реальной нагрузкой.

Что будем изучать в курсе?
Прежде всего — у нас будет отдельный тестовый стенд, и это не просто CRUD API и база данных под ним. Вы будете работать с настоящей учебной банковской системой, построенной по принципам микросервисной архитектуры. В ней есть всё, что используется в современных production-системах:
- Kafka — для асинхронных очередей,
- S3-совместимое файловое хранилище (MinIO) — для работы с документами и вложениями,
- Redis — для кеширования,
- PostgreSQL — как основная реляционная БД,
- Поддержка двух протоколов: HTTP и gRPC.

Это максимально приближённый к боевым условиям стенд, а не «игрушка с /ping» в блокноте. Мы будем не просто «посылать запросы», а тестировать поведение сложной системы под реальной нагрузкой.

С первых шагов вы будете работать руками. Первые модули курса посвящены настройке окружения и изучению инфраструктуры, чтобы вы понимали:
- как устроен стенд,
- как взаимодействуют сервисы,
- какие метрики важны,
- какие системные ресурсы участвуют в нагрузке.

Вы освоите и будете использовать вживую:
- docker, docker-compose,
- PostgreSQL и утилиту pgAdmin,
- Kafka UI для работы с очередями,
- MinIO как облачное хранилище,
- Grafana для метрик и анализа,
- Postman для ручного взаимодействия с API,
и многое другое.

В этом курсе вы будете работать сразу с двумя протоколами — HTTP и gRPC. Когда мы пишем функциональные тесты, разница между ними может быть не столь заметна — формат запроса разный, но бизнес-логика одна и та же. А вот в нагрузочном тестировании отличия становятся принципиальными.
- gRPC работает поверх HTTP/2, использует бинарную сериализацию (protobuf) и куда эффективнее в плане скорости и сетевых затрат.
- HTTP проще, но медленнее — особенно при большом количестве пользователей и высокой конкуренции за ресурсы.

Моки: создаём собственные сервисы для нагрузки
В курсе мы не просто «попробуем», а создадим собственный мок-сервис с нуля — и сразу в двух вариантах: для HTTP и для gRPC. Зачем это нужно?
- Во-первых, моки — это важнейший инструмент в нагрузочном тестировании, особенно при проверке систем, где реальные зависимости либо нестабильны, либо ресурсоёмки.
- Во-вторых, вы научитесь отделять нагрузку на конкретный компонент от нагрузки на всю систему.
- В-третьих, эти навыки полезны не только в нагрузке, но и в интеграционном, изоляционном и контрактном тестировании.

Мы реализуем мок-сервис с использованием FastAPI и grpcio, и это даст вам в руки ещё один универсальный инструмент, который пригодится как QA-инженеру, так и performance-инженеру.

Нагрузочное тестирование без анализа метрик — это просто цифры. Поэтому мы научимся работать с Grafana — одним из самых мощных инструментов для визуализации и анализа системных метрик. Вы не просто будете «смотреть графики», а разбираться в происходящем под капотом:
- Какой сервис даёт пиковую нагрузку?
- Куда уходит CPU?
- Что расходует память?
- Где реальное узкое место?
- Почему RPS начал падать?

Мы самостоятельно настроим Grafana-дэшборд, чтобы вы могли анализировать нагрузку не вслепую, а как инженер-исследователь, принимающий решения на основе объективных данных.

Нагрузочное тестирование начинается не с кода и не с графика. Оно начинается с понимания бизнес-контекста. Мы научимся:
- не просто «влепить 1000 виртуальных пользователей»,
- а проанализировать реальные сценарии поведения пользователей,
- рассчитать нагрузочные пики, типичные RPS, время активной сессии,
- построить реалистичный профиль нагрузки, отражающий реальную работу системы в проде.

Locust — наш основной инструмент нагрузочного тестирования, и мы разберём его на атомы. Вы научитесь:
- запускать базовые сценарии,
- использовать TaskSet, SequentialTaskSet, веса, тайминги,
- интегрировать кастомные HTTP и gRPC клиенты,
собирать единую архитектуру фреймворка, подходящую под разные типы API и сценариев.

Итогом станет универсальный нагрузочный фреймворк, который вы сможете:
- развернуть с нуля в любом проекте,
- адаптировать под любую систему,
- аргументировать его архитектуру перед командой или на собеседовании.

Сидинг — это то, о чём не говорят в большинстве курсов. И очень зря. Система не живёт в вакууме. На проде она работает с миллионами уже существующих пользователей, аккаунтов, историй операций. А значит — и в нагрузочных тестах база должна быть реалистично наполнена. В курсе вы научитесь:
- писать сидинг-сценарии,
- подготавливать начальные данные: пользователей, счета, документы,
- сохранять эти данные в JSON-файлы и использовать повторно,
- восстанавливать состояние базы перед каждым прогоном.

Это один из самых критически важных шагов, потому что нагрузка на пустую систему даёт ложные результаты.

В курсе мы активно будем использовать настоящие инструменты, с которыми работают инженеры в реальных проектах:
- Git — для версионирования кода,
- Docker и Docker Compose — для поднятия микросервисного стенда,
- Postman — для ручной работы с HTTP и gRPC API,
- MinIO — как S3-совместимое файловое хранилище,
- PostgreSQL + pgAdmin — для работы с базой,
- Kafka UI — для мониторинга и отправки сообщений в очереди.

Вы не просто «увидите их», вы будете использовать их каждый день: запускать контейнеры, подключаться к брокеру, писать запросы, читать логи. Например, вы научитесь:
- отправлять gRPC-запросы через Postman,
- смотреть состояние Kafka-топиков,
- визуализировать структуру БД через pgAdmin.

Интеграция с CI/CD — автоматизация нагрузки

Нагрузочные тесты не должны жить «в локалке». Я покажу, как:
- интегрировать нагрузочное тестирование в CI/CD-процессы,
- настроить запуск тестов по кнопке,
- автоматически поднимать тестовый стенд с помощью Docker и Docker Compose.

Цель — добиться того, чтобы любой член команды мог:
- запустить нужный сценарий,
- получить метрики,
- увидеть результат в Grafana или отчёте.

Вы научитесь создавать гибкие, универсальные API-клиенты как для HTTP, так и для gRPC. Причём речь не о «заглушках для одного теста», а о полноценных клиентах, которые можно использовать в разных целях:
- в нагрузочном тестировании (как часть сценариев Locust),
- в сидинге — для генерации данных,
- в автоматизированных API-тестах, если вы захотите использовать тот же клиент за пределами курса.

Клиенты будут построены по принципу модульности и переиспользуемости: их легко масштабировать, адаптировать под другие проекты или команды. Это навык, который пригодится вам вне зависимости от вашей роли: QA, перформанс-инженер, automation, SDET — все работают с API, и грамотный API-клиент — это основа продуктивной работы.

В курсе мы также разберёмся в терминологии и видах тестирования производительности, потому что тут важно понимать нюансы. Часто можно услышать: «нагрузим систему до упора — будет нагрузочное тестирование». Но на самом деле — это упрощение, и часто приводит к неправильным выводам. Мы научимся отличать:
- нагрузочное тестирование (load testing) — чтобы понять, выдерживает ли система ожидаемую нагрузку;
- стресс-тестирование — когда мы проверяем, на сколько система способна выйти за пределы нормы;
- тестирование отказоустойчивости — когда эмулируются сбои, ошибки сервисов, падение компонентов;
- резилианс-тестирование — способность восстанавливаться после сбоев без потери данных и целостности;



******************************************

1.2 Советы по изучению материала

урок состоит из - 
- видео 
- теория 
- тесты 
- практическое задание 

смотреть сначала текст (+ схемы, ссылки и т.п.) а потом видео 

делать самому всё что автор делает в видео 

смотреть все ссылки и рекомендации, которые дает автор 



Изучение Python -

Этот курс предполагает базовые знания Python. Если вы не уверены в следующих темах, рекомендую сначала их повторить:

Переменные -
https://www.w3schools.com/python/python_variables.asp

Типы данных -
https://www.w3schools.com/python/python_datatypes.asp

Функции -
https://www.w3schools.com/python/python_functions.asp

Логические операторы -
https://www.w3schools.com/python/python_conditions.asp

Циклы -
https://www.w3schools.com/python/python_for_loops.asp

Lambda-функции -
https://www.w3schools.com/python/python_lambda.asp

Классы -
https://www.w3schools.com/python/python_classes.asp

Знакомство с пакетным менеджером pip -
https://www.w3schools.com/python/python_pip.asp

Работа со строками и форматирование строк -
https://www.w3schools.com/python/python_string_formatting.asp



Для закрепления основ Python, рекомендую следующие бесплатные курсы, которые можно пройти за одну-две недели:

Бесплатный курс по Python от W3Schools -
https://www.w3schools.com/python/default.asp

Бесплатный курс по Python от Metanit -
https://metanit.com/python/tutorial/

Эти ресурсы помогут вам уверенно работать с нагрузочным тестами.



******************************************

1.3 Инструкции по отправке заданий на проверку

Инструкция по отправке на проверку -
1 - Выполните задание и опубликуйте результат на GitHub.

- Решение задания должно быть зафиксировано в одном коммите, если это возможно.
- Название коммита должно соответствовать следующему шаблону: {название урока}. {название шага}. Например, для задания ниже коммит должен быть назван так: 
"Введение в HTTPX. Практическое задание: работа с HTTPX"

- Если задание не получилось выполнить в одном коммите, это не критично. В этом случае просто добавьте еще один коммит с тем же названием, чтобы сохранить логическую структуру.

2 - Вставьте ссылку на GitHub репозиторий в поле ответа:
https://github.com/Nikita-Filonov/performance-tests

3 - Вы получите баллы за задание после его рецензирования

Важно! Если сейчас вам непонятны термины "репозиторий", "коммит" и структура GitHub, не беспокойтесь. Вы сможете пропустить данный шаг и вернуться к нему позже, после изучения основ работы с Git в уроке Начало работы с Git -
https://stepik.org/lesson/1799578/step/1?unit=1825311

- Обратите внимание, что задание не будет принято к оценке, если оно не соответствует указанному формату
- Отправить решение на рецензию можно только один раз!



Текстовый ответ -

Инструкция по отправке на проверку

1 - Составьте текстовый ответ:
- Напишите подробный ответ, следуя требованиям задания.
- Убедитесь, что ваш ответ содержит все необходимые шаги и пояснения.

2 - Вставьте решение в поле ответа

3 - Вы получите баллы за задание после его рецензирования



проверять ответы на задания, если ошибся - создать коммит с таким же названием 



******************************************

1.4 Поддержка от преподавателя и вопросы

Задавать вопросы рекомендуется в следующих ситуациях:
- Если при выполнении практического задания возникли трудности с пониманием условий и вы не уверены, как его выполнить.
- Если при изучении материала курса вы столкнулись с проблемой, которую не удается решить самостоятельно.
- Если вам непонятен процесс отправки домашнего задания на проверку.
- Если вы наткнулись на тему, в которой хотите разобраться глубже, и хотите получить дополнительные материалы для изучения.
- В любых других ситуациях, когда вам не удалось самостоятельно найти ответ, и вы исчерпали доступные ресурсы.



******************************************

2.1 Виды тестирования производительности

Виды тестирования производительности (Performance Testing)
Ссылки:

Performance Testing -
https://glossary.istqb.org/en_US/term/performance-testing
- Тип теста для определения эффективности работы компонента или системы.


Load Testing (нагрузочное тестирование) -
https://glossary.istqb.org/en_US/term/load-testing
- Тип тестирования производительности, проводимый для оценки поведения компонента или системы при различных нагрузках, обычно в интервале между ожидаемыми условиями низкой, типичной и пиковой нагрузки.
-
- что это - стандартная нагрузка, увеличенная в 2-3-5-6 раз 
- цель - нагрузить систему и собрать определенные метрики 
- когда проводится - после добавления новой функциональности или изменения старой (рефакторинга), либо перед каждым релизом и сравнивать метрики с предидущими релизами  


Stress Testing (стресс-тестирование) -
https://glossary.istqb.org/en_US/term/stress-testing
- Тип тестирования производительности, проводимый для оценки системы или компонента на пределе ожидаемых или указанных рабочих нагрузок или за их пределами, или при ограниченной доступности ресурсов, таких как доступ к памяти или серверам.
-
- что это - каждый раз повышаем нагрузку, пока система не откажет - 100-200-300-400-......
- цель - узнать максимальную нагрузку и увидеть какой компонент первым выходит из строя и как система будет восстанавливаться после сбоя, и вообще восстановится ли она 
- когда проводится - никогда не проводить на продакшине, только на тестовых стендах, проводится например при черной пятницей, акциями, когда ожидается большая пиковая нагрузка и нужно понять предел системы 


Soak Testing/Endurance Testing (тестирование выносливости) -
https://glossary.istqb.org/en_US/term/endurance-testing
- Тестирование для определения стабильности системы под значительной нагрузкой в течение значительного периода времени в контексте эксплуатации системы.
-
- что это - подаём ту же нагрузку что и обычно, но в течении нескольких часов или дней 
- цель - выявление утечек ресурсов либо накопительных эффектов - например есть система где кэшируются данные, и мы несколько часов или суток держим её под стандартной постоянной нагрузкой, и смотрим как ведут себя ресурсы, например каждый час по немногу возрастает нагрузка на память, то есть кэш не очищается и остается в памяти, и т.п. При обычном нагрузочном тестировании это может быть незаметно, а при долгом тестировании уже заметно 
- когда проводится - в системах которые долгое время работают под нагрузкой (банковские системы, телеком, чарты, биржи)


Spike Testing (тестирование всплесков) -
https://glossary.istqb.org/en_US/term/spike-testing
- Тестирование для определения способности системы восстанавливаться после внезапных скачков пиковых нагрузок и возвращаться в устойчивое состояние.
-
- что это - здесь нагрузка подаётся резким всплеском, например со 100 до 3000 
- цель - посмотреть как система переживает пик и как восстанавливается после этого, будет ли использоваться кэширование, будут ли увеличиваться ресурсы, масштабироваться система, либо вернутся ошибки, как при DDOS-атаке или когда клиент сразу отправляет очень много запросов на сервер 


Scalability Testing (тестирование масштабируемости) -
https://glossary.istqb.org/en_US/term/scalability-testing
- Тестирование для определения масштабируемости программного продукта.
-
- что это - подаем нагрузку и потихоньку её увеличиваем (тестируем вертикальное масштабирование(количество пользователей растет и соответственно растут потребляемые ресурсы) и горизонтальное масштабирование(растет количество инстансов, до 20-30 штук может расти (копий системы, контейнеров)))
- цель - снять метрики и посмотреть как система масштабируется (будет ли вообще масштабироваться) и что для нас выгоднее - рост ресурсов (вертикальное) или рост количества инстансов системы (горизонтальное) 
- когда проводится - когда поменяли инфраструктуру, настройки или переехали в облачное хранилище 


Failover / Resilience Testing (тестирование отказоустойчивости) -
-
- что это - подаём нагрузку, которая постоянно увеличивается, и смотрим как ведут себя компоненты системы на предмет отказоустойчивости, например есть сервис, который должен быть всегда доступен, сервер должен сам определить когда начинает давать сбой и включить механизм Circuit Breaker, при котором наша система начинает чуть медленее отвечать либо тротлить, то есть этот механизм защищает сервер от отказа (падения) при непомерной нагрузке  

Circuit Breaker распределяет - эти запросы в очередь, эти я замедляю, а эти я отклоняю 

Иногда мы сами можем отключить какой-то сервис, или иммитировать отказ БД, кэширования и посмотреть как себя ведет система, насколько наш сервис отказоустойчивый 


Chaos Testing (хаос-тестирование) -
-
- что это - подаем нагрузку на стенд и начинаем отключать или замедлять сервисы, уменьшать их ресурсы, не позволять им масштабироваться и т.д. 
- цель - Смотрим насколько система устойчивая и надежная. 


Circuit Breaker Design Pattern -
https://en.wikipedia.org/wiki/Circuit_breaker_design_pattern

Тестирование производительности (Performance Testing) включает в себя несколько подвидов, каждый из которых фокусируется на определённой характеристике системы: скорости отклика, устойчивости, масштабируемости и способности к восстановлению. Далее мы рассмотрим ключевые виды такого тестирования.



И ещё раз про то же самое -



1. Load Testing (нагрузочное тестирование)

Цель:
- Проверка, как система работает под нормальной и увеличенной ожидаемой нагрузкой в течение продолжительного времени.

Особенности:
- Эмулируется реалистичная пользовательская активность (например, 100–500 одновременных пользователей).
- Проверяются: производительность, стабильность, скорость отклика, throughput.
- Используется на этапе подготовки к реальному продакшену.

Типичные метрики:
- Время отклика (Response Time)
- Пропускная способность (Requests per Second, Throughput)
- Утилизация CPU / памяти / сети
- Количество ошибок

Когда использовать:
- Перед релизом или масштабированием
- Для выявления узких мест при ожидаемой нагрузке



2. Stress Testing (стресс-тестирование)

Цель:
Определить максимальную нагрузку, которую система может выдержать до деградации или сбоя. Проверяется поведение за пределами нормальных условий.

Особенности:
- Нагрузка постепенно или резко увеличивается выше проектной нормы.
- Цель — увидеть, когда и как "ломается" система, и как она восстанавливается после сбоя.
- Тестируется устойчивость и деградация, а не стабильная работа.

Нюансы:
- Может привести к серьёзным сбоям, поэтому не проводится в продакшене.
- Важно отслеживать, какие компоненты первыми выходят из строя.

Когда использовать:
- При оценке пределов масштабируемости
- При подготовке к резким пиковым нагрузкам (распродажи, маркетинговые кампании)



3. Soak Testing / Endurance Testing (тестирование выносливости)

Цель:
Проверить стабильность системы при продолжительной нагрузке (несколько часов или даже дней) с целью выявления утечек ресурсов и накопительных эффектов.

Особенности:
- Нагрузка может быть на уровне Load Testing, но важно время: часы, сутки.
- Ищутся памятные утечки, утечка соединений, ухудшение времени отклика со временем.
- Выявляются проблемы, которые не видны при коротком тестировании.

Когда использовать:
- В критических системах с длительной работой (банкинг, телеком)
- После обновлений, которые могут повлиять на сборку мусора, кеширование и пр.



4. Spike Testing (тестирование всплесков)

Цель:
Оценить реакцию системы на резкий, кратковременный всплеск нагрузки.

Особенности:
- В отличие от Stress Testing, нагрузка скачет внезапно и резко, а не нарастает.
- Имитируется ситуация, например, когда внезапно заходит 10 000 пользователей за 1 секунду.
- Проверяется, как система "переживает" пик и восстанавливается.

Когда использовать:
- Для оценки реакции на DDoS, флешмобы, баги в клиентском ПО
- Для тестирования автоскейлинга и кэширования



5. Scalability Testing (тестирование масштабируемости)

Цель:
Проверить, насколько хорошо система масштабируется при увеличении:
- числа пользователей,
- объёма данных,
- количества узлов и ресурсов (CPU, памяти и т.д.)

Особенности:
- Может проводиться как в вертикальном (увеличение ресурсов), так и в горизонтальном масштабе (добавление инстансов).
- Анализируется эффективность масштабирования: линейное, сублинейное или деградирующее.

Когда использовать:
- При выборе между горизонтальным и вертикальным масштабированием
- При тестировании облачных или распределённых архитектур



6. Failover / Resilience Testing (тестирование отказоустойчивости)

Цель:
Оценить, как система реагирует на сбой компонентов (сервисов, БД, сети, дисков), и способна ли она восстановиться.

Особенности:
- Имитируются реальные сбои: отключение узла, отказ БД, network partition, и т.д.
- Часто сочетается с Chaos Testing.
- Проверяются механизмы репликации, автоматического переключения, circuit breaker'ы и пр.

Когда использовать:
- При построении отказоустойчивых систем
- Для валидации резервирования и механизмов восстановления



Circuit Breaker

Circuit Breaker (в контексте распределённых систем и отказоустойчивости) — это паттерн устойчивости, который предотвращает повторяющиеся попытки обращения к зависимому (часто внешнему) компоненту, если он уже не отвечает или работает с ошибками. Другими словами это программный механизм, который временно блокирует вызовы к ресурсу (например, микросервису или базе данных), если обнаружено, что он находится в ошибочном или нестабильном состоянии. Это помогает избежать избыточной нагрузки на зависимость и позволяет системе восстанавливаться более эффективно.

Circuit Breaker имеет три состояния:

1 - Closed (закрыт):
- Всё работает нормально.
- Запросы проходят к целевому компоненту.
- При ошибках считает количество/частоту неудач.

2 - Open (открыт):
- Когда число неудач превышает порог — "перегорает".
- Запросы не отправляются, а сразу получают ошибку.
- Даёт целевому компоненту "время на восстановление".

3 - Half-Open (полуоткрыт):
- Через некоторое время позволяет отправить ограниченное количество пробных запросов.
- Если они успешны — возвращается в Closed.
- Если снова ошибка — возвращается в Open.

Зачем нужен:
- Защищает систему от каскадных сбоев.
- Улучшает восстанавливаемость и устойчивость.
- Избегает перегрузки зависимого сервиса в момент, когда он уже не работает.

Примеры применения:
- Между микросервисами, где один сервис зависит от другого.
- При работе с нестабильной внешней API.
- В связке с retry и fallback логикой.



7. Chaos Testing (хаос-тестирование)

Цель:
- Преднамеренно вносить хаос и неопределённость в систему, чтобы проверить её устойчивость и надёжность в условиях неожиданных сбоев.

Особенности:
- Выключение случайных сервисов, сетевых подключений, подмена данных.
- Нестабильность создаётся преднамеренно, часто в продакшене.
- Используется инструментами типа Chaos Monkey, Gremlin.

Нюансы:
- Требует зрелой инфраструктуры, мониторинга и автоматического восстановления.
- Очень мощный инструмент, но опасен без должного контроля.



Сводная таблица сравнения:

Вид теста         - Load Testing
Цель              - Проверить стабильность
Нагрузка          - В норме
Продолжительность - Средняя	
Пример метрик     - Время отклика, ошибки

Вид теста         - Stress Testing
Цель              - Найти пределы	
Нагрузка          - Сверх нормы
Продолжительность - Кратковременная
Пример метрик     - Точка отказа, деградация

Вид теста         - Soak Testing
Цель              - Найти утечки, дрейф
Нагрузка          - В норме	
Продолжительность - Долгая
Пример метрик     - Утечки памяти, рост latency

Вид теста         - Spike Testing	
Цель              - Проверить на всплески	
Нагрузка          - Резкие пики
Продолжительность - Кратковременная
Пример метрик     - Пиковое поведение, отклик

Вид теста         - Scalability Testing	
Цель              - Проверить масштабируемость	
Нагрузка          - Растущая
Продолжительность - Любая	
Пример метрик     - Throughput на ресурс

Вид теста         - Resilience Testing
Цель              - Проверить восстановление
Нагрузка          - Любая	
Продолжительность - По сценарию
Пример метрик     - Восстановление, ошибки

Вид теста         - Chaos Testing
Цель              - Проверить устойчивость к сбоям
Нагрузка          - Нестабильная
Продолжительность - Любая
Пример метрик     - Выживаемость, самовосстановление


Мы в рамках этого курса будем работать с Load Testing (нагрузочным тестированием) - время ответа, количество запросов в секунду, процессор, память, диск, сеть - то есть будем делать снятие всяких метрик 

Также в этом уроке мы разобрали все виды тестирования производительности 



******************************************

2.2 Системные ресурсы: CPU и память

Ссылки:

CPU -
https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80

RAM -
https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BF%D0%BE%D0%BC%D0%B8%D0%BD%D0%B0%D1%8E%D1%89%D0%B5%D0%B5_%D1%83%D1%81%D1%82%D1%80%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%BE_%D1%81_%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%BB%D1%8C%D0%BD%D1%8B%D0%BC_%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%BE%D0%BC

Любое нагрузочное тестирование в итоге сводится к вопросу: хватает ли системе ресурсов, чтобы справиться с текущей и будущей нагрузкой.

Два ключевых ресурса:
- CPU (центральный процессор) — обрабатывает инструкции, выполняет код, принимает сетевые соединения и т.д.
- Память (RAM) — хранит данные, к которым требуется быстрый доступ: объекты, кэши, соединения, промежуточные результаты.

Понимание их работы, поведения под нагрузкой и типичных "узких мест" помогает точно интерпретировать результаты тестов. Ошибки, заниженные или переоценённые ожидания от CPU и памяти могут:
- искажать результаты тестов,
- приводить к ложным выводам,
- вызывать непредсказуемое поведение в продакшене.



Процессор: CPU (Central Processing Unit)

Что такое CPU? CPU — мозг системы. Его задачи:
- Выполнение инструкций программ,
- Планирование потоков,
- Обработка сетевых соединений,
- Шифрование, сериализация, маршрутизация.

Масштаб нагрузки на CPU зависит от:
- количества одновременных пользователей,
- характера операций (IO-bound или CPU-bound),
- архитектуры приложения (однопоточное/многопоточное),
- языка программирования и рантайма.



Метрики CPU - 
(Метрика -- Описание) -

CPU Usage (%) -- Доля занятости процессора. Суммируется по всем ядрам.

Load Average (Linux) -- Количество процессов, ожидающих CPU. Сравнивается с числом ядер.

Context Switches -- Количество переключений между задачами. Много — признак проблем с многопоточностью.

CPU Steal (в виртуальных машинах) -- Сколько времени CPU "украдено" хостом (например, в облаке).



Примеры проблем с CPU -
(Симптом -- Возможная причина -- Как диагностировать)

CPU 100% -- Узкое место в алгоритме или сервисе -- top, htop, flamegraph

Высокий Load Avg > ядер -- Перегрузка, очереди -- uptime, w, vmstat

Неравномерная загрузка ядер -- Неоптимальное распараллеливание -- инструменты профилирования

Слишком много context switches -- Нестабильная многопоточность -- pidstat, perf



Что важно в нагрузочных тестах?
- Наращивая нагрузку (stress), определяем точку деградации CPU.
- В endurance тестах оцениваем устойчивость CPU к длительной нагрузке.
- При spike test'ах смотрим, как быстро CPU восстанавливается после всплеска.
- Анализируем: какое число пользователей/запросов система выдерживает до перегрузки CPU?
	

	
Оперативная память: RAM (Random Access Memory)
Что такое оперативная память? RAM используется для:
- хранения промежуточных данных (объекты, сессии, буферы),
- работы garbage collector'а (в языках с автоматическим управлением памятью),
- кэширования (например, баз данных, API-ответов),
- работы ОС (файловые кэши, очереди, сетевые буферы).



Метрики памяти -
(Метрика -- Описание) -

RSS (Resident Set Size) -- Сколько физической памяти использует процесс.

VSZ (Virtual Size) -- Виртуальный объём адресного пространства.

Heap / Non-Heap -- Память, выделенная для объектов / остальная служебная память.

Page Faults -- Обращения к диску при нехватке памяти.

GC Activity -- Количество и длительность сборок мусора.



Примеры проблем с памятью -
(Симптом -- Возможная причина -- Диагностика) -

Утечка памяти (leak) -- Объекты не освобождаются -- Профайлер, heap dump

Частые паузы GC -- Недостаток памяти, плохая настройка GC -- метрики GC, pause time

Рост latency со временем -- Кеши не сбрасываются, ресурсы накапливаются -- endurance test

OOM (Out Of Memory) -- Превышение лимитов памяти -- лог OOM Killer, мониторинг



Что важно в нагрузочных тестах -

- Soak/Endurance Testing позволяет найти медленные утечки, не видимые за 5 минут.

- Load Testing показывает объём памяти, необходимый при стабильной нагрузке.

- Stress Testing помогает проверить, как система ведёт себя при превышении лимитов.

- Resilience Testing проверяет, как приложение реагирует на OOM, падения GC и пр.



Инструменты мониторинга и анализа - 
(Инструмент	--- Назначение) -

top, htop, atop, dstat, vmstat	--- Общая загрузка ресурсов

pidstat, iostat, mpstat	--- Диагностика процессов

pmap, smem	--- Анализ памяти процессов

Prometheus + Grafana --- Визуализация метрик в реальном времени

valgrind, VisualVM, gperftools, Flamegraph --- Глубокий анализ и профилирование



Связь с видами нагрузочного тестирования -
(Вид тестирования -- CPU и память — ключевые аспекты) -

Load Testing -- Следим за стабильной утилизацией

Stress Testing -- Где "ломается" CPU или память

Soak Testing -- Проверка на утечки, усталость системы

Spike Testing -- Моментальная реакция ресурсов

Scalability Testing -- Как ресурсы реагируют на рост нагрузки

Resilience Testing -- Устойчивость к деградации и восстановление

Chaos Testing -- Проверка на сбои: OOM, CPU starvation и пр.



нагрузка на процессор измеряется в процентах 

одно ядро - это 100% 

соответственно если 5 ядер, то будет 500% всего в Grafana

нагрузка на память измеряется в гигабайтах, но нужно оценивать динамику загрузки оперативной памяти  

при анализе памяти учитывать что могут быть утечки, например не очищается кэш 

весь смысл работы и анализа с оперативной памятью сводится к тому, что нужно выявить утечки, так как оперативная память должна очищаться 

когда оперативная память кончается, она начинает делать свап, то есть перемещать часть данных из оперативной памяти на жесткий диск, но запись на жесткий диск достаточно долгая, то на несколько секунд всё подвисает 

в Grafana посмотреть объем свапа можно на графике - Memory Swap per Container

не путать понятия -
- оперативная память 
- HDD
- SSD 

нагрузочное тестирование без анализа системных ресурсов смысла не имеет 



******************************************

2.3 Метрики нагрузочного тестирования

Метрики можно условно разделить на несколько групп:
- Метрики производительности приложения (Response Time, RPS, ошибки)
- Метрики нагрузки (кол-во пользователей, concurrency, throughput)
- Метрики инфраструктуры (CPU, RAM, диски, сеть)
- Метрики распределения и статистики (percentiles, медиана и др.)



1. Основные метрики отклика

- Response Time (время отклика) -
Определение: время между отправкой запроса и получением полного ответа от сервера.

Варианты:
- Average Response Time – среднее время отклика (может быть искажено пиками).
- Min / Max Response Time – минимальное и максимальное время отклика.
- Median Response Time (P50) – время, за которое половина запросов завершилась (менее чувствительно к выбросам).
- Percentiles (P90, P95, P99) – процентиль — значение, ниже которого находится заданный процент всех измерений.

Пример:
- P95 = 1500 мс означает, что 95% запросов завершились быстрее, чем за 1,5 секунды.
- P99 важен в SLA, особенно для UI и API-интерфейсов.

Percentiles vs Average - Среднее значение может быть обманчивым: если 9 запросов по 100 мс и 1 запрос за 5 сек → среднее = 590 мс, но большинство пользователей имели отличный опыт.



2. Метрики нагрузки

RPS (Requests per Second) -
Определение: количество обрабатываемых запросов в секунду.

Важно для:
- оценки throughput (пропускной способности),
- тестирования серверной части под реальной нагрузкой.

Пример: если у API 100 RPS, а 95% запросов укладываются в 300 мс — это хороший показатель.



Throughput -
Близкий к RPS, но иногда трактуется шире: как объём данных, проходящих через систему в единицу времени (например, MB/s).

Concurrent Users (одновременные пользователи) -
Сколько виртуальных пользователей (VUs) одновременно активны в сценарии (например, делают запрос, ожидают ответа, или "зависают" в think time).



Virtual Users (VUs) -
Количество имитируемых пользователей в нагрузочном тесте. Может не совпадать с "активными" пользователями (не все делают запросы одновременно).

Важно! Если 100 VU делают по 1 запросу каждые 10 секунд → это лишь 10 RPS.

Latency vs Response Time
- Latency — задержка между отправкой запроса и первым байтом ответа.
- Response Time — полное время получения ответа.
- Иногда путаются, особенно в сетевых метриках.



3. Метрики ошибок


Error Rate -
Процент завершившихся с ошибкой запросов (например, 5xx, timeout, network error и т.д.)

Пример: если было 10000 запросов, а из них 50 неуспешных, error rate = 0.5%

HTTP status code distribution -
Полезно отслеживать, сколько 200, 4xx, 5xx и пр. Это помогает отличить клиентские ошибки от серверных проблем.

Timeouts / Connection Errors -
- Таймауты: запросы, которые превысили лимит времени.
- Connection Errors: проблемы при установке TCP/SSL соединения.

Failures per Second - запросы, которые завершились с ошибкой (штук в секунду)



4. Продвинутые метрики


Think Time / Pacing -
- Think Time - имитация "времени раздумий" пользователя между действиями (сколько думает один средний пользователь между запросами) - измеряется в секундах 
- Pacing — задержка между итерациями одного и того же VU.
- Позволяет избежать нереалистичной нагрузки.

Dropped Requests / Retries -
- Dropped — сервер сбрасывает соединение под нагрузкой.
- Retries — количество повторных запросов после неудачи.

CPU Time per Request -
Время CPU, затраченное на обработку одного запроса (можно оценивать через профилировщик или APM).



Сводная таблица: часто используемые метрики -
Метрика	-- Тип -- Комментарий

Response Time (avg)	-- Время -- Среднее время отклика

Response Time (P95, P99) -- Время -- Более точный показатель UX

RPS -- Нагрузка -- Кол-во запросов в секунду

VUs -- Нагрузка -- Сколько пользователей

Error Rate -- Ошибки -- % запросов с ошибкой

Min/Max Response Time -- Время -- Для выявления пиков

CPU / RAM Usage -- Системные ресурсы -- Инфраструктурная метрика

Throughput -- Нагрузка -- Пропускная способность

Timeout Count -- Ошибки -- Количество таймаутов

Connection Failures -- Ошибки -- Проблемы сети / API Gateway

Percentiles -- Статистика -- P50, P90, P95, P99

Latency -- Время -- Особенно важно в сетевых API



Пример интерпретации - Допустим, после запуска теста:
RPS = 200
P95 Response Time = 950 мс
P99 = 1800 мс
Error Rate = 0.7%
CPU = 90%
RAM = 65%

Интерпретация:
- Производительность в целом хорошая, но есть проблемы на пике (P99 высокое).
- CPU почти на пределе → возможный кандидат на масштабирование.
- Нужно разобраться с 0.7% ошибок: возможно, таймауты.



Извините, а скриншот графика с Percentiles (P90, P95, P99) из locust или используется стороннее приложение?
"Из коробки", кажется, в locust такого не видела.
-
Да, в locust такого нет. Данный скриншот взят из системы аналитики load-testing-hub, можно почитать подробнее тут https://habr.com/ru/articles/871154/



******************************************

2.4 Клиент-серверная архитектура

Ссылки - Клиент-серверная архитектура -
https://en.wikipedia.org/wiki/Client%E2%80%93server_model

Клиент-серверная архитектура — это модель, в которой взаимодействуют два типа компонентов: клиент и сервер. Она широко используется в разработке приложений, особенно тех, что требуют взаимодействия с удаленными системами, будь то веб-сервисы, базы данных, файлы или другие ресурсы.



Основные компоненты клиент-серверной архитектуры:

1 - Клиент: Это приложение или устройство, которое инициирует запросы. Клиент может быть веб-браузером, мобильным приложением, десктопной программой или другим компонентом, который взаимодействует с сервером для получения или отправки данных.

2 - Сервер: Это система, которая обрабатывает запросы от клиента и возвращает результаты. Сервер может быть программным или аппаратным обеспечением, которое выполняет операции, связанные с хранением данных, вычислениями, и обеспечивает доступ к различным ресурсам.



Взаимодействие между клиентом и сервером:

- Запрос: Клиент отправляет запрос на сервер, используя стандартный протокол, такой как HTTP, FTP, WebSocket и другие.

- Ответ: Сервер обрабатывает запрос, выполняет необходимые операции и отправляет клиенту результат (например, данные, статус, ошибку).

Пример: Когда вы заходите на веб-сайт, ваш браузер (клиент) отправляет запрос на веб-сервер, который возвращает веб-страницу, отображаемую на вашем экране.



Преимущества клиент-серверной архитектуры:

1 - Масштабируемость: Серверы могут быть настроены для обработки множества запросов от клиентов.

2 - Централизация: Вся логика и данные могут быть централизованы на сервере, что упрощает управление и безопасность.

3 - Безопасность: Сервер может быть настроен для проверки прав доступа и защиты данных.



Виды клиент-серверной архитектуры:

1 - Одноуровневая архитектура (1-tier architecture):
- Вся логика (клиент и сервер) находится в одном месте, обычно на одном устройстве или сервере.
- Пример: Простое приложение, где клиент и сервер совмещены (например, локальные программы).

2 - Двухуровневая архитектура (2-tier architecture):
- В этой модели есть два компонента: клиент и сервер.
- Пример: Веб-приложение с веб-сервером, который обрабатывает запросы от клиента (браузера).

3 - Многоуровневая архитектура (N-tier architecture):
- Это расширенная модель, в которой могут быть несколько слоев: например, клиент, веб-сервер, приложение и база данных.
- Пример: Большие веб-приложения, которые используют серверы приложений, базы данных и другие компоненты для обработки данных. 



Пример двухуровневой архитектуры (клиент-сервер):
- Клиент: Браузер, который отправляет HTTP-запросы на сервер.
- Сервер: Веб-сервер, который обрабатывает запросы и взаимодействует с базой данных.

Пример:
- Пользователь открывает браузер и вводит URL, например, https://example.com.
- Браузер отправляет HTTP GET-запрос на сервер, который находится по этому адресу.
- Сервер обрабатывает запрос, извлекает данные из базы данных или выполняет другую логику, а затем отправляет ответ обратно.
- Браузер получает HTML, CSS и JavaScript и отображает веб-страницу пользователю.



Примеры использования клиент-серверной архитектуры:

1 - Веб-приложения:
- Веб-браузер отправляет запросы на сервер, который обрабатывает их и возвращает результаты в виде веб-страниц (HTML, CSS, JS).
- Примеры: Gmail, Facebook, банковские приложения.

2 - Мобильные приложения:
- Мобильное приложение может работать как клиент, а сервер обрабатывает запросы и возвращает данные, которые отображаются на устройстве.
- Примеры: WhatsApp, Instagram, приложения для заказа еды.

3 - Игры:
- Онлайн-игры используют клиент-серверную архитектуру для отправки и получения данных о состоянии игры между клиентом (игроком) и сервером.
- Пример: Fortnite, World of Warcraft.



Клиент-серверная архитектура является основой для большинства современных приложений и сервисов. Она позволяет централизовать обработку данных на сервере, обеспечивать масштабируемость и безопасность, а также упрощает управление логикой приложения.

Этот подход играет важную роль в автоматизации тестирования, поскольку тесты могут быть направлены на проверку взаимодействия между клиентом и сервером, включая запросы и ответы, обработку ошибок и производительность.



протоколы для -

- web-приложение (браузер) - HTTP, HTTPS

- десктопное приложение и мобильное приложение - gRPS



******************************************

2.5 Монолитная архитектура

Ссылки:

Сравнение микросервисной и монолитной архитектур -
https://www.atlassian.com/ru/microservices/microservices-architecture/microservices-vs-monolith

В чем разница между монолитной архитектурой и архитектурой микросервисов? -
https://aws.amazon.com/ru/compare/the-difference-between-monolithic-and-microservices-architecture/



Монолитная архитектура — это архитектурный стиль, при котором всё приложение разрабатывается, разворачивается и масштабируется как единое целое.

В монолите все компоненты приложения — пользовательский интерфейс, бизнес-логика, доступ к данным и взаимодействие с внешними сервисами — находятся в одном исполняемом процессе.



Структура монолитного приложения -
Обычно монолитное приложение включает в себя следующие слои:

- Представление (UI Layer). Отвечает за взаимодействие с пользователем (например, HTML-страницы, REST API, графический интерфейс).

- Бизнес-логика (Business Logic Layer). Основные правила и логика обработки данных, расчетов, валидации и принятия решений.

- Доступ к данным (Data Access Layer). Работа с базами данных, кэшами, файлами и другими хранилищами.

- Интеграции (Integration Layer). Если монолит взаимодействует с внешними API или сервисами, этот слой обрабатывает вызовы.

Все эти слои разворачиваются как единый модуль, зачастую в одном контейнере или на одном сервере.



Примеры монолитных приложений -

- Приложения, написанные в Java EE / Spring Boot с использованием Tomcat или JBoss, где всё приложение — один .war или .jar файл.

- Приложения, написанные на Python и использующие Django фреймворк.

- Старые веб-приложения на PHP, где бизнес-логика, шаблоны и SQL-запросы находятся в одном проекте.

Примеры:
- WordPress
- CRM-системы типа 1С:Предприятие
- Внутренние ERP-программы крупных компаний до перехода к микросервисам



Преимущества монолитной архитектуры -

Преимущество -
Объяснение

Простота разработки	- 
Один проект, одна точка входа. Удобно начинать с монолита на ранних этапах.

Единый деплой -
Всё приложение деплоится как единый артефакт. Нет необходимости в настройке множества сервисов.

Проще отлаживать и тестировать -
Вся система в одном процессе, легче использовать отладчик, писать юнит-тесты.

Проще локальная разработка -
Нет необходимости поднимать множество сервисов или использовать Docker/Orchestrator.



Недостатки монолитной архитектуры -

Недостаток -
Объяснение

Плохая масштабируемость по частям -
Нельзя масштабировать только “узкие места” — масштабируется всё приложение.

Сложность изменений в больших системах -
Малейшее изменение требует пересборки и перезапуска всего приложения.

Сложности с командами -
Несколько команд, работающих над одним проектом, могут мешать друг другу.

Ограниченная гибкость технологий -
Все части должны использовать одну и ту же технологическую версию, библиотеку, стек.

Риск полного отказа -
Ошибка в одном месте может “уронить” всё приложение.



Когда выбирать монолит?
Монолитная архитектура подходит в следующих случаях:

- Вы создаёте MVP или первый прототип, который нужно быстро запустить.

- Команда небольшая, проще сосредоточиться на одной кодовой базе.

- Вы работаете в условиях ограниченного бюджета, и инфраструктура микросервисов избыточна.

- Приложение по определению не будет масштабироваться (например, внутренние инструменты).



Эволюция: от монолита к микросервисам
Монолитное приложение со временем может:
- “распухнуть” — превратиться в громоздкий и трудноизменяемый код;
- начать испытывать трудности с масштабированием;
- требовать разделения команд и внедрения микросервисной архитектуры.

Этот процесс называют модульным рефакторингом — вынос функциональности из монолита в отдельные сервисы.



Монолитная архитектура — это простая и эффективная модель для начальной разработки и небольших команд. Однако при росте нагрузки и сложности системы появляются ограничения, требующие перехода к более гибким архитектурам, таким как микросервисы или модульные монолиты.



******************************************

2.6 Микросервисная арихтекутра

Ссылки:

Микросервисная архитектура -
https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0

Микросервисная архитектура статья от atlassian -
https://www.atlassian.com/ru/microservices/microservices-architecture

Сравнение микросервисной и монолитной архитектур -
https://www.atlassian.com/ru/microservices/microservices-architecture/microservices-vs-monolith

В чем разница между монолитной архитектурой и архитектурой микросервисов? -
https://aws.amazon.com/ru/compare/the-difference-between-monolithic-and-microservices-architecture/



Микросервисная архитектура (microservice architecture) — это подход к проектированию программных систем как набора небольших, автономных сервисов, каждый из которых реализует отдельную бизнес-функцию, взаимодействуя с другими сервисами через лёгкие протоколы (обычно HTTP/REST, gRPC, AMQP и др.).

Каждый микросервис:
- Развивается и деплоится независимо
- Обладает собственной логикой и хранением данных
- Может быть написан на своём языке программирования



Основные характеристики микросервисов -

Характеристика -
Описание

Изоляция -
Каждый сервис — отдельный процесс. Ошибка одного сервиса не должна ломать всю систему.

Независимое масштабирование -
Можно масштабировать только “узкие” сервисы (в отличие от монолита).

Автономность разработки -
Команды могут независимо разрабатывать, тестировать и деплоить отдельные сервисы.

Свои данные -
Каждый микросервис владеет своей БД (или схемой в общей БД) — “Database per service”.

Коммуникация по сети -
Взаимодействие идёт через сетевые вызовы, обычно по API.

Обработка сбоев -
Часто применяются: Circuit Breaker, Retry, Timeout, Load Balancer.

DevOps и автоматизация -
Нужна зрелая CI/CD-инфраструктура, наблюдаемость, логирование.



Коммуникации между микросервисами -

- Синхронные: HTTP/REST, gRPC. Быстро, просто, но чувствительно к сбоям

- Асинхронные: через очереди сообщений (RabbitMQ, Kafka). Повышает устойчивость, снижает связанность



Преимущества микросервисной архитектуры -

- Масштабируемость. Горизонтальное масштабирование отдельных компонентов

- Независимость разработки. Меньше конфликтов между командами, проще CI/CD

- Гибкость технологий. Возможность использовать разные языки, базы, фреймворки

- Отказоустойчивость. Локализация проблем: сбой одного сервиса ≠ падение всей системы

- Лучшая поддержка DevOps/Cloud. Хорошо сочетается с Kubernetes, контейнерами, облаками



Недостатки и сложности -

Недостаток -
Почему это проблема

Сложность инфраструктуры -
Нужен сервис-меш (например, Istio), оркестратор (K8s), мониторинг

Сетевые накладные расходы -
Больше запросов по сети → latency, ошибки

Трудности отладки -
Сервис может "ломаться" в связке с другим

Согласованность данных -
Труднее обеспечить ACID и транзакции между сервисами

Сложное управление версиями -
Необходима контрактная совместимость API

DevOps-зрелость обязательна -
Нужны CI/CD, логирование, трассировка, автоматизация



Когда стоит использовать микросервисы? -

Подходят:
- Для крупных распределённых систем
- Когда есть несколько команд разработки
- Если бизнес-логика чётко делится на независимые домены
- При высоких требованиях к масштабируемости и доступности

Не рекомендуются:
- Для маленьких или средних проектов
- Если нет опыта в CI/CD, облаках и Kubernetes
- Когда проще использовать модульный монолит



Пример микросервиса - Банковская система -
- AccountService — управление счетами
- TransactionService — перевод средств
- ReportingService — отчёты
- FraudDetectionService — выявление подозрительной активности



Отличие от монолита -
Признак - Монолит - Микросервисы -

Масштабируемость - Только целиком - По частям

Разработка - Одним блоком - Независимыми командами

Развёртывание - Общее - Независимое

Надёжность - Уязвим к сбою одного модуля - Локализация проблем

Работа с данными - Единая БД - Базы у каждого сервиса

Производительность - Быстрее (внутренние вызовы) - Зависит от сети, требует кеширования

Тестирование - Проще - Сложнее, нужны контракты и трассировка



Связанные архитектурные шаблоны -

- API Gateway — единая точка входа, маршрутизация к микросервисам (грубо говоря - это прокси)

- Service Discovery — динамическое обнаружение сервисов

- Sidecar — вспомогательные контейнеры для логирования, трейсинга

- CQRS / Event Sourcing — раздельная обработка чтения и записи

- SAGA Pattern — распределённые транзакции



Микросервисы — это мощный, но не бесплатный архитектурный подход. Их внедрение требует зрелости как в инженерной культуре, так и в технической инфраструктуре. Для крупных систем это может дать огромные преимущества: гибкость, отказоустойчивость и масштабируемость. Но для небольших — избыточная сложность.



мы в этом курсе позже будем работать со стендом, где используется микросервисная архитектура

для каждого микросервиса - запускается отдельный процесс 

микросервисы можно масштабировать независимо друг от друга (точечно, то есть добавлять ресурсы только микросервису, которому они нужны, а не всему приложению, как в монолите)

каждый микросервис владеет своей БД (или схемой в общей БД) - "Database per service"

gRPS - самый быстрый синхронный протокол взаимосвязи между микросервисами 



******************************************

2.7 Инструменты нагрузочного тестирования

Введение: Зачем нужны инструменты нагрузочного тестирования

Когда приложение или сервис разрабатывается, важно не только убедиться в его корректной работе (функциональное тестирование), но и понять, как он будет вести себя под нагрузкой: сможет ли выдерживать большое количество пользователей, насколько быстро будет отвечать, не упадёт ли при высоком трафике. Именно для этого и применяется нагрузочное тестирование.



Тестирование производительности — это обобщающее понятие, включающее в себя несколько подвидов:

- Load Testing — проверка системы при ожидаемой нагрузке;

- Stress Testing — проверка пределов, когда нагрузка превышает норму;

- Spike Testing — оценка реакции на резкие всплески трафика;

- Soak Testing — длительное тестирование для выявления деградации;

- Scalability Testing — анализ способности масштабироваться при росте нагрузки.



Но возникает вопрос: Как сымитировать поведение сотен, тысяч или даже миллионов пользователей, чтобы проверить систему?



Решением являются специальные инструменты нагрузочного тестирования. Они позволяют:

- Имитировать запросы от пользователей (HTTP, WebSocket, gRPC и др.)

- Создавать настраиваемую нагрузку — например, 1000 пользователей в течение 10 минут

- Оценивать производительность — время ответа, количество ошибок, RPS, процентильные задержки и другие метрики

- Автоматизировать тесты и интегрировать их в CI/CD

- Настраивать сценарии поведения пользователей, включая сложные последовательности действий



Как работают эти инструменты - 

1 - Сценарий теста описывает поведение пользователей:
Например: 
"Открыть страницу → Войти → Получить список товаров → Добавить товар в корзину".

2 - Инструмент запускает множество виртуальных пользователей (VUs), которые параллельно и многократно выполняют этот сценарий.

3 - Запросы отправляются к серверу, как если бы это делали настоящие пользователи.

4 - Инструмент собирает метрики: время ответа, количество запросов в секунду (RPS), процент ошибок, поведение под пиковыми нагрузками.

5 - Результаты визуализируются в виде графиков или отчётов — это помогает принимать архитектурные и бизнес-решения.

Виртуальные пользователи (Virtual Users, VUs) — это программные сущности, имитирующие действия реальных пользователей. Каждый такой пользователь выполняет заданный сценарий, посылает запросы к серверу и участвует в генерации нагрузки.



Типовые цели использования инструментов:

- Проверить, сколько пользователей может выдержать система

- Найти узкие места в производительности (например, медленные запросы)

- Сравнить поведение разных версий (до и после оптимизации)

- Тестировать SLA (время ответа, стабильность, доступность)

- Подготовиться к реальным пиковым нагрузкам (Black Friday, акции, релизы)



Примеры использования на практике:

- Интернет-магазин проверяет, выдержит ли он 10 000 пользователей во время распродажи

- Банк тестирует обработку тысяч транзакций в минуту

- Мобильное приложение проверяет API при подключении 5000 одновременных клиентов

- Онлайн-игра моделирует игровую сессию с 3000 игроками на сервере



Нагрузочное тестирование — это обязательный этап для любого серьёзного продукта. А инструменты для нагрузочного тестирования — это основной способ смоделировать поведение пользователей, зафиксировать метрики и убедиться, что система будет работать быстро, стабильно и предсказуемо даже под высокими нагрузками.

В этом курсе мы сделаем акцент на open-source решениях, которые легко использовать локально, интегрировать в пайплайны и применять даже в небольших командах. Особое внимание уделим Locust — современному инструменту на Python, который легко осваивается и при этом подходит как для обучения, так и для промышленных нагрузочных сценариев.



Инструменты нагрузочного тестирования: подробный обзор и сравнение -



Locust: 

Официальный сайт -
https://locust.io/

Официальная документация -
https://docs.locust.io/en/stable/

Репозиторий -
https://github.com/locustio/locust



JMeter:

Официальный сайт -
https://jmeter.apache.org/

Официальная документация -
https://jmeter.apache.org/usermanual/index.html

Репозиторий -
https://github.com/apache/jmeter



K6:

Официальный сайт -
https://k6.io/

Официальная документация -
https://grafana.com/docs/k6/latest/

Репозиторий -
https://github.com/grafana/k6



Gatling:

Официальный сайт -
https://gatling.io/

Официальная документация -
https://docs.gatling.io/

Репозиторий -
https://github.com/gatling/gatling



Artillery:

Официальный сайт -
https://www.artillery.io/

Официальная документация -
https://www.artillery.io/docs

Репозиторий -
https://github.com/artilleryio/artillery



1. Locust

Locust — это современный инструмент нагрузочного тестирования с открытым исходным кодом, в котором сценарии описываются на чистом Python. Он отлично подходит для моделирования поведения пользователей с высокой степенью реалистичности и гибкости. Благодаря удобному API, простому запуску и поддержке популярных протоколов, Locust стал выбором многих команд разработки и тестирования.



Основные характеристики:

- Язык сценариев: Python

- Подход: Поведение пользователей описывается как Python-классы

- Протоколы: HTTP/HTTPS, WebSocket, gRPC (через сторонние расширения)

- Интерфейс: Web-интерфейс для управления нагрузкой + CLI для автоматизации

- Масштабирование: Поддержка master/worker модели (distributed mode)

- Мониторинг: Встроенная web-панель, интеграция с Prometheus и Grafana

- Установка: pip install locust



Преимущества:

- Написание тестов на чистом Python — просто, читаемо, удобно для разработчиков

- Поддержка реалистичного пользовательского поведения — задержки, веса, последовательности

- Лёгкая интеграция с любыми Python-библиотеками (requests, httpx, grpcio, pydantic и др.)

- Быстрый вход в инструмент — идеален для обучения и прототипирования

- Активное сообщество, расширения и хорошая документация -
github.com/locustio/locust



Ограничения:

- Меньше встроенных визуальных инструментов, чем у JMeter или k6

- Не предназначен для экстремально высоких нагрузок (млн+ RPS), но работает стабильно до сотен тысяч при правильной настройке



Кому подойдёт: Python-разработчикам, QA-инженерам, DevOps-специалистам, которым важна гибкость сценариев, хорошая читаемость и простая интеграция в пайплайны CI/CD.

Пример простого сценария на Locust:
--
from locust import HttpUser, task, between

class WebsiteUser(HttpUser):
    wait_time = between(1, 5)  # Пауза между действиями (в секундах)

    @task
    def load_homepage(self):
        self.client.get("/")

    @task
    def view_products(self):
        self.client.get("/products")

    @task
    def make_purchase(self):
        self.client.post("/purchase", json={"item_id": 42})
----
- В этом примере:

- Класс WebsiteUser описывает поведение виртуального пользователя.

- Методы, помеченные @task, представляют действия, которые он выполняет.

- self.client используется для отправки HTTP-запросов.

- wait_time задаёт паузу между действиями, моделируя поведение настоящего пользователя.



2. Apache JMeter

JMeter — один из самых известных инструментов для нагрузочного тестирования. Он предлагает визуальный интерфейс для создания сценариев без программирования и поддерживает широкий спектр протоколов, включая не только HTTP, но и FTP, SOAP, JDBC, JMS и другие. JMeter активно используется в корпоративной среде, особенно в крупных организациях, где важна поддержка legacy-систем.



Основные характеристики:

- Язык сценариев: GUI-инструмент (визуальная сборка) + JMX/XML-конфигурации (опционально Groovy)

- Подход: Сценарии собираются через графический интерфейс, можно сохранять и редактировать в виде конфигурационных файлов

- Протоколы: HTTP, JDBC, FTP, SOAP, JMS и др.

- Интерфейс: Графический интерфейс (GUI) + командная строка (CLI) для запуска без UI

- Масштабирование: Есть поддержка distributed mode, но настройка сложнее, чем в Locust

- Мониторинг: Через встроенные или сторонние плагины; возможен экспорт метрик в Prometheus, InfluxDB и др.

- Установка: Скачивание с сайта Apache JMeter -
https://jmeter.apache.org/
+
github.com/apache/jmeter



Преимущества:

- Богатая поддержка различных протоколов и конфигураций — удобно для нестандартных или legacy-сценариев

- Возможность создавать тесты без программирования — через визуальный интерфейс

- Часто используется в больших компаниях, хорошо известен в индустрии

- Поддержка широкого набора плагинов и расширений



Ограничения:

- Интерфейс довольно тяжёлый и устаревший, особенно при работе с большими сценариями

- Сценарии хранятся в JMX/XML, что делает их сложными для чтения, версионирования и code-review

- Ограниченная гибкость при описании логики поведения пользователей

- Не интегрируется нативно с Python — не лучший выбор для Python-ориентированных команд

- Хотя JMeter широко используется и часто встречается в учебных курсах, его архитектура и интерфейс устарели. Он был создан в начале 2000-х, и с тех пор принципы разработки и тестирования сильно изменились.

- Многие компании используют JMeter из-за исторических причин или внутреннего наследия (legacy). Legacy (наследие) — это устаревший код или инструменты, которые тяжело заменить, но продолжают использоваться.

- На практике это означает: JMeter не лучший выбор для новых проектов, особенно если вы работаете с Python, современными API, CI/CD и микросервисами. Есть более лёгкие, гибкие и удобные инструменты — такие как Locust, k6, Gatling, которые лучше отражают текущие подходы в нагрузочном тестировании.

Кому подойдёт: Тестировщикам и инженерам, работающим с широким спектром протоколов, корпоративными сервисами и legacy-системами. Особенно актуален, если требуется безкодовое создание тестов и поддержка старых технологий (SOAP, JMS и др.).



Пример сценария в JMeter (визуально) - 
Хотя JMeter — это в первую очередь GUI-инструмент, можно описать базовую структуру сценария:
--
Test Plan
├── Thread Group (например, 100 пользователей, 10 циклов)
│   ├── HTTP Request (GET https://example.com)
│   ├── HTTP Request (POST https://example.com/login)
│   ├── Assertions (проверка кода ответа, текста)
│   └── Timers (задержки между действиями)
└── Listeners (отчёты: графики, таблицы, лог-файлы)
----

Визуально вы собираете такой сценарий как блок-схему в JMeter GUI, задавая параметры через формы



Почему мы не делаем акцент на JMeter в этом курсе?
Хотя JMeter по-прежнему встречается в крупных компаниях и старых системах, мы намеренно не делаем его основным инструментом. Он плохо подходит для гибкой автоматизации, плохо читается в виде кода, требует ручного конфигурирования и не вписывается в современные пайплайны.

Вместо этого мы сосредоточимся на инструментах нового поколения, которые легко использовать в CI/CD, удобно писать как код и масштабировать — например, Locust и k6.



3. k6

k6 — это современный и лёгкий инструмент для нагрузочного тестирования, ориентированный на автоматизацию, CI/CD и мониторинг. Сценарии пишутся на JavaScript (ES6), а основной упор сделан на тестирование HTTP и WebSocket API. Инструмент активно развивается и используется в DevOps-среде благодаря своей простоте, скорости и глубокой интеграции с системами мониторинга, особенно с Grafana и InfluxDB.



Основные характеристики:

- Язык сценариев: JavaScript (ES6)

- Подход: Сценарии пишутся как код — экспортируются функции default и setup

- Протоколы: HTTP, WebSocket, gRPC (через отдельные модули)

- Интерфейс: CLI + облачная платформа k6 Cloud (опционально)

- Масштабирование: Поддерживает распределённые запуски, интеграцию с Docker, Kubernetes

- Мониторинг: Встроенный экспорт метрик в Grafana, InfluxDB, Prometheus

- Установка: brew install k6 или скачать с официального сайта -
k6.io



Преимущества:

- Современный, удобный CLI-интерфейс

- Отлично вписывается в CI/CD пайплайны

- Гибкий экспорт метрик в системы мониторинга

- Поддержка k6 Cloud для визуального анализа и запуска из облака

- Быстро запускается, минимальные зависимости



Ограничения:

- Сценарии пишутся на JavaScript без строгой типизации, что делает код уязвимым к скрытым ошибкам: undefined, преобразование типов, ловушки null, непредсказуемые логические выражения — всё это может вызвать сбои в нагрузочном тесте, которые тяжело отловить

- Полноценной поддержки TypeScript нет — возможна только через сторонние сборки и конфигурации (xk6, webpack, esbuild), что усложняет разработку

- В отличие от Python в Locust, меньше гибкости при описании пользовательской логики, особенно при сложных сценариях и интеграциях

- Поддержка gRPC реализована, но через дополнительные модули и требует ручной настройки



Кому подойдёт: DevOps-инженерам, QA-специалистам и разработчикам, которые работают с CI/CD, используют Grafana и хотят быстро интегрировать нагрузочное тестирование в пайплайны. Особенно актуален, если команда уже использует JavaScript или хочет запускать тесты в облаке.

Важно! Несмотря на современный облик и интеграции, выбор JavaScript в чистом виде без типизации делает k6 рискованным инструментом для сложных сценариев, особенно при долгосрочной поддержке. При разработке на Python или в командах с высоким требованием к надёжности кода — Locust может быть предпочтительнее.



Пример простого сценария на k6:
--
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  vus: 50,            // Количество виртуальных пользователей
  duration: '30s',    // Продолжительность теста
};

export default function () {
  const res = http.get('https://test-api.k6.io');
  check(res, { 'статус 200': (r) => r.status === 200 });
  sleep(1);  // Пауза между запросами
----
В этом примере:
- Задаётся 50 VU на 30 секунд
- Пользователи делают GET-запрос к сайту
- Выполняется базовая проверка успешности ответа
- Используется sleep(1) для симуляции пользовательской паузы



4. Gatling

Gatling — это высокопроизводительный инструмент нагрузочного тестирования, ориентированный на разработчиков, особенно тех, кто работает со стеком Scala/Java. Он предлагает декларативный DSL для описания сценариев, хорошую масштабируемость и автоматическую генерацию HTML-отчётов. Gatling часто используют для нагрузки на HTTP API, особенно в проектах, где уже есть JVM-экосистема.

Официальный сайт - 
gatling.io 
+
github.com/gatling/gatling 



Основные характеристики:

- Язык сценариев: Scala (также возможны Kotlin и Java)

- Подход: Сценарии описываются как код с использованием Gatling DSL

- Протоколы: HTTP, WebSocket, JMS, MQTT, gRPC (ограничено)

- Интерфейс: CLI для запуска, HTML-отчёты для анализа

- Мониторинг: Автоматическая генерация подробных графиков (latency, throughput и др.)

- Установка: Через brew, sdkman, Docker или скачивание с gatling.io - https://gatling.io/



Преимущества:

- Очень высокая производительность — подходит для создания серьёзной нагрузки

- Эффективное использование ресурсов благодаря архитектуре на базе Netty

- Чёткие, подробные HTML-отчёты с графиками из коробки

- Хорошо интегрируется с CI/CD и инфраструктурой на базе JVM

- Подходит для стресс-тестирования и длительных soak-тестов



Ограничения:

- Требует знания Scala или Java — для многих команд это барьер

- Меньше гибкости и читаемости, если вы не знакомы с функциональным стилем Scala

- Не так распространён среди Python-сообщества и начинающих QA-инженеров

- Поддержка gRPC и нестандартных протоколов требует дополнительных настроек или расширений



Кому подойдёт: Разработчикам и DevOps-инженерам, работающим в JVM-экосистеме (Java, Scala, Kotlin), которым нужна высокая производительность, строгая структура сценариев и встроенная визуализация результатов. Особенно актуален в крупных продакшн-проектах, где важна скорость генерации нагрузки.

Важно! Gatling — отличный выбор для команд, уже работающих на Scala/Java, или для ситуаций, где нужна максимальная производительность и отчётность, но может быть неудобным для Python- или JavaScript-ориентированных команд из-за высокой кривой обучения.

Пример простого сценария на Gatling (Scala DSL):
--
import io.gatling.core.Predef._
import io.gatling.http.Predef._
import scala.concurrent.duration._

class BasicSimulation extends Simulation {

  val httpProtocol = http
    .baseUrl("https://test-api.gatling.io")

  val scn = scenario("Простой сценарий")
    .exec(http("Загрузка главной страницы")
    .get("/"))
    .pause(1)

  setUp(
    scn.inject(atOnceUsers(50))
  ).protocols(httpProtocol)
}
----
В этом примере:
- Используется 50 виртуальных пользователей
- Каждый выполняет GET-запрос и делает паузу
- Все результаты автоматически попадают в HTML-отчёт после завершения



5. Artillery

Artillery — это лёгкий инструмент для нагрузочного тестирования, ориентированный на разработчиков JavaScript/Node.js. Он позволяет описывать сценарии в YAML-файлах с возможностью подключения кастомной логики на JavaScript. Особенно хорошо подходит для тестирования event-driven систем: WebSocket, Socket.IO, MQTT и REST API.

Официальный сайт - 
artillery.io


Основные характеристики:

- Язык сценариев: YAML + JavaScript (Node.js)

- Подход: Конфигурационные сценарии в YAML + логика на JS-функциях

- Протоколы: HTTP, WebSocket, Socket.IO, MQTT

- Интерфейс: CLI

- Мониторинг: JSON-отчёты, интеграция с Prometheus (через плагин)

- Установка: npm install -g artillery



Преимущества:

- Простая и декларативная структура сценариев на YAML

- Возможность добавлять JS-функции для логики, генерации данных и проверки ответов

- Поддержка event-driven протоколов, включая WebSocket и MQTT

- Быстро разворачивается, не требует сложной инфраструктуры

- Хорошо вписывается в проекты на Node.js



Ограничения:

- YAML плохо подходит для больших сценариев с ветвлениями и сложной логикой — сложно отлаживать, нет автокомплита и контроля типов

- JS-функции ограничены в возможностях по сравнению с полноценными Python-классами (как в Locust)

- Менее активное и зрелое сообщество по сравнению с Locust, JMeter или k6

- Интеграция с системами мониторинга требует ручной настройки и дополнительных плагинов



Кому подойдёт: Командам, уже работающим с Node.js, которым нужно протестировать HTTP/WebSocket/MQTT API без лишней сложности. Подходит для небольших или среднеразмерных нагрузок, особенно когда важна поддержка realtime-протоколов и простота конфигурации. 

Пример простого сценария на Artillery (HTTP + JS check):
--
scenario.yaml:
--
config:
  target: "https://test-api.example.com"
  phases:
    - duration: 30
      arrivalRate: 10
  processor: "./logic.js"
scenarios:
  - flow:
      - get:
          url: "/"
          capture:
            - json: "$.status"
              as: "status"
          afterResponse: "checkStatus"
----
+
--
logic.js:
--
module.exports = {
  checkStatus: function (req, res, context, ee, next) {
    if (res.statusCode !== 200) {
      console.error("Ошибка ответа:", res.statusCode);
    }
    return next();
  }
};
----
В этом примере:
- Сценарий задаёт нагрузку в 10 пользователей/секунду
- Каждый пользователь делает GET-запрос к /
- Ответ анализируется в JS-функции checkStatus

Artillery может быть удобен как лёгкий старт, особенно для тех, кто работает в JavaScript-экосистеме. Но при необходимости сложных сценариев, масштабирования или строгой валидации — лучше рассмотреть Locust или k6 как более мощные и расширяемые инструменты. 



Сравнительная таблица нагрузочных инструментов -

Locust:
Язык сценариев - Python
Подход - Код (классы Python)
Протоколы - Любые: HTTP, WS, gRPC и т.д.
Интерфейс - CLI + Web + HTML-отчёт
Мониторинг - Веб-панель, Prometheus
Производительность - Средняя/высокая
Гибкость логики - Очень высокая (Python)
Порог входа - Низкий
Подходит для CI/CD - Да
Основной недостаток - Меньше визуальных отчётов
Кому подойдёт - Python-командам 



JMeter:
Язык сценариев - GUI + XML/Groovy
Подход - Конфигурация (JMX)
Протоколы - HTTP, SOAP, JMS и др.
Интерфейс - GUI + CLI
Мониторинг - Плагины, Prometheus
Производительность - Средняя
Гибкость логики - Низкая (конфигурации)
Порог входа - Средний
Подходит для CI/CD - Ограниченно
Основной недостаток - Устаревший, громоздкий
Кому подойдёт - Корпоративным системам



k6:
Язык сценариев - JavaScript (ES6)
Подход - Код (JS-функции)
Протоколы - HTTP, WS, gRPC
Интерфейс - CLI
Мониторинг - InfluxDB, Grafana
Производительность - Высокая
Гибкость логики - Средняя (без типизации)
Порог входа - Средний (JS обязателен)
Подходит для CI/CD - Да (встроено)
Основной недостаток - JS без типизации
Кому подойдёт - DevOps, JS-командам



Gatling:
Язык сценариев - Scala / Java / Kotlin
Подход - Код (DSL на Scala)
Протоколы - HTTP, WS, JMS, MQTT
Интерфейс - CLI + HTML-отчёты
Мониторинг - HTML-отчёты
Производительность - Очень высокая
Гибкость логики - Высокая (DSL)
Порог входа - Высокий (Scala/Java)
Подходит для CI/CD - Да
Основной недостаток - Требует Scala/Java
Кому подойдёт - JVM-разработчикам



Artillery:
Язык сценариев - YAML + JavaScript (Node)
Подход - YAML + JS-функции
Протоколы - HTTP, WS, MQTT
Интерфейс - CLI
Мониторинг - JSON, Prometheus
Производительность - Средняя
Гибкость логики - Ограниченная
Порог входа - Низкий для простых задач
Подходит для CI/CD - Да
Основной недостаток - YAML + слабая отладка
Кому подойдёт - Node.js и простые кейсы



Инструмент нагрузочного тестирования — это лишь 5–10% от всего процесса. Он — как молоток: полезный, но бесполезен без плана, чертежей и строительных навыков. Настоящее нагрузочное тестирование включает гораздо больше:

- генерация и подготовка данных (сидинги),

- создание и использование API-клиентов,

- работа с моками и изоляцией окружений,

- настройка отчётности и аналитики,

- запуск тестов в CI/CD,

- управление инфраструктурой, логами, конфигурациями,
интерпретация результатов, выявление узких мест, подготовка отчётов для бизнеса и архитекторов.



Изучая инструмент (например, Locust или JMeter), вы не изучаете всё нагрузочное тестирование. Вы изучаете лишь его инструментальную часть.

В этом курсе мы пойдём значительно дальше: от простого знакомства с инструментом — к построению зрелого, технически обоснованного процесса производительного тестирования.



Клауд-решения сейчас появляются у многих: это тренд, и даже у Locust теперь есть облачная версия, хотя раньше этого не было.

Мы рассматриваем Locust как один из самых гибких и простых инструментов для нагрузочного тестирования. А если хочется действительно красивые графики и удобный просмотр отчётов - можно использовать load-testing-hub (https://github.com/Nikita-Filonov/load-testing-hub-panel), про который я упоминал ранее. Он легко интегрируется с Locust и полностью работает локально.



Задача инструмента - создать нагрузку с определенными сценариями по определенным параметрам, собирает метрики и предоставляет нам отчет



Сопутствующие инструменты: HTTP-клиенты, валидация и контроль версий -


Ссылки:

Работа с HTTP протоколом: 
    httpx - https://www.python-httpx.org/
    requests - https://requests.readthedocs.io/en/latest/


Работа с gRPC протоколом: 
    grpcio - https://grpc.io/docs/languages/python/quickstart/


Работа с данными:
    pydantic - https://docs.pydantic.dev/latest/
    dataclasses - https://docs.python.org/3/library/dataclasses.html
    TypedDict - https://peps.python.org/pep-0589/
    NamedTuple - https://docs.python.org/3/library/collections.html#collections.namedtuple


Система контроля версий:
    GitHub - https://github.com/
    GitLab - https://about.gitlab.com/
    Bitbucket - https://bitbucket.org/product/
    Gerrit - https://www.gerritcodereview.com/



Работа с HTTP протоколом: httpx против requests

Мы будем взаимодействовать с HTTP API. Для этого нам нужен надёжный и удобный HTTP-клиент.



Почему мы выбираем httpx:

- Поддержка синхронного и асинхронного режима. httpx позволяет писать как синхронный, так и async/await-код — это даёт гибкость и масштабируемость.

- Хорошая типизация (type hints). Поддержка type hints повышает читаемость, уменьшает количество ошибок и отлично работает с IDE и mypy.

- Удобный объект Client. С поддержкой base_url, connection pooling и переиспользуемыми настройками.

- Поддержка event hooks. Можно удобно перехватывать запросы и ответы — полезно для логирования, автоматической авторизации, сбора метрик и др.



Почему не requests:

- Нет поддержки async/await и не планируется

- Нет встроенной типизации — сложно отлаживать и поддерживать в больших проектах

- Нет нативного base_url и хуков на запрос/ответ

- Развитие идёт медленно, библиотека фактически заморожена



Почему не aiohttp:

- Только асинхронный — неудобно, если проект частично синхронный

- Основной сценарий — написание серверных приложений

- Не оптимален для нагрузочного тестирования и API-клиентов



В итоге:
httpx — это современный, гибкий и хорошо типизированный HTTP-клиент, который отлично подходит для задач нагрузочного тестирования, где важна читаемость, повторное использование и контроль над запросами. Именно его мы будем использовать в этом курсе.



Работа с gRPC протоколом: grpcio

Если вы пишете нагрузочные тесты для gRPC-сервисов — вам нужен gRPC-клиент для Python. И здесь выбора практически нет: стандартная и единственная зрелая библиотека — это grpcio.



Почему grpcio:

- Официальная реализация от Google

- Поддержка всех типов вызовов: unary, server/client/bidirectional streaming

- Совместимость с .proto-контрактами (через protoc или grpcio-tools)

- Гибкость — можно использовать с любыми клиентами, фреймворками и тестовыми сценариями



Есть ли альтернативы?

Теоретически — grpclib, betterproto, grpclite, но:

- grpclib — только для async-кода

- betterproto — нестабильный, требует своей генерации

- Остальные — не поддерживают все типы вызовов или не подходят для нагрузочного тестирования


В этом курсе мы используем grpcio — как проверенное, стабильное и полностью совместимое решение для работы с gRPC-протоколом в нагрузочных тестах.



Работа с данными: pydantic

В нагрузочном тестировании важно надёжно работать с данными. Нам нужно:

- Валидировать входные данные

- Преобразовывать JSON в объекты и обратно

- Работать с алиасами, датами, enum, вложенными структурами



Для этого мы используем Pydantic — стандарт де-факто для сериализации и валидации данных в Python.



Почему именно pydantic:

- Автоматическая валидация по типам. Ошибки в данных ловятся сразу при создании модели.

Простая сериализация. Методы .dict(), .json() позволяют легко передавать и логировать данные.

Поддержка алиасов, enum, вложенности. Удобно работать с API, где ключи не всегда совпадают с Python-именами.

Читаемый и декларативный стиль. Код с BaseModel читается как документация — особенно полезно в тестах и клиентах.



Альтернативы (и почему нет):

dataclass — только структура, без встроенной валидации и сериализации

TypedDict — статичная структура, нет поведения, валидации и методов

NamedTuple — неизменяемые, неудобны в работе с JSON и вложенностью

Обычные dict — легко ошибиться, нет проверок, трудно сопровождать



В итоге:
Pydantic — это надежный инструмент для описания и валидации данных в нагрузочном тестировании. Он упрощает разработку, делает код предсказуемым и лучше документированным. В этом курсе мы будем активно использовать pydantic для API-клиентов, генерации и валидации данных.



Система контроля версий
Всё, что вы пишете, должно быть под контролем версий.
Особенно если:
- В проекте участвует несколько автоматизаторов
- Требуется история изменений и откат
- Есть CI/CD и код-ревью

Мы используем Git — стандарт в индустрии.



Популярные платформы:

- GitHub — открытые проекты, отличная документация, удобные pull-requests и обсуждения

- GitLab — подходит для приватных репозиториев и встроенных CI/CD (часто используется в корпорациях)

- Bitbucket — менее популярен, но удобен для команд, использующих Atlassian (Jira, Confluence)

- Gerrit — используется в старых или специфических проектах, требует жёсткого контроля ревью



В этом курсе мы будем использовать GitHub — как самую доступную, гибкую и популярную платформу.



отправка запросов одинакова что в httpx что в requests, разница может быть и есть, но минимальная 

pydantic - это стандарт серилизации и валидации данных в python 



******************************************

3.1 Установка и настройка окружения Python



Установка Python

Ссылки:

- Список доступных версий Python -
https://www.python.org/downloads/

- Версия Python 3.12.6 – на момент написания курса это последняя стабильная версия. Рекомендуется скачивать именно ее -
https://www.python.org/downloads/release/python-3126/



В данном уроке мы поговорим об установке интерпретатора языка Python

Установка Python на Windows

1 - Скачивание установщика:
- Перейдите на официальный сайт Python: https://www.python.org/downloads/.
- На главной странице отобразится кнопка Download Python X.X.X (где X.X.X – последняя версия Python). Нажмите на нее, чтобы загрузить установочный файл.

2 - Запуск установщика:
- Откройте загруженный файл python-X.X.X.exe.
- В появившемся окне обязательно установите флажок "Add Python to PATH" внизу окна, чтобы Python автоматически добавился в переменные среды (это упростит запуск Python в командной строке).
- Нажмите Install Now для быстрой установки или Customize installation для выбора дополнительных параметров.

3 - Проверка установки:
- После завершения установки откройте командную строку: нажмите Win + R, введите cmd, и нажмите Enter.
- Введите команду:
--
python --version
----
- Если вы увидите версию Python (например, Python 3.X.X), установка прошла успешно.



Установка Python на Linux

На большинстве дистрибутивов Linux Python уже предустановлен, но возможно, потребуется его обновление или установка новой версии. Инструкции могут отличаться в зависимости от дистрибутива. 



Ubuntu / Debian - 
1 - Обновите список пакетов:
--
sudo apt update
----
2 - Установите Python 3 и pip (менеджер пакетов Python):
--
sudo apt install python3 python3-pip -y
----
3 - Проверка установки:
Введите команду:
--
python3 --version
----
- Если вы увидите версию Python, установка выполнена успешно.



CentOS / Fedora / RHEL
1 - Установка Python 3 (на примере CentOS 8):
Выполните следующую команду:
--
sudo dnf install python3
----
2 - Проверка установки:
Введите команду:
--
python3 --version
----



Установка Python из исходного кода (если нужна последняя версия)
1 - Установите зависимости для сборки:
--
sudo apt update
sudo apt install -y build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev curl
----
2 - Скачайте и установите Python:
--
curl -O https://www.python.org/ftp/python/X.X.X/Python-X.X.X.tgz
tar -xf Python-X.X.X.tgz
cd Python-X.X.X
./configure --enable-optimizations
make
sudo make altinstall
----
- Замените X.X.X на номер версии, которую хотите установить.



Установка Python на macOS
На macOS обычно установлена более старая версия Python. Для установки последней версии рекомендуется использовать Homebrew – пакетный менеджер для macOS.
1 - Установите Homebrew (если еще не установлен):
Откройте Terminal и введите следующую команду:
--
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
----
2 - Установите Python с помощью Homebrew:
--
brew install python
----
3 - Проверка установки:
Введите команду:
--
python3 --version
----
- Должна отобразиться версия Python.
4 - Обновление pip:
Убедитесь, что менеджер пакетов pip обновлен:
--
python3 -m pip install --upgrade pip
----



Проверка переменных окружения (все системы) -
Для запуска Python в терминале или командной строке необходимо убедиться, что путь до Python добавлен в переменные среды (PATH):
1 - Windows: Если выбрано Add Python to PATH при установке, путь будет добавлен автоматически.
2 - Linux и macOS: Обычно путь добавляется автоматически, но можно проверить его в файле .bashrc, .bash_profile, или .zshrc:
--
export PATH="/usr/local/bin/python3:$PATH"
----



автор рекомендует ставить версию python на одну ниже от текущей, допустим если сейчас последняя версия - 3.12, то ставить версию 3.11 



******************************************

3.2 Установка и настройка PyCharm



PyCharm: Что это и зачем он нужен?

PyCharm — это мощная интегрированная среда разработки (IDE) для Python, разработанная JetBrains. Она предлагает множество инструментов для написания, тестирования и отладки кода, что делает его особенно популярным среди разработчиков на Python. PyCharm поддерживает автозавершение кода, отладку, контроль версий и интеграцию с популярными инструментами, такими как Docker (https://www.docker.com/) и Kubernetes (https://kubernetes.io/).

Альтернативы: Среди популярных альтернатив PyCharm можно выделить -
- Visual Studio Code - https://code.visualstudio.com/
- Atom - https://atom-editor.cc/
- Sublime Text - https://www.sublimetext.com/
- Spyder - https://www.spyder-ide.org/

Они предоставляют похожие возможности, но могут различаться по интерфейсу, поддержке плагинов и производительности.



Инструкции по установке PyCharm

Ссылки:

- Установка PyCharm для Windows -
https://www.jetbrains.com/pycharm/download/?section=windows

- Установка PyCharm для macOS - 
https://www.jetbrains.com/pycharm/download/?section=mac

- Установка PyCharm для Linux -
https://www.jetbrains.com/pycharm/download/?section=linux



Существует две версии PyCharm:

- PyCharm Community Edition (бесплатная): предназначена для обучения и разработки с базовым функционалом.

- PyCharm Professional Edition (платная): поддерживает расширенные возможности для профессионалов, такие как работа с веб-фреймворками (Django, Flask), поддержка работы с базами данных, поддержка JavaScript и других языков, а также интеграция с Docker и другими инструментами.



Установка PyCharm Community Edition - 



1 - Windows
- Перейдите на сайт JetBrains (https://www.jetbrains.com/pycharm/download/)
- Выберите версию PyCharm Community Edition и загрузите установочный файл для Windows.
- Запустите установочный файл.
- Следуйте инструкциям установщика, при этом:
    - Укажите путь для установки.
    - Выберите дополнительные опции, такие как создание ярлыка на рабочем столе и добавление PyCharm в PATH.
- По завершении установки запустите PyCharm и завершите настройку, следуя подсказкам на экране.



2 - Linux
- Загрузите архив для Linux с официального сайта (https://www.jetbrains.com/pycharm/download/)
- Распакуйте архив:
--
tar -xzf pycharm-community-*.tar.gz -C /opt/
----
- Перейдите в директорию, где установлен PyCharm:
--
cd /opt/pycharm-community-*/
----
- Запустите PyCharm:
--
./bin/pycharm.sh
----
- Вы можете создать ярлык или добавить путь к запускаемому файлу, чтобы запускать PyCharm из меню приложений.



3 - macOS
- Скачайте установочный файл с сайта JetBrains (выберите версию PyCharm Community Edition) - 
https://www.jetbrains.com/pycharm/download/
- Откройте загруженный .dmg файл.
- Перетащите значок PyCharm в папку Applications.
- Откройте PyCharm через Finder или из Launchpad.



Создание проекта PyCharm

Чтобы создать первый проект в PyCharm, выполните следующие шаги:



1 - Откройте PyCharm: После запуска PyCharm вы окажетесь на начальном экране. Здесь можно создать новый проект или открыть существующий.



2 - Создание нового проекта:
    - Нажмите кнопку "New Project".
    - В появившемся окне настройте параметры проекта:
        - Location: выберите папку для проекта или оставьте путь по умолчанию. Название проекта должно быть performance-tests.
        - Python Interpreter: укажите интерпретатор Python, который будет использоваться в проекте. Можно выбрать существующий интерпретатор или установить новый, если он не настроен.



3 - Конфигурация интерпретатора:

Если у вас ещё нет интерпретатора Python, нажмите "Add Interpreter" и выберите:
- Virtual Environment: PyCharm создаст виртуальное окружение в папке проекта (рекомендуется для изоляции зависимостей).
- System Interpreter: если у вас установлен Python на системе, выберите его.
- Conda Environment: если используете Anaconda, укажите conda-окружение.



4 - Создание проекта:
- Нажмите "Create". PyCharm создаст проект и автоматически запустит его в основном окне.



5 - Первый файл:
- В панели проекта (справа) нажмите правой кнопкой на корневую папку проекта, выберите New > Python File, назовите файл, например main.py, и нажмите Enter.
- Откройте файл и напишите любой код, например:
--
print("Hello, PyCharm!")
----



6 - Запуск проекта:
- Чтобы запустить скрипт, правой кнопкой мыши кликните по файлу и выберите Run 'main'.
- Результаты выполнения появятся внизу в панели консоли.



запустить файл main.py можно через терминал -
--
python -m main 
---- 



******************************************

3.3 Установка и знакомство с Docker



Знакомство с Docker

и пройти бесплатный курс - 
https://karpov.courses/docker

-


























*********************************************************
*********************************************************
*********************************************************
*********************************************************
*********************************************************

Ссылки:

- Официальный сайт Docker -
https://www.docker.com/

- Вводный туториал по работе с Docker - 
https://www.docker.com/101-tutorial/



Docker — это платформа с открытым исходным кодом, которая позволяет создавать, запускать и управлять изолированными средами, называемыми контейнерами. Контейнеры позволяют упаковать приложение со всеми его зависимостями и запускать его в любой операционной системе, где установлен Docker.

Проще говоря: Docker — это способ «запаковать» приложение вместе со всем необходимым (код, библиотеки, окружение, зависимости), чтобы оно запускалось всегда одинаково в любом месте — на вашем компьютере, в облаке, на сервере.



В чём отличие от виртуальных машин? - 
Характеристика	    - Виртуальная машина (VM)	- Docker (контейнер)
Вес	                  Гигабайты             Сотни мегабайт или меньше
Время запуска	            Минуты	        Секунды
Изоляция	    Полная (собственная ОС)	Изоляция на уровне ОС (ядра)
Производительность  Ниже из-за гипервизора	Почти нативная
Использование ресурсов	    Больше	        Меньше
Развёртывание	            Сложнее	        Быстрее и проще



Как это работает?
Контейнер — это как лёгкая виртуальная машина, но без полноценной операционной системы внутри. Вместо этого, контейнер использует ядро хост-системы, но при этом имеет своё файловое окружение, библиотеки и зависимости.



Компоненты Docker:
- Образы (Images) — это шаблоны контейнеров. Как "снимок" приложения и окружения.
- Контейнеры (Containers) — запущенные экземпляры образов.
- Dockerfile — файл с инструкциями, как собрать образ.
- Docker Engine — основной движок, который управляет контейнерами.



Пример -
Допустим, вы разрабатываете FastAPI-приложение (Python), и оно требует:
- Python 3.11
- Pip-пакеты: FastAPI, SQLAlchemy
- PostgreSQL
- nginx

Вместо того чтобы устанавливать это всё на каждый компьютер вручную, вы пишете Dockerfile, в котором описываете:
--
FROM python:3.11
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "app.py"]
----

Затем запускаете:
--
docker build -t my-fastapi-app .
docker run -p 8000:8000 my-fastapi-app
----

И получаете изолированное приложение, которое можно отправить кому угодно — оно будет работать всегда одинаково.



Где используется Docker -
- Разработка ПО — настройка среды единожды, затем клонирование и запуск за секунды
- CI/CD — автотесты и сборки в однотипных контейнерах
- DevOps и администрирование — лёгкое масштабирование, деплой, мониторинг
- Нагрузочное тестирование — изоляция сервисов, симуляция стендов
- Образовательные курсы — создание преднастроенных окружений



Преимущества Docker -
- Изолированность: каждый контейнер работает независимо
- Повторяемость: приложение запускается одинаково на любой машине
- Быстрая разработка и тестирование: всё можно автоматизировать
- Лёгкость: контейнеры весят гораздо меньше, чем виртуалки
- Гибкость: можно запускать несколько версий одного сервиса параллельно
- Упрощённый деплой: образы можно отправить на сервер, в облако, CI/CD



Сценарии использования в нагрузочном тестировании -

Docker — идеальный инструмент для изоляции:
- Системы, которую нужно нагрузить (например, API-сервер)
- Генераторов нагрузки (Locust, k6 и др.)
- Баз данных (PostgreSQL, Redis, MongoDB)
- Мониторинга (Prometheus, Grafana)

Это особенно важно при создании тестовых стендов, которые должны:
- Быстро разворачиваться
- Не зависеть от окружения разработчика
- Легко масштабироваться



Команды Docker:



1 - Образы (Images)

- docker build
Создаёт Docker-образ из Dockerfile.
--
docker build -t my-image:latest .
----                  
-t — задаёт тег образа (имя:тег).
. — путь к папке с Dockerfile.

- docker pull
Скачивает образ из Docker Hub или другого реестра.
--
docker pull nginx:latest
----

- docker images
Показывает список локальных образов.
--
docker images
----

- docker rmi
Удаляет один или несколько образов.
--
docker rmi my-image:latest
----



2 - Контейнеры (Containers)

- docker run
Создаёт и запускает контейнер из образа.
--
docker run -d -p 8080:80 --name my-nginx nginx
----                  
-d — в фоновом режиме.
-p — пробрасывает порт (host:container).
--name — задаёт имя контейнера.

- docker ps 
Показывает список запущенных контейнеров.
--
docker ps
----
                  
- docker ps -a
Показывает все контейнеры, включая остановленные.
--
docker ps -a
----
                  
- docker stop
Останавливает запущенный контейнер.
--
docker stop my-nginx
----

- docker start
Запускает остановленный контейнер.
--
docker start my-nginx
----
                  
- docker restart
Перезапускает контейнер.
--
docker restart my-nginx
----
                  
- docker rm
Удаляет остановленный контейнер.
--
docker rm my-nginx
----

- docker exec
Выполняет команду внутри запущенного контейнера.
--
docker exec -it my-nginx bash
----                  
-it — интерактивный режим с tty.

- docker logs
Показывает логи контейнера.
--
docker logs my-nginx
----



3 - Тома (Volumes)

- docker volume create
Создаёт том для хранения данных.
--
docker volume create my-volume
----

- docker volume ls
Показывает список томов.
--
docker volume ls
----
                  
- docker volume inspect
Показывает подробную информацию о томе.
--
docker volume inspect my-volume
----
                  
- docker volume rm
Удаляет том.
--
docker volume rm my-volume
----



4 - Сети (Networks)

- docker network create
Создаёт пользовательскую сеть.
--
docker network create my-network
----
                  
- docker network ls
Список сетей.
--
docker network ls
----
                  
- docker network inspect
Информация о сети.
--
docker network inspect my-network
----
                  
- docker network connect
Подключает контейнер к сети.
--
docker network connect my-network my-container
----



5 - Служебные и отладочные команды

- docker inspect
Детальная информация об объекте (контейнере, образе, томе, сети).
--
docker inspect my-container
----
                  
- docker stats
Ресурсы, потребляемые контейнерами в реальном времени (CPU, RAM).
--
docker stats
----
                  
- docker top
Показывает процессы внутри контейнера.
--
docker top my-container
----
                  
- docker info
Общая информация о Docker Engine.
--
docker info
----



6 - Очистка системы

- docker system prune
Удаляет все неиспользуемые контейнеры, образы и сети.
--
docker system prune
----
                  
- docker image prune
Удаляет неиспользуемые образы.
--
docker image prune
----
                  
- docker container prune
Удаляет остановленные контейнеры.
--
docker container prune
----



Docker — ключевой инструмент современной разработки и тестирования. Он помогает вам не «настраивать» всё вручную, а собирать окружение как код, сохранять его, переносить и масштабировать. В курсе мы будем использовать Docker, чтобы запускать тестируемые сервисы, а также имитировать нагрузку в отдельных контейнерах с помощью Locust



Установка Docker

Скачать Docker Desktop - 
https://www.docker.com/products/docker-desktop/
- telegram - избранное - 26.09.2025 (10:21)


1 - Установка Docker на Windows

Шаг 1: Требования
- Windows 10 или 11 с Hyper-V (Pro/Enterprise) или Windows 10/11 Home с WSL2
- Включенная виртуализация в BIOS

Шаг 2: Установка Docker Desktop
- Перейдите на сайт: https://www.docker.com/products/docker-desktop
- Скачайте установщик для Windows
- Запустите установку и следуйте инструкциям:
    - Выберите опцию использовать WSL2 (если Windows Home)
    - Docker установит необходимые компоненты

Шаг 3: Убедитесь, что всё работает
- Откройте PowerShell или терминал:
--
docker --version docker run hello-world
----
- Если выводится сообщение об успешном запуске — всё установлено

Возможные проблемы
- Проверьте, что включен WSL2:
--
wsl --list --verbose
----
- Убедитесь, что установлены Ubuntu или другая дистрибуция через Microsoft Store

Зачем устанавливать WSL для Docker на Windows?
На Windows Docker не может нативно использовать Linux-контейнеры, так как ядро Windows отличается от Linux. Поэтому:
- Docker Desktop использует WSL 2 как виртуализированную среду Linux;
- Именно в ней запускаются образы Linux-контейнеров (а таких — подавляющее большинство).

Почему это важно:
- Без WSL 2 Docker не будет работать с Linux-контейнерами;
- WSL 2 обеспечивает более высокую производительность, чем старый Hyper-V режим;
- С WSL 2 можно напрямую использовать Linux-утилиты в Windows (например, bash, curl, apt и т.п.).

Устанавливается ли WSL автоматически с Docker Desktop?
Да, если вы ставите Docker Desktop с нуля — он:
- Проверит наличие WSL 2;
- Если WSL не установлен — предложит установить его;
- Также скачает Linux-дистрибутив (обычно Ubuntu).



Установка Docker на macOS

Шаг 1: Требования -
- macOS Monterey или новее (M1/M2/M3 и Intel поддерживаются)
- 4+ ГБ RAM, включённая виртуализация

Шаг 2: Установка Docker Desktop
- Перейдите на сайт: https://www.docker.com/products/docker-desktop
- Скачайте .dmg файл
- Откройте и перетащите Docker в папку Программы
- Запустите Docker и разрешите все системные запросы (в т.ч. права на сеть)

Шаг 3: Проверка установки
Откройте терминал:
--
docker --version docker run hello-world
----



Установка Docker на Linux:

1 - Ubuntu/Debian -
--
sudo apt update
sudo apt install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Добавление Docker GPG-ключа
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
    sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# Добавление репозитория
echo \
  "deb [arch=$(dpkg --print-architecture) \
   signed-by=/etc/apt/keyrings/docker.gpg] \
   https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) stable" | \
   sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Установка Docker Engine
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Проверка
sudo docker run hello-world

# (Опционально) Запуск без sudo
sudo usermod -aG docker $USER
newgrp docker
----

2 - CentOS/RHEL -
--
sudo yum install -y yum-utils
sudo yum-config-manager \
    --add-repo https://download.docker.com/linux/centos/docker-ce.repo

sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Запуск и автозапуск
sudo systemctl start docker
sudo systemctl enable docker

# Проверка
sudo docker run hello-world
----

3 - Arch Linux / Manjaro -
--
sudo pacman -Syu docker

# Запуск и автозапуск
sudo systemctl enable docker
sudo systemctl start docker

# Проверка
sudo docker run hello-world
----



Проверка установки на всех ОС
После установки Docker должен быть доступен из командной строки:
--
docker --version docker run hello-world
----
- Успешный запуск hello-world означает, что контейнерная платформа работает.

Рекомендации -
- Обновляйте Docker регулярно через интерфейс (на Windows/macOS) или apt/yum/pacman.
- Используйте команду 
docker info 
для диагностики окружения.

Теперь ваша система готова для запуска стендов, сценариев и тестов с использованием Docker. В курсе дальше мы будем использовать команды docker, docker-compose.

создадим докерфайл в корне нашего проекта и назовем его - Dockerfail - без точек и расширений 

как учебная цель - запустим внутри Docker наш main-скрипт - 
--
main.py
--
def print_hi(name):
    print(f"Hi, {name}")


if __name__ == '__main__':
    print_hi('PyCharm')
----

--
Dockerfail
--
FROM python:3.12
WORKDIR /app
COPY . .
CMD ["python", "main.py"]
----

через терминал запустим команду на сборку - 
--
docker build -t test-docker .
----

через терминал запустим контейнер -
--
docker run test-docker
----
Hi, PyCharm
------

теперь другому человеку можно скинуть этот Dockerfile, он у себя сбилдит образ (Image) и на основании него сможет создавать контейнеры, и изменять, настраивать и запускать их - для этого ему нужно выполнить только 2 команды (которые указаны тут выше) - build и run 

весь код содержится в образе и образ можно опубликовать для сторонних пользователей -
в Docker Desktop - Images - в строке справа нажать на три точки - Push to Docker Hub 

чтобы удалить - сначала нужно удалить все контейнеры, где используется образ, а потом уже можно удалить сам образ 

когда образы и контейнеры не нужны - лучше их удалять, чтобы не занимали память и ресурсы компьютера (сервера)



Практика: работа с Docker - 
В этом задании вы самостоятельно создадите Docker-образ, который будет содержать Python-интерпретатор, необходимые зависимости и скрипт docker_example.py. Такой образ можно запустить в любом окружении как изолированное приложение. Это поможет вам закрепить навыки работы с Docker и понять, как упаковываются скрипты вместе с зависимостями.

Цель задания -
- Научиться писать простой Dockerfile;
- Освоить базовые инструкции: FROM, WORKDIR, COPY, RUN, CMD;
- Понять, как упаковывать Python-программы в контейнеры вместе с зависимостями;
- Научиться собирать и запускать образы через CLI.



Шаги выполнения -
1 - В корне проекта performance-tests создайте файл docker_example.py
2 - В этом файле напишите скрипт, который использует стороннюю Python-библиотеку termcolor для вывода цветного текста:
--
docker_example.py
--
from termcolor import colored

print(colored("Привет из контейнера!", "green"))
----
3 - Далее создайте файл Dockerfile.example в той же директории.
4 - Ваша задача — самостоятельно реализовать содержимое Dockerfile так, чтобы при сборке образа и запуске контейнера скрипт отработал корректно.



Требования к Dockerfile.example - 
Ваша реализация Dockerfile должна соответствовать следующим требованиям:
- Используется образ с Python версии 3.11.
- Устанавливается рабочая директория /app внутри контейнера.
- Весь исходный код (включая docker_example.py) копируется в контейнер.
- Устанавливается библиотека termcolor (с помощью pip).
- Контейнер при запуске выполняет файл docker_example.py.

Как проверить?
После реализации Dockerfile выполните в терминале (из корня проекта):
--
docker build -f Dockerfile.example -t docker-example .
docker run docker-example
----                  
- Если всё сделано правильно, вы увидите сообщение в консоли:
Привет из контейнера!
                
Если ваш терминал не поддерживает цветовой вывод, сообщение всё равно должно отобразиться — это означает, что контейнер работает корректно. Цвет — необязательный визуальный эффект.

Формат сдачи задания
Отправьте код решения в следующем виде:
Dockerfile.example
// Тут ваша реализация Dockerfile

Критерии успешного выполнения задания -
1 - В корне проекта создан файл docker_example.py с указанным кодом
2 - Файл Dockerfile.example реализован и соответствует всем требованиям:
- используется базовый образ Python 3.11. Рекомендуется использовать официальный образ python:3.11 или python:3.11-slim. Не используйте alpine — установка зависимостей может потребовать дополнительных шагов.
- установлена рабочая директория /app
- исходный код скрипта скопирован внутрь контейнера
- выполнена установка библиотеки termcolor
- задана команда запуска скрипта
3 - Команды docker build и docker run выполняются без ошибок
4 - При запуске контейнера в консоль выводится фраза Привет из контейнера!

Мой ответ на задание - 
--
Dockerfile.example 
--
FROM python:3.11-slim
WORKDIR /app
RUN pip install termcolor
COPY . /app
CMD ["python", "docker_example.py"]
----



******************************************

3.4 Установка и знакомство с Docker Compose



Знакомство с Docker Compose

Ссылки:

- Официальная документация Docker Compose -
https://docs.docker.com/compose/

- Вводный туториал по работе с Docker Compose -
https://docs.docker.com/compose/gettingstarted/



Docker Compose — это инструмент, который позволяет описывать и запускать многоконтейнерные приложения в Docker с помощью одного конфигурационного файла -
docker-compose.yml

Когда вы работаете с современными приложениями, часто приходится запускать сразу несколько сервисов: например, веб-сервер, базу данных, очередь сообщений, Redis и т.д. Docker Compose автоматизирует это — запускает все эти компоненты одной командой.

Зачем нужен Docker Compose?
- Автоматизация запуска многоконтейнерной среды.
- Упрощение настройки окружения.
- Описание зависимостей в одном месте (docker-compose.yml).
- Возможность быстро разворачивать и останавливать инфраструктуру.
- Используется в CI/CD, тестировании, разработке.

Пример: из чего состоит проект - Допустим, у нас есть веб-приложение на Python (FastAPI) + PostgreSQL. Чтобы его запустить, нужны:
- Контейнер с FastAPI-приложением.
- Контейнер с PostgreSQL.
- Связь между ними.
- Настройки окружения.
С Docker Compose всё это описывается в одном файле — docker-compose.yml

Пример docker-compose.yml -
--
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgres://user:password@db:5432/appdb
    depends_on:
      - db

  db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: appdb
    volumes:
      - db_data:/var/lib/postgresql/data

volumes:
  db_data:
----



Что здесь происходит:

services - Определяет контейнеры (например, web, db)

build или image - Как собрать контейнер: build из Dockerfile или image из Docker Hub

ports - Пробрасывает порты

environment - Переменные окружения

depends_on - Указывает порядок запуска

volumes - Постоянное хранилище данных (например, для БД)



Команды Docker Compose -

docker compose up	
- Запустить все контейнеры

docker compose down
- Остановить и удалить контейнеры, сеть, тома

docker compose build	
- Сборка образов

docker compose ps	
- Показать состояние контейнеров

docker compose logs	
- Логи всех контейнеров

docker compose exec <service> bash	
- Зайти внутрь контейнера

docker compose restart	
- Перезапустить все сервисы



Примеры использования - 

1. Разработка
Вы можете локально запускать целую инфраструктуру (API + БД + Redis) одной командой:
--
docker compose up --build
----

2. Тестирование
- Тестовые базы данных
- Очереди сообщений (RabbitMQ, Kafka)
- Песочницы для e2e-тестов

3. CI/CD
Docker Compose используется в GitHub Actions, GitLab CI и других пайплайнах для поднятия временного окружения.

4. Нагрузочное тестирование
Сценарий: вы хотите протестировать нагрузку на систему. С помощью Compose можно быстро поднять нужные сервисы (бэкенд, БД, Locust master/worker) и запустить тест.



Сетевые настройки
- Все сервисы внутри docker compose находятся в одной виртуальной сети.
- Вы можете обращаться к другим контейнерам по имени сервиса:
Пример: контейнер web может подключаться к db по адресу db:5432



Версии Docker Compose -
2.x - Устаревшая, но широко используемая
3.x - Совместима с Docker Swarm
3.8 - Рекомендуемая для большинства приложений
v2 - Современная CLI-реализация (docker compose, а не docker-compose)



Плюсы Docker Compose - 
- Простота в использовании
- Идеален для тестирования
- Легко портировать (один файл можно использовать в любой среде)
- Стандартизирует инфраструктуру
- Используется в проде (в малых и средних системах)
- Отличный выбор для обучения



Минусы -
- Не предназначен для масштабирования (лучше использовать Kubernetes)
- Подходит только для одной хост-машины
- Невозможно тонко настраивать отказоустойчивость и балансировку



Docker Compose — мощный инструмент для локальной разработки, тестирования и автоматизации. Он позволяет легко управлять инфраструктурой, упрощает запуск сложных конфигураций и делает проекты предсказуемыми и переносимыми. Если вы планируете запускать тестовые стенды, поднимать микросервисы, разрабатывать распределенные системы или проводить нагрузочное тестирование — Docker Compose вам обязательно пригодится.



Установка Docker Compose

Нужно ли устанавливать Docker Compose вручную?
Нет, в большинстве случаев устанавливать Docker Compose вручную не требуется.
Современные версии Docker (v20.10.13 и выше) уже включают Docker Compose как встроенный плагин. Начиная с Docker Desktop 2.0+ (Windows и macOS), docker compose идёт в комплекте. Вместо старой команды docker-compose теперь используется новая - docker compose (без дефиса)

Как проверить, установлен ли Docker Compose
Откройте терминал и выполните:
--
docker compose version
----                  
Если вы увидите версию, например:
Docker Compose version v2.24.2
               
Значит, всё работает, и устанавливать ничего не нужно.



Важно: старая vs. новая команда
Версия - Команда - Поддержка -
Новая - docker compose - Рекомендуется
Старая - docker-compose - Устаревшая, не развивается



Пример запуска контейнеров:
--
docker compose up
----



Состояние по операционным системам - 
ОС - Нужно ли устанавливать compose? - Как работает -
Windows	- Нет - Встроено в Docker Desktop
macOS - Нет - Встроено в Docker Desktop
Linux - Да, один пакет - sudo apt install docker-compose-plugin



Установка на Linux (если вдруг не установлен)
Если команда docker compose не работает — установите плагин:
--
sudo apt update
sudo apt install docker-compose-plugin
----              
Затем проверьте:
--
docker compose version
----



Нужно ли устанавливать docker-compose (через curl)? - Нет. Это устаревший подход. Старая утилита docker-compose больше не развивается и не рекомендуется к использованию. Используйте docker compose



Краткая проверка -
--
docker --version          # Проверка Docker
docker compose version    # Проверка Compose
----



Итого -
- Устанавливать Docker Compose отдельно не нужно, если у вас современная версия Docker.
- Используйте новую команду docker compose.
- Устаревшую docker-compose лучше больше не использовать.
- На Linux может потребоваться установить плагин: docker-compose-plugin.



установим Redis через терминал - 
--
pip install redis 
----



в папке нашего проекта создадим файл - 
--
docker_compose_basics.py
--
from redis import Redis 

cache = Redis(host = "redis", port=6379)
cache.incr("times", amount=1)
print(cache.get("times"))
----



создадим новый докерфайл - Dockerfile.redis - 
--
Dockerfile.redis
-- 
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install redis
CMD ["python", "docker_compose_basics.py"]
----


10-40
















