
*****************************************************************

Прямая ссылка на курс:
https://stepik.org/242935

https://stepik.org/course/242935/promo

https://stepik.org/course/242935/syllabus

В курс входят -
74 урока
50 часов 9 минут видео
640 тестов
44 интерактивные задачи



stepik - 16-07-2025
~ 6_250 р.



Не задавайте вопросы, которые можно легко найти в сети. Если что-то непонятно, постарайтесь сначала найти ответ самостоятельно. Если же неясно, с чего начать, обратитесь ко мне через урок Поддержка преподавателя и вопросы -
https://stepik.org/lesson/1677142/step/1



Если у вас возникают вопросы в процессе прохождения курса и вы не можете найти на них ответы, вы можете задать вопрос преподавателю в Telegram по адресу -
@sound_right
Преподаватель постарается ответить вам в течение трех рабочих дней



папка для GitHub на диске С -
load_testing_from_my_work



******************************************

1.1 Знакомимся

Нагрузочное тестирование — глубокая, системная дисциплина, которая требует понимания:
- ресурсов системы (CPU, RAM, IO),
- сетевых протоколов (HTTP/gRPC),
- устройства БД,
- очередей и кешей,
- архитектуры приложений (монолит vs микросервисы),
- работы со стендом, сидинга данных и CI/CD.

Это не просто «открыть браузер и нажать кнопку», как в UI-автотестах. Здесь каждый тест — это инженерная гипотеза, которая проверяет прочность всей системы под реальной нагрузкой.

Что будем изучать в курсе?
Прежде всего — у нас будет отдельный тестовый стенд, и это не просто CRUD API и база данных под ним. Вы будете работать с настоящей учебной банковской системой, построенной по принципам микросервисной архитектуры. В ней есть всё, что используется в современных production-системах:
- Kafka — для асинхронных очередей,
- S3-совместимое файловое хранилище (MinIO) — для работы с документами и вложениями,
- Redis — для кеширования,
- PostgreSQL — как основная реляционная БД,
- Поддержка двух протоколов: HTTP и gRPC.

Это максимально приближённый к боевым условиям стенд, а не «игрушка с /ping» в блокноте. Мы будем не просто «посылать запросы», а тестировать поведение сложной системы под реальной нагрузкой.

С первых шагов вы будете работать руками. Первые модули курса посвящены настройке окружения и изучению инфраструктуры, чтобы вы понимали:
- как устроен стенд,
- как взаимодействуют сервисы,
- какие метрики важны,
- какие системные ресурсы участвуют в нагрузке.

Вы освоите и будете использовать вживую:
- docker, docker-compose,
- PostgreSQL и утилиту pgAdmin,
- Kafka UI для работы с очередями,
- MinIO как облачное хранилище,
- Grafana для метрик и анализа,
- Postman для ручного взаимодействия с API,
и многое другое.

В этом курсе вы будете работать сразу с двумя протоколами — HTTP и gRPC. Когда мы пишем функциональные тесты, разница между ними может быть не столь заметна — формат запроса разный, но бизнес-логика одна и та же. А вот в нагрузочном тестировании отличия становятся принципиальными.
- gRPC работает поверх HTTP/2, использует бинарную сериализацию (protobuf) и куда эффективнее в плане скорости и сетевых затрат.
- HTTP проще, но медленнее — особенно при большом количестве пользователей и высокой конкуренции за ресурсы.

Моки: создаём собственные сервисы для нагрузки
В курсе мы не просто «попробуем», а создадим собственный мок-сервис с нуля — и сразу в двух вариантах: для HTTP и для gRPC. Зачем это нужно?
- Во-первых, моки — это важнейший инструмент в нагрузочном тестировании, особенно при проверке систем, где реальные зависимости либо нестабильны, либо ресурсоёмки.
- Во-вторых, вы научитесь отделять нагрузку на конкретный компонент от нагрузки на всю систему.
- В-третьих, эти навыки полезны не только в нагрузке, но и в интеграционном, изоляционном и контрактном тестировании.

Мы реализуем мок-сервис с использованием FastAPI и grpcio, и это даст вам в руки ещё один универсальный инструмент, который пригодится как QA-инженеру, так и performance-инженеру.

Нагрузочное тестирование без анализа метрик — это просто цифры. Поэтому мы научимся работать с Grafana — одним из самых мощных инструментов для визуализации и анализа системных метрик. Вы не просто будете «смотреть графики», а разбираться в происходящем под капотом:
- Какой сервис даёт пиковую нагрузку?
- Куда уходит CPU?
- Что расходует память?
- Где реальное узкое место?
- Почему RPS начал падать?

Мы самостоятельно настроим Grafana-дэшборд, чтобы вы могли анализировать нагрузку не вслепую, а как инженер-исследователь, принимающий решения на основе объективных данных.

Нагрузочное тестирование начинается не с кода и не с графика. Оно начинается с понимания бизнес-контекста. Мы научимся:
- не просто «влепить 1000 виртуальных пользователей»,
- а проанализировать реальные сценарии поведения пользователей,
- рассчитать нагрузочные пики, типичные RPS, время активной сессии,
- построить реалистичный профиль нагрузки, отражающий реальную работу системы в проде.

Locust — наш основной инструмент нагрузочного тестирования, и мы разберём его на атомы. Вы научитесь:
- запускать базовые сценарии,
- использовать TaskSet, SequentialTaskSet, веса, тайминги,
- интегрировать кастомные HTTP и gRPC клиенты,
собирать единую архитектуру фреймворка, подходящую под разные типы API и сценариев.

Итогом станет универсальный нагрузочный фреймворк, который вы сможете:
- развернуть с нуля в любом проекте,
- адаптировать под любую систему,
- аргументировать его архитектуру перед командой или на собеседовании.

Сидинг — это то, о чём не говорят в большинстве курсов. И очень зря. Система не живёт в вакууме. На проде она работает с миллионами уже существующих пользователей, аккаунтов, историй операций. А значит — и в нагрузочных тестах база должна быть реалистично наполнена. В курсе вы научитесь:
- писать сидинг-сценарии,
- подготавливать начальные данные: пользователей, счета, документы,
- сохранять эти данные в JSON-файлы и использовать повторно,
- восстанавливать состояние базы перед каждым прогоном.

Это один из самых критически важных шагов, потому что нагрузка на пустую систему даёт ложные результаты.

В курсе мы активно будем использовать настоящие инструменты, с которыми работают инженеры в реальных проектах:
- Git — для версионирования кода,
- Docker и Docker Compose — для поднятия микросервисного стенда,
- Postman — для ручной работы с HTTP и gRPC API,
- MinIO — как S3-совместимое файловое хранилище,
- PostgreSQL + pgAdmin — для работы с базой,
- Kafka UI — для мониторинга и отправки сообщений в очереди.

Вы не просто «увидите их», вы будете использовать их каждый день: запускать контейнеры, подключаться к брокеру, писать запросы, читать логи. Например, вы научитесь:
- отправлять gRPC-запросы через Postman,
- смотреть состояние Kafka-топиков,
- визуализировать структуру БД через pgAdmin.

Интеграция с CI/CD — автоматизация нагрузки

Нагрузочные тесты не должны жить «в локалке». Я покажу, как:
- интегрировать нагрузочное тестирование в CI/CD-процессы,
- настроить запуск тестов по кнопке,
- автоматически поднимать тестовый стенд с помощью Docker и Docker Compose.

Цель — добиться того, чтобы любой член команды мог:
- запустить нужный сценарий,
- получить метрики,
- увидеть результат в Grafana или отчёте.

Вы научитесь создавать гибкие, универсальные API-клиенты как для HTTP, так и для gRPC. Причём речь не о «заглушках для одного теста», а о полноценных клиентах, которые можно использовать в разных целях:
- в нагрузочном тестировании (как часть сценариев Locust),
- в сидинге — для генерации данных,
- в автоматизированных API-тестах, если вы захотите использовать тот же клиент за пределами курса.

Клиенты будут построены по принципу модульности и переиспользуемости: их легко масштабировать, адаптировать под другие проекты или команды. Это навык, который пригодится вам вне зависимости от вашей роли: QA, перформанс-инженер, automation, SDET — все работают с API, и грамотный API-клиент — это основа продуктивной работы.

В курсе мы также разберёмся в терминологии и видах тестирования производительности, потому что тут важно понимать нюансы. Часто можно услышать: «нагрузим систему до упора — будет нагрузочное тестирование». Но на самом деле — это упрощение, и часто приводит к неправильным выводам. Мы научимся отличать:
- нагрузочное тестирование (load testing) — чтобы понять, выдерживает ли система ожидаемую нагрузку;
- стресс-тестирование — когда мы проверяем, на сколько система способна выйти за пределы нормы;
- тестирование отказоустойчивости — когда эмулируются сбои, ошибки сервисов, падение компонентов;
- резилианс-тестирование — способность восстанавливаться после сбоев без потери данных и целостности;



******************************************

1.2 Советы по изучению материала

урок состоит из - 
- видео 
- теория 
- тесты 
- практическое задание 

смотреть сначала текст (+ схемы, ссылки и т.п.) а потом видео 

делать самому всё что автор делает в видео 

смотреть все ссылки и рекомендации, которые дает автор 



Изучение Python -

Этот курс предполагает базовые знания Python. Если вы не уверены в следующих темах, рекомендую сначала их повторить:

Переменные -
https://www.w3schools.com/python/python_variables.asp

Типы данных -
https://www.w3schools.com/python/python_datatypes.asp

Функции -
https://www.w3schools.com/python/python_functions.asp

Логические операторы -
https://www.w3schools.com/python/python_conditions.asp

Циклы -
https://www.w3schools.com/python/python_for_loops.asp

Lambda-функции -
https://www.w3schools.com/python/python_lambda.asp

Классы -
https://www.w3schools.com/python/python_classes.asp

Знакомство с пакетным менеджером pip -
https://www.w3schools.com/python/python_pip.asp

Работа со строками и форматирование строк -
https://www.w3schools.com/python/python_string_formatting.asp



Для закрепления основ Python, рекомендую следующие бесплатные курсы, которые можно пройти за одну-две недели:

Бесплатный курс по Python от W3Schools -
https://www.w3schools.com/python/default.asp

Бесплатный курс по Python от Metanit -
https://metanit.com/python/tutorial/

Эти ресурсы помогут вам уверенно работать с нагрузочным тестами.



******************************************

1.3 Инструкции по отправке заданий на проверку

Инструкция по отправке на проверку -
1 - Выполните задание и опубликуйте результат на GitHub.

- Решение задания должно быть зафиксировано в одном коммите, если это возможно.
- Название коммита должно соответствовать следующему шаблону: {название урока}. {название шага}. Например, для задания ниже коммит должен быть назван так: 
"Введение в HTTPX. Практическое задание: работа с HTTPX"

- Если задание не получилось выполнить в одном коммите, это не критично. В этом случае просто добавьте еще один коммит с тем же названием, чтобы сохранить логическую структуру.

2 - Вставьте ссылку на GitHub репозиторий в поле ответа:
https://github.com/Nikita-Filonov/performance-tests

3 - Вы получите баллы за задание после его рецензирования

Важно! Если сейчас вам непонятны термины "репозиторий", "коммит" и структура GitHub, не беспокойтесь. Вы сможете пропустить данный шаг и вернуться к нему позже, после изучения основ работы с Git в уроке Начало работы с Git -
https://stepik.org/lesson/1799578/step/1?unit=1825311

- Обратите внимание, что задание не будет принято к оценке, если оно не соответствует указанному формату
- Отправить решение на рецензию можно только один раз!



Текстовый ответ -

Инструкция по отправке на проверку

1 - Составьте текстовый ответ:
- Напишите подробный ответ, следуя требованиям задания.
- Убедитесь, что ваш ответ содержит все необходимые шаги и пояснения.

2 - Вставьте решение в поле ответа

3 - Вы получите баллы за задание после его рецензирования



проверять ответы на задания, если ошибся - создать коммит с таким же названием 



******************************************

1.4 Поддержка от преподавателя и вопросы

Задавать вопросы рекомендуется в следующих ситуациях:
- Если при выполнении практического задания возникли трудности с пониманием условий и вы не уверены, как его выполнить.
- Если при изучении материала курса вы столкнулись с проблемой, которую не удается решить самостоятельно.
- Если вам непонятен процесс отправки домашнего задания на проверку.
- Если вы наткнулись на тему, в которой хотите разобраться глубже, и хотите получить дополнительные материалы для изучения.
- В любых других ситуациях, когда вам не удалось самостоятельно найти ответ, и вы исчерпали доступные ресурсы.



******************************************

2.1 Виды тестирования производительности

Виды тестирования производительности (Performance Testing)
Ссылки:

Performance Testing -
https://glossary.istqb.org/en_US/term/performance-testing
- Тип теста для определения эффективности работы компонента или системы.


Load Testing (нагрузочное тестирование) -
https://glossary.istqb.org/en_US/term/load-testing
- Тип тестирования производительности, проводимый для оценки поведения компонента или системы при различных нагрузках, обычно в интервале между ожидаемыми условиями низкой, типичной и пиковой нагрузки.
-
- что это - стандартная нагрузка, увеличенная в 2-3-5-6 раз 
- цель - нагрузить систему и собрать определенные метрики 
- когда проводится - после добавления новой функциональности или изменения старой (рефакторинга), либо перед каждым релизом и сравнивать метрики с предидущими релизами  


Stress Testing (стресс-тестирование) -
https://glossary.istqb.org/en_US/term/stress-testing
- Тип тестирования производительности, проводимый для оценки системы или компонента на пределе ожидаемых или указанных рабочих нагрузок или за их пределами, или при ограниченной доступности ресурсов, таких как доступ к памяти или серверам.
-
- что это - каждый раз повышаем нагрузку, пока система не откажет - 100-200-300-400-......
- цель - узнать максимальную нагрузку и увидеть какой компонент первым выходит из строя и как система будет восстанавливаться после сбоя, и вообще восстановится ли она 
- когда проводится - никогда не проводить на продакшине, только на тестовых стендах, проводится например при черной пятницей, акциями, когда ожидается большая пиковая нагрузка и нужно понять предел системы 


Soak Testing/Endurance Testing (тестирование выносливости) -
https://glossary.istqb.org/en_US/term/endurance-testing
- Тестирование для определения стабильности системы под значительной нагрузкой в течение значительного периода времени в контексте эксплуатации системы.
-
- что это - подаём ту же нагрузку что и обычно, но в течении нескольких часов или дней 
- цель - выявление утечек ресурсов либо накопительных эффектов - например есть система где кэшируются данные, и мы несколько часов или суток держим её под стандартной постоянной нагрузкой, и смотрим как ведут себя ресурсы, например каждый час по немногу возрастает нагрузка на память, то есть кэш не очищается и остается в памяти, и т.п. При обычном нагрузочном тестировании это может быть незаметно, а при долгом тестировании уже заметно 
- когда проводится - в системах которые долгое время работают под нагрузкой (банковские системы, телеком, чарты, биржи)


Spike Testing (тестирование всплесков) -
https://glossary.istqb.org/en_US/term/spike-testing
- Тестирование для определения способности системы восстанавливаться после внезапных скачков пиковых нагрузок и возвращаться в устойчивое состояние.
-
- что это - здесь нагрузка подаётся резким всплеском, например со 100 до 3000 
- цель - посмотреть как система переживает пик и как восстанавливается после этого, будет ли использоваться кэширование, будут ли увеличиваться ресурсы, масштабироваться система, либо вернутся ошибки, как при DDOS-атаке или когда клиент сразу отправляет очень много запросов на сервер 


Scalability Testing (тестирование масштабируемости) -
https://glossary.istqb.org/en_US/term/scalability-testing
- Тестирование для определения масштабируемости программного продукта.
-
- что это - подаем нагрузку и потихоньку её увеличиваем (тестируем вертикальное масштабирование(количество пользователей растет и соответственно растут потребляемые ресурсы) и горизонтальное масштабирование(растет количество инстансов, до 20-30 штук может расти (копий системы, контейнеров)))
- цель - снять метрики и посмотреть как система масштабируется (будет ли вообще масштабироваться) и что для нас выгоднее - рост ресурсов (вертикальное) или рост количества инстансов системы (горизонтальное) 
- когда проводится - когда поменяли инфраструктуру, настройки или переехали в облачное хранилище 


Failover / Resilience Testing (тестирование отказоустойчивости) -
-
- что это - подаём нагрузку, которая постоянно увеличивается, и смотрим как ведут себя компоненты системы на предмет отказоустойчивости, например есть сервис, который должен быть всегда доступен, сервер должен сам определить когда начинает давать сбой и включить механизм Circuit Breaker, при котором наша система начинает чуть медленее отвечать либо тротлить, то есть этот механизм защищает сервер от отказа (падения) при непомерной нагрузке  

Circuit Breaker распределяет - эти запросы в очередь, эти я замедляю, а эти я отклоняю 

Иногда мы сами можем отключить какой-то сервис, или иммитировать отказ БД, кэширования и посмотреть как себя ведет система, насколько наш сервис отказоустойчивый 


Chaos Testing (хаос-тестирование) -
-
- что это - подаем нагрузку на стенд и начинаем отключать или замедлять сервисы, уменьшать их ресурсы, не позволять им масштабироваться и т.д. 
- цель - Смотрим насколько система устойчивая и надежная. 


Circuit Breaker Design Pattern -
https://en.wikipedia.org/wiki/Circuit_breaker_design_pattern

Тестирование производительности (Performance Testing) включает в себя несколько подвидов, каждый из которых фокусируется на определённой характеристике системы: скорости отклика, устойчивости, масштабируемости и способности к восстановлению. Далее мы рассмотрим ключевые виды такого тестирования.



И ещё раз про то же самое -



1. Load Testing (нагрузочное тестирование)

Цель:
- Проверка, как система работает под нормальной и увеличенной ожидаемой нагрузкой в течение продолжительного времени.

Особенности:
- Эмулируется реалистичная пользовательская активность (например, 100–500 одновременных пользователей).
- Проверяются: производительность, стабильность, скорость отклика, throughput.
- Используется на этапе подготовки к реальному продакшену.

Типичные метрики:
- Время отклика (Response Time)
- Пропускная способность (Requests per Second, Throughput)
- Утилизация CPU / памяти / сети
- Количество ошибок

Когда использовать:
- Перед релизом или масштабированием
- Для выявления узких мест при ожидаемой нагрузке



2. Stress Testing (стресс-тестирование)

Цель:
Определить максимальную нагрузку, которую система может выдержать до деградации или сбоя. Проверяется поведение за пределами нормальных условий.

Особенности:
- Нагрузка постепенно или резко увеличивается выше проектной нормы.
- Цель — увидеть, когда и как "ломается" система, и как она восстанавливается после сбоя.
- Тестируется устойчивость и деградация, а не стабильная работа.

Нюансы:
- Может привести к серьёзным сбоям, поэтому не проводится в продакшене.
- Важно отслеживать, какие компоненты первыми выходят из строя.

Когда использовать:
- При оценке пределов масштабируемости
- При подготовке к резким пиковым нагрузкам (распродажи, маркетинговые кампании)



3. Soak Testing / Endurance Testing (тестирование выносливости)

Цель:
Проверить стабильность системы при продолжительной нагрузке (несколько часов или даже дней) с целью выявления утечек ресурсов и накопительных эффектов.

Особенности:
- Нагрузка может быть на уровне Load Testing, но важно время: часы, сутки.
- Ищутся памятные утечки, утечка соединений, ухудшение времени отклика со временем.
- Выявляются проблемы, которые не видны при коротком тестировании.

Когда использовать:
- В критических системах с длительной работой (банкинг, телеком)
- После обновлений, которые могут повлиять на сборку мусора, кеширование и пр.



4. Spike Testing (тестирование всплесков)

Цель:
Оценить реакцию системы на резкий, кратковременный всплеск нагрузки.

Особенности:
- В отличие от Stress Testing, нагрузка скачет внезапно и резко, а не нарастает.
- Имитируется ситуация, например, когда внезапно заходит 10 000 пользователей за 1 секунду.
- Проверяется, как система "переживает" пик и восстанавливается.

Когда использовать:
- Для оценки реакции на DDoS, флешмобы, баги в клиентском ПО
- Для тестирования автоскейлинга и кэширования



5. Scalability Testing (тестирование масштабируемости)

Цель:
Проверить, насколько хорошо система масштабируется при увеличении:
- числа пользователей,
- объёма данных,
- количества узлов и ресурсов (CPU, памяти и т.д.)

Особенности:
- Может проводиться как в вертикальном (увеличение ресурсов), так и в горизонтальном масштабе (добавление инстансов).
- Анализируется эффективность масштабирования: линейное, сублинейное или деградирующее.

Когда использовать:
- При выборе между горизонтальным и вертикальным масштабированием
- При тестировании облачных или распределённых архитектур



6. Failover / Resilience Testing (тестирование отказоустойчивости)

Цель:
Оценить, как система реагирует на сбой компонентов (сервисов, БД, сети, дисков), и способна ли она восстановиться.

Особенности:
- Имитируются реальные сбои: отключение узла, отказ БД, network partition, и т.д.
- Часто сочетается с Chaos Testing.
- Проверяются механизмы репликации, автоматического переключения, circuit breaker'ы и пр.

Когда использовать:
- При построении отказоустойчивых систем
- Для валидации резервирования и механизмов восстановления



Circuit Breaker

Circuit Breaker (в контексте распределённых систем и отказоустойчивости) — это паттерн устойчивости, который предотвращает повторяющиеся попытки обращения к зависимому (часто внешнему) компоненту, если он уже не отвечает или работает с ошибками. Другими словами это программный механизм, который временно блокирует вызовы к ресурсу (например, микросервису или базе данных), если обнаружено, что он находится в ошибочном или нестабильном состоянии. Это помогает избежать избыточной нагрузки на зависимость и позволяет системе восстанавливаться более эффективно.

Circuit Breaker имеет три состояния:

1 - Closed (закрыт):
- Всё работает нормально.
- Запросы проходят к целевому компоненту.
- При ошибках считает количество/частоту неудач.

2 - Open (открыт):
- Когда число неудач превышает порог — "перегорает".
- Запросы не отправляются, а сразу получают ошибку.
- Даёт целевому компоненту "время на восстановление".

3 - Half-Open (полуоткрыт):
- Через некоторое время позволяет отправить ограниченное количество пробных запросов.
- Если они успешны — возвращается в Closed.
- Если снова ошибка — возвращается в Open.

Зачем нужен:
- Защищает систему от каскадных сбоев.
- Улучшает восстанавливаемость и устойчивость.
- Избегает перегрузки зависимого сервиса в момент, когда он уже не работает.

Примеры применения:
- Между микросервисами, где один сервис зависит от другого.
- При работе с нестабильной внешней API.
- В связке с retry и fallback логикой.



7. Chaos Testing (хаос-тестирование)

Цель:
- Преднамеренно вносить хаос и неопределённость в систему, чтобы проверить её устойчивость и надёжность в условиях неожиданных сбоев.

Особенности:
- Выключение случайных сервисов, сетевых подключений, подмена данных.
- Нестабильность создаётся преднамеренно, часто в продакшене.
- Используется инструментами типа Chaos Monkey, Gremlin.

Нюансы:
- Требует зрелой инфраструктуры, мониторинга и автоматического восстановления.
- Очень мощный инструмент, но опасен без должного контроля.



Сводная таблица сравнения:

Вид теста         - Load Testing
Цель              - Проверить стабильность
Нагрузка          - В норме
Продолжительность - Средняя	
Пример метрик     - Время отклика, ошибки

Вид теста         - Stress Testing
Цель              - Найти пределы	
Нагрузка          - Сверх нормы
Продолжительность - Кратковременная
Пример метрик     - Точка отказа, деградация

Вид теста         - Soak Testing
Цель              - Найти утечки, дрейф
Нагрузка          - В норме	
Продолжительность - Долгая
Пример метрик     - Утечки памяти, рост latency

Вид теста         - Spike Testing	
Цель              - Проверить на всплески	
Нагрузка          - Резкие пики
Продолжительность - Кратковременная
Пример метрик     - Пиковое поведение, отклик

Вид теста         - Scalability Testing	
Цель              - Проверить масштабируемость	
Нагрузка          - Растущая
Продолжительность - Любая	
Пример метрик     - Throughput на ресурс

Вид теста         - Resilience Testing
Цель              - Проверить восстановление
Нагрузка          - Любая	
Продолжительность - По сценарию
Пример метрик     - Восстановление, ошибки

Вид теста         - Chaos Testing
Цель              - Проверить устойчивость к сбоям
Нагрузка          - Нестабильная
Продолжительность - Любая
Пример метрик     - Выживаемость, самовосстановление


Мы в рамках этого курса будем работать с Load Testing (нагрузочным тестированием) - время ответа, количество запросов в секунду, процессор, память, диск, сеть - то есть будем делать снятие всяких метрик 

Также в этом уроке мы разобрали все виды тестирования производительности 



******************************************

2.2 Системные ресурсы: CPU и память

Ссылки:

CPU -
https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80

RAM -
https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BF%D0%BE%D0%BC%D0%B8%D0%BD%D0%B0%D1%8E%D1%89%D0%B5%D0%B5_%D1%83%D1%81%D1%82%D1%80%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%BE_%D1%81_%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%BB%D1%8C%D0%BD%D1%8B%D0%BC_%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%BE%D0%BC

Любое нагрузочное тестирование в итоге сводится к вопросу: хватает ли системе ресурсов, чтобы справиться с текущей и будущей нагрузкой.

Два ключевых ресурса:
- CPU (центральный процессор) — обрабатывает инструкции, выполняет код, принимает сетевые соединения и т.д.
- Память (RAM) — хранит данные, к которым требуется быстрый доступ: объекты, кэши, соединения, промежуточные результаты.

Понимание их работы, поведения под нагрузкой и типичных "узких мест" помогает точно интерпретировать результаты тестов. Ошибки, заниженные или переоценённые ожидания от CPU и памяти могут:
- искажать результаты тестов,
- приводить к ложным выводам,
- вызывать непредсказуемое поведение в продакшене.



Процессор: CPU (Central Processing Unit)

Что такое CPU? CPU — мозг системы. Его задачи:
- Выполнение инструкций программ,
- Планирование потоков,
- Обработка сетевых соединений,
- Шифрование, сериализация, маршрутизация.

Масштаб нагрузки на CPU зависит от:
- количества одновременных пользователей,
- характера операций (IO-bound или CPU-bound),
- архитектуры приложения (однопоточное/многопоточное),
- языка программирования и рантайма.



Метрики CPU - 
(Метрика -- Описание) -

CPU Usage (%) -- Доля занятости процессора. Суммируется по всем ядрам.

Load Average (Linux) -- Количество процессов, ожидающих CPU. Сравнивается с числом ядер.

Context Switches -- Количество переключений между задачами. Много — признак проблем с многопоточностью.

CPU Steal (в виртуальных машинах) -- Сколько времени CPU "украдено" хостом (например, в облаке).



Примеры проблем с CPU -
(Симптом -- Возможная причина -- Как диагностировать)

CPU 100% -- Узкое место в алгоритме или сервисе -- top, htop, flamegraph

Высокий Load Avg > ядер -- Перегрузка, очереди -- uptime, w, vmstat

Неравномерная загрузка ядер -- Неоптимальное распараллеливание -- инструменты профилирования

Слишком много context switches -- Нестабильная многопоточность -- pidstat, perf



Что важно в нагрузочных тестах?
- Наращивая нагрузку (stress), определяем точку деградации CPU.
- В endurance тестах оцениваем устойчивость CPU к длительной нагрузке.
- При spike test'ах смотрим, как быстро CPU восстанавливается после всплеска.
- Анализируем: какое число пользователей/запросов система выдерживает до перегрузки CPU?
	

	
Оперативная память: RAM (Random Access Memory)
Что такое оперативная память? RAM используется для:
- хранения промежуточных данных (объекты, сессии, буферы),
- работы garbage collector'а (в языках с автоматическим управлением памятью),
- кэширования (например, баз данных, API-ответов),
- работы ОС (файловые кэши, очереди, сетевые буферы).



Метрики памяти -
(Метрика -- Описание) -

RSS (Resident Set Size) -- Сколько физической памяти использует процесс.

VSZ (Virtual Size) -- Виртуальный объём адресного пространства.

Heap / Non-Heap -- Память, выделенная для объектов / остальная служебная память.

Page Faults -- Обращения к диску при нехватке памяти.

GC Activity -- Количество и длительность сборок мусора.



Примеры проблем с памятью -
(Симптом -- Возможная причина -- Диагностика) -

Утечка памяти (leak) -- Объекты не освобождаются -- Профайлер, heap dump

Частые паузы GC -- Недостаток памяти, плохая настройка GC -- метрики GC, pause time

Рост latency со временем -- Кеши не сбрасываются, ресурсы накапливаются -- endurance test

OOM (Out Of Memory) -- Превышение лимитов памяти -- лог OOM Killer, мониторинг



Что важно в нагрузочных тестах -

- Soak/Endurance Testing позволяет найти медленные утечки, не видимые за 5 минут.

- Load Testing показывает объём памяти, необходимый при стабильной нагрузке.

- Stress Testing помогает проверить, как система ведёт себя при превышении лимитов.

- Resilience Testing проверяет, как приложение реагирует на OOM, падения GC и пр.



Инструменты мониторинга и анализа - 
(Инструмент	--- Назначение) -

top, htop, atop, dstat, vmstat	--- Общая загрузка ресурсов

pidstat, iostat, mpstat	--- Диагностика процессов

pmap, smem	--- Анализ памяти процессов

Prometheus + Grafana --- Визуализация метрик в реальном времени

valgrind, VisualVM, gperftools, Flamegraph --- Глубокий анализ и профилирование



Связь с видами нагрузочного тестирования -
(Вид тестирования -- CPU и память — ключевые аспекты) -

Load Testing -- Следим за стабильной утилизацией

Stress Testing -- Где "ломается" CPU или память

Soak Testing -- Проверка на утечки, усталость системы

Spike Testing -- Моментальная реакция ресурсов

Scalability Testing -- Как ресурсы реагируют на рост нагрузки

Resilience Testing -- Устойчивость к деградации и восстановление

Chaos Testing -- Проверка на сбои: OOM, CPU starvation и пр.



нагрузка на процессор измеряется в процентах 

одно ядро - это 100% 

соответственно если 5 ядер, то будет 500% всего в Grafana

нагрузка на память измеряется в гигабайтах, но нужно оценивать динамику загрузки оперативной памяти  

при анализе памяти учитывать что могут быть утечки, например не очищается кэш 

весь смысл работы и анализа с оперативной памятью сводится к тому, что нужно выявить утечки, так как оперативная память должна очищаться 

когда оперативная память кончается, она начинает делать свап, то есть перемещать часть данных из оперативной памяти на жесткий диск, но запись на жесткий диск достаточно долгая, то на несколько секунд всё подвисает 

в Grafana посмотреть объем свапа можно на графике - Memory Swap per Container

не путать понятия -
- оперативная память 
- HDD
- SSD 

нагрузочное тестирование без анализа системных ресурсов смысла не имеет 



******************************************

2.3 Метрики нагрузочного тестирования

Метрики можно условно разделить на несколько групп:
- Метрики производительности приложения (Response Time, RPS, ошибки)
- Метрики нагрузки (кол-во пользователей, concurrency, throughput)
- Метрики инфраструктуры (CPU, RAM, диски, сеть)
- Метрики распределения и статистики (percentiles, медиана и др.)



1. Основные метрики отклика

- Response Time (время отклика) -
Определение: время между отправкой запроса и получением полного ответа от сервера.

Варианты:
- Average Response Time – среднее время отклика (может быть искажено пиками).
- Min / Max Response Time – минимальное и максимальное время отклика.
- Median Response Time (P50) – время, за которое половина запросов завершилась (менее чувствительно к выбросам).
- Percentiles (P90, P95, P99) – процентиль — значение, ниже которого находится заданный процент всех измерений.

Пример:
- P95 = 1500 мс означает, что 95% запросов завершились быстрее, чем за 1,5 секунды.
- P99 важен в SLA, особенно для UI и API-интерфейсов.

Percentiles vs Average - Среднее значение может быть обманчивым: если 9 запросов по 100 мс и 1 запрос за 5 сек → среднее = 590 мс, но большинство пользователей имели отличный опыт.



2. Метрики нагрузки

RPS (Requests per Second) -
Определение: количество обрабатываемых запросов в секунду.

Важно для:
- оценки throughput (пропускной способности),
- тестирования серверной части под реальной нагрузкой.

Пример: если у API 100 RPS, а 95% запросов укладываются в 300 мс — это хороший показатель.



Throughput -
Близкий к RPS, но иногда трактуется шире: как объём данных, проходящих через систему в единицу времени (например, MB/s).

Concurrent Users (одновременные пользователи) -
Сколько виртуальных пользователей (VUs) одновременно активны в сценарии (например, делают запрос, ожидают ответа, или "зависают" в think time).



Virtual Users (VUs) -
Количество имитируемых пользователей в нагрузочном тесте. Может не совпадать с "активными" пользователями (не все делают запросы одновременно).

Важно! Если 100 VU делают по 1 запросу каждые 10 секунд → это лишь 10 RPS.

Latency vs Response Time
- Latency — задержка между отправкой запроса и первым байтом ответа.
- Response Time — полное время получения ответа.
- Иногда путаются, особенно в сетевых метриках.



3. Метрики ошибок


Error Rate -
Процент завершившихся с ошибкой запросов (например, 5xx, timeout, network error и т.д.)

Пример: если было 10000 запросов, а из них 50 неуспешных, error rate = 0.5%

HTTP status code distribution -
Полезно отслеживать, сколько 200, 4xx, 5xx и пр. Это помогает отличить клиентские ошибки от серверных проблем.

Timeouts / Connection Errors -
- Таймауты: запросы, которые превысили лимит времени.
- Connection Errors: проблемы при установке TCP/SSL соединения.

Failures per Second - запросы, которые завершились с ошибкой (штук в секунду)



4. Продвинутые метрики


Think Time / Pacing -
- Think Time - имитация "времени раздумий" пользователя между действиями (сколько думает один средний пользователь между запросами) - измеряется в секундах 
- Pacing — задержка между итерациями одного и того же VU.
- Позволяет избежать нереалистичной нагрузки.

Dropped Requests / Retries -
- Dropped — сервер сбрасывает соединение под нагрузкой.
- Retries — количество повторных запросов после неудачи.

CPU Time per Request -
Время CPU, затраченное на обработку одного запроса (можно оценивать через профилировщик или APM).



Сводная таблица: часто используемые метрики -
Метрика	-- Тип -- Комментарий

Response Time (avg)	-- Время -- Среднее время отклика

Response Time (P95, P99) -- Время -- Более точный показатель UX

RPS -- Нагрузка -- Кол-во запросов в секунду

VUs -- Нагрузка -- Сколько пользователей

Error Rate -- Ошибки -- % запросов с ошибкой

Min/Max Response Time -- Время -- Для выявления пиков

CPU / RAM Usage -- Системные ресурсы -- Инфраструктурная метрика

Throughput -- Нагрузка -- Пропускная способность

Timeout Count -- Ошибки -- Количество таймаутов

Connection Failures -- Ошибки -- Проблемы сети / API Gateway

Percentiles -- Статистика -- P50, P90, P95, P99

Latency -- Время -- Особенно важно в сетевых API



Пример интерпретации - Допустим, после запуска теста:
RPS = 200
P95 Response Time = 950 мс
P99 = 1800 мс
Error Rate = 0.7%
CPU = 90%
RAM = 65%

Интерпретация:
- Производительность в целом хорошая, но есть проблемы на пике (P99 высокое).
- CPU почти на пределе → возможный кандидат на масштабирование.
- Нужно разобраться с 0.7% ошибок: возможно, таймауты.



Извините, а скриншот графика с Percentiles (P90, P95, P99) из locust или используется стороннее приложение?
"Из коробки", кажется, в locust такого не видела.
-
Да, в locust такого нет. Данный скриншот взят из системы аналитики load-testing-hub, можно почитать подробнее тут https://habr.com/ru/articles/871154/



******************************************

2.4 Клиент-серверная архитектура

Ссылки - Клиент-серверная архитектура -
https://en.wikipedia.org/wiki/Client%E2%80%93server_model

Клиент-серверная архитектура — это модель, в которой взаимодействуют два типа компонентов: клиент и сервер. Она широко используется в разработке приложений, особенно тех, что требуют взаимодействия с удаленными системами, будь то веб-сервисы, базы данных, файлы или другие ресурсы.



Основные компоненты клиент-серверной архитектуры:

1 - Клиент: Это приложение или устройство, которое инициирует запросы. Клиент может быть веб-браузером, мобильным приложением, десктопной программой или другим компонентом, который взаимодействует с сервером для получения или отправки данных.

2 - Сервер: Это система, которая обрабатывает запросы от клиента и возвращает результаты. Сервер может быть программным или аппаратным обеспечением, которое выполняет операции, связанные с хранением данных, вычислениями, и обеспечивает доступ к различным ресурсам.



Взаимодействие между клиентом и сервером:

- Запрос: Клиент отправляет запрос на сервер, используя стандартный протокол, такой как HTTP, FTP, WebSocket и другие.

- Ответ: Сервер обрабатывает запрос, выполняет необходимые операции и отправляет клиенту результат (например, данные, статус, ошибку).

Пример: Когда вы заходите на веб-сайт, ваш браузер (клиент) отправляет запрос на веб-сервер, который возвращает веб-страницу, отображаемую на вашем экране.



Преимущества клиент-серверной архитектуры:

1 - Масштабируемость: Серверы могут быть настроены для обработки множества запросов от клиентов.

2 - Централизация: Вся логика и данные могут быть централизованы на сервере, что упрощает управление и безопасность.

3 - Безопасность: Сервер может быть настроен для проверки прав доступа и защиты данных.



Виды клиент-серверной архитектуры:

1 - Одноуровневая архитектура (1-tier architecture):
- Вся логика (клиент и сервер) находится в одном месте, обычно на одном устройстве или сервере.
- Пример: Простое приложение, где клиент и сервер совмещены (например, локальные программы).

2 - Двухуровневая архитектура (2-tier architecture):
- В этой модели есть два компонента: клиент и сервер.
- Пример: Веб-приложение с веб-сервером, который обрабатывает запросы от клиента (браузера).

3 - Многоуровневая архитектура (N-tier architecture):
- Это расширенная модель, в которой могут быть несколько слоев: например, клиент, веб-сервер, приложение и база данных.
- Пример: Большие веб-приложения, которые используют серверы приложений, базы данных и другие компоненты для обработки данных. 



Пример двухуровневой архитектуры (клиент-сервер):
- Клиент: Браузер, который отправляет HTTP-запросы на сервер.
- Сервер: Веб-сервер, который обрабатывает запросы и взаимодействует с базой данных.

Пример:
- Пользователь открывает браузер и вводит URL, например, https://example.com.
- Браузер отправляет HTTP GET-запрос на сервер, который находится по этому адресу.
- Сервер обрабатывает запрос, извлекает данные из базы данных или выполняет другую логику, а затем отправляет ответ обратно.
- Браузер получает HTML, CSS и JavaScript и отображает веб-страницу пользователю.



Примеры использования клиент-серверной архитектуры:

1 - Веб-приложения:
- Веб-браузер отправляет запросы на сервер, который обрабатывает их и возвращает результаты в виде веб-страниц (HTML, CSS, JS).
- Примеры: Gmail, Facebook, банковские приложения.

2 - Мобильные приложения:
- Мобильное приложение может работать как клиент, а сервер обрабатывает запросы и возвращает данные, которые отображаются на устройстве.
- Примеры: WhatsApp, Instagram, приложения для заказа еды.

3 - Игры:
- Онлайн-игры используют клиент-серверную архитектуру для отправки и получения данных о состоянии игры между клиентом (игроком) и сервером.
- Пример: Fortnite, World of Warcraft.



Клиент-серверная архитектура является основой для большинства современных приложений и сервисов. Она позволяет централизовать обработку данных на сервере, обеспечивать масштабируемость и безопасность, а также упрощает управление логикой приложения.

Этот подход играет важную роль в автоматизации тестирования, поскольку тесты могут быть направлены на проверку взаимодействия между клиентом и сервером, включая запросы и ответы, обработку ошибок и производительность.



протоколы для -

- web-приложение (браузер) - HTTP, HTTPS

- десктопное приложение и мобильное приложение - gRPS



******************************************

2.5 Монолитная архитектура

Ссылки:

Сравнение микросервисной и монолитной архитектур -
https://www.atlassian.com/ru/microservices/microservices-architecture/microservices-vs-monolith

В чем разница между монолитной архитектурой и архитектурой микросервисов? -
https://aws.amazon.com/ru/compare/the-difference-between-monolithic-and-microservices-architecture/



Монолитная архитектура — это архитектурный стиль, при котором всё приложение разрабатывается, разворачивается и масштабируется как единое целое.

В монолите все компоненты приложения — пользовательский интерфейс, бизнес-логика, доступ к данным и взаимодействие с внешними сервисами — находятся в одном исполняемом процессе.



Структура монолитного приложения -
Обычно монолитное приложение включает в себя следующие слои:

- Представление (UI Layer). Отвечает за взаимодействие с пользователем (например, HTML-страницы, REST API, графический интерфейс).

- Бизнес-логика (Business Logic Layer). Основные правила и логика обработки данных, расчетов, валидации и принятия решений.

- Доступ к данным (Data Access Layer). Работа с базами данных, кэшами, файлами и другими хранилищами.

- Интеграции (Integration Layer). Если монолит взаимодействует с внешними API или сервисами, этот слой обрабатывает вызовы.

Все эти слои разворачиваются как единый модуль, зачастую в одном контейнере или на одном сервере.



Примеры монолитных приложений -

- Приложения, написанные в Java EE / Spring Boot с использованием Tomcat или JBoss, где всё приложение — один .war или .jar файл.

- Приложения, написанные на Python и использующие Django фреймворк.

- Старые веб-приложения на PHP, где бизнес-логика, шаблоны и SQL-запросы находятся в одном проекте.

Примеры:
- WordPress
- CRM-системы типа 1С:Предприятие
- Внутренние ERP-программы крупных компаний до перехода к микросервисам



Преимущества монолитной архитектуры -

Преимущество -
Объяснение

Простота разработки	- 
Один проект, одна точка входа. Удобно начинать с монолита на ранних этапах.

Единый деплой -
Всё приложение деплоится как единый артефакт. Нет необходимости в настройке множества сервисов.

Проще отлаживать и тестировать -
Вся система в одном процессе, легче использовать отладчик, писать юнит-тесты.

Проще локальная разработка -
Нет необходимости поднимать множество сервисов или использовать Docker/Orchestrator.



Недостатки монолитной архитектуры -

Недостаток -
Объяснение

Плохая масштабируемость по частям -
Нельзя масштабировать только “узкие места” — масштабируется всё приложение.

Сложность изменений в больших системах -
Малейшее изменение требует пересборки и перезапуска всего приложения.

Сложности с командами -
Несколько команд, работающих над одним проектом, могут мешать друг другу.

Ограниченная гибкость технологий -
Все части должны использовать одну и ту же технологическую версию, библиотеку, стек.

Риск полного отказа -
Ошибка в одном месте может “уронить” всё приложение.



Когда выбирать монолит?
Монолитная архитектура подходит в следующих случаях:

- Вы создаёте MVP или первый прототип, который нужно быстро запустить.

- Команда небольшая, проще сосредоточиться на одной кодовой базе.

- Вы работаете в условиях ограниченного бюджета, и инфраструктура микросервисов избыточна.

- Приложение по определению не будет масштабироваться (например, внутренние инструменты).



Эволюция: от монолита к микросервисам
Монолитное приложение со временем может:
- “распухнуть” — превратиться в громоздкий и трудноизменяемый код;
- начать испытывать трудности с масштабированием;
- требовать разделения команд и внедрения микросервисной архитектуры.

Этот процесс называют модульным рефакторингом — вынос функциональности из монолита в отдельные сервисы.



Монолитная архитектура — это простая и эффективная модель для начальной разработки и небольших команд. Однако при росте нагрузки и сложности системы появляются ограничения, требующие перехода к более гибким архитектурам, таким как микросервисы или модульные монолиты.



******************************************

2.6 Микросервисная арихтекутра

Ссылки:

Микросервисная архитектура -
https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D0%BD%D0%B0%D1%8F_%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0

Микросервисная архитектура статья от atlassian -
https://www.atlassian.com/ru/microservices/microservices-architecture

Сравнение микросервисной и монолитной архитектур -
https://www.atlassian.com/ru/microservices/microservices-architecture/microservices-vs-monolith

В чем разница между монолитной архитектурой и архитектурой микросервисов? -
https://aws.amazon.com/ru/compare/the-difference-between-monolithic-and-microservices-architecture/



Микросервисная архитектура (microservice architecture) — это подход к проектированию программных систем как набора небольших, автономных сервисов, каждый из которых реализует отдельную бизнес-функцию, взаимодействуя с другими сервисами через лёгкие протоколы (обычно HTTP/REST, gRPC, AMQP и др.).

Каждый микросервис:
- Развивается и деплоится независимо
- Обладает собственной логикой и хранением данных
- Может быть написан на своём языке программирования



Основные характеристики микросервисов -

Характеристика -
Описание

Изоляция -
Каждый сервис — отдельный процесс. Ошибка одного сервиса не должна ломать всю систему.

Независимое масштабирование -
Можно масштабировать только “узкие” сервисы (в отличие от монолита).

Автономность разработки -
Команды могут независимо разрабатывать, тестировать и деплоить отдельные сервисы.

Свои данные -
Каждый микросервис владеет своей БД (или схемой в общей БД) — “Database per service”.

Коммуникация по сети -
Взаимодействие идёт через сетевые вызовы, обычно по API.

Обработка сбоев -
Часто применяются: Circuit Breaker, Retry, Timeout, Load Balancer.

DevOps и автоматизация -
Нужна зрелая CI/CD-инфраструктура, наблюдаемость, логирование.



Коммуникации между микросервисами -

- Синхронные: HTTP/REST, gRPC. Быстро, просто, но чувствительно к сбоям

- Асинхронные: через очереди сообщений (RabbitMQ, Kafka). Повышает устойчивость, снижает связанность



Преимущества микросервисной архитектуры -

- Масштабируемость. Горизонтальное масштабирование отдельных компонентов

- Независимость разработки. Меньше конфликтов между командами, проще CI/CD

- Гибкость технологий. Возможность использовать разные языки, базы, фреймворки

- Отказоустойчивость. Локализация проблем: сбой одного сервиса ≠ падение всей системы

- Лучшая поддержка DevOps/Cloud. Хорошо сочетается с Kubernetes, контейнерами, облаками



Недостатки и сложности -

Недостаток -
Почему это проблема

Сложность инфраструктуры -
Нужен сервис-меш (например, Istio), оркестратор (K8s), мониторинг

Сетевые накладные расходы -
Больше запросов по сети → latency, ошибки

Трудности отладки -
Сервис может "ломаться" в связке с другим

Согласованность данных -
Труднее обеспечить ACID и транзакции между сервисами

Сложное управление версиями -
Необходима контрактная совместимость API

DevOps-зрелость обязательна -
Нужны CI/CD, логирование, трассировка, автоматизация



Когда стоит использовать микросервисы? -

Подходят:
- Для крупных распределённых систем
- Когда есть несколько команд разработки
- Если бизнес-логика чётко делится на независимые домены
- При высоких требованиях к масштабируемости и доступности

Не рекомендуются:
- Для маленьких или средних проектов
- Если нет опыта в CI/CD, облаках и Kubernetes
- Когда проще использовать модульный монолит



Пример микросервиса - Банковская система -
- AccountService — управление счетами
- TransactionService — перевод средств
- ReportingService — отчёты
- FraudDetectionService — выявление подозрительной активности



Отличие от монолита -
Признак - Монолит - Микросервисы -

Масштабируемость - Только целиком - По частям

Разработка - Одним блоком - Независимыми командами

Развёртывание - Общее - Независимое

Надёжность - Уязвим к сбою одного модуля - Локализация проблем

Работа с данными - Единая БД - Базы у каждого сервиса

Производительность - Быстрее (внутренние вызовы) - Зависит от сети, требует кеширования

Тестирование - Проще - Сложнее, нужны контракты и трассировка



Связанные архитектурные шаблоны -

- API Gateway — единая точка входа, маршрутизация к микросервисам (грубо говоря - это прокси)

- Service Discovery — динамическое обнаружение сервисов

- Sidecar — вспомогательные контейнеры для логирования, трейсинга

- CQRS / Event Sourcing — раздельная обработка чтения и записи

- SAGA Pattern — распределённые транзакции



Микросервисы — это мощный, но не бесплатный архитектурный подход. Их внедрение требует зрелости как в инженерной культуре, так и в технической инфраструктуре. Для крупных систем это может дать огромные преимущества: гибкость, отказоустойчивость и масштабируемость. Но для небольших — избыточная сложность.



мы в этом курсе позже будем работать со стендом, где используется микросервисная архитектура

для каждого микросервиса - запускается отдельный процесс 

микросервисы можно масштабировать независимо друг от друга (точечно, то есть добавлять ресурсы только микросервису, которому они нужны, а не всему приложению, как в монолите)

каждый микросервис владеет своей БД (или схемой в общей БД) - "Database per service"

gRPS - самый быстрый синхронный протокол взаимосвязи между микросервисами 



******************************************

2.7 Инструменты нагрузочного тестирования

Введение: Зачем нужны инструменты нагрузочного тестирования

Когда приложение или сервис разрабатывается, важно не только убедиться в его корректной работе (функциональное тестирование), но и понять, как он будет вести себя под нагрузкой: сможет ли выдерживать большое количество пользователей, насколько быстро будет отвечать, не упадёт ли при высоком трафике. Именно для этого и применяется нагрузочное тестирование.



Тестирование производительности — это обобщающее понятие, включающее в себя несколько подвидов:

- Load Testing — проверка системы при ожидаемой нагрузке;

- Stress Testing — проверка пределов, когда нагрузка превышает норму;

- Spike Testing — оценка реакции на резкие всплески трафика;

- Soak Testing — длительное тестирование для выявления деградации;

- Scalability Testing — анализ способности масштабироваться при росте нагрузки.



Но возникает вопрос: Как сымитировать поведение сотен, тысяч или даже миллионов пользователей, чтобы проверить систему?



Решением являются специальные инструменты нагрузочного тестирования. Они позволяют:

- Имитировать запросы от пользователей (HTTP, WebSocket, gRPC и др.)

- Создавать настраиваемую нагрузку — например, 1000 пользователей в течение 10 минут

- Оценивать производительность — время ответа, количество ошибок, RPS, процентильные задержки и другие метрики

- Автоматизировать тесты и интегрировать их в CI/CD

- Настраивать сценарии поведения пользователей, включая сложные последовательности действий



Как работают эти инструменты - 

1 - Сценарий теста описывает поведение пользователей:
Например: 
"Открыть страницу → Войти → Получить список товаров → Добавить товар в корзину".

2 - Инструмент запускает множество виртуальных пользователей (VUs), которые параллельно и многократно выполняют этот сценарий.

3 - Запросы отправляются к серверу, как если бы это делали настоящие пользователи.

4 - Инструмент собирает метрики: время ответа, количество запросов в секунду (RPS), процент ошибок, поведение под пиковыми нагрузками.

5 - Результаты визуализируются в виде графиков или отчётов — это помогает принимать архитектурные и бизнес-решения.

Виртуальные пользователи (Virtual Users, VUs) — это программные сущности, имитирующие действия реальных пользователей. Каждый такой пользователь выполняет заданный сценарий, посылает запросы к серверу и участвует в генерации нагрузки.



Типовые цели использования инструментов:

- Проверить, сколько пользователей может выдержать система

- Найти узкие места в производительности (например, медленные запросы)

- Сравнить поведение разных версий (до и после оптимизации)

- Тестировать SLA (время ответа, стабильность, доступность)

- Подготовиться к реальным пиковым нагрузкам (Black Friday, акции, релизы)



Примеры использования на практике:

- Интернет-магазин проверяет, выдержит ли он 10 000 пользователей во время распродажи

- Банк тестирует обработку тысяч транзакций в минуту

- Мобильное приложение проверяет API при подключении 5000 одновременных клиентов

- Онлайн-игра моделирует игровую сессию с 3000 игроками на сервере



Нагрузочное тестирование — это обязательный этап для любого серьёзного продукта. А инструменты для нагрузочного тестирования — это основной способ смоделировать поведение пользователей, зафиксировать метрики и убедиться, что система будет работать быстро, стабильно и предсказуемо даже под высокими нагрузками.

В этом курсе мы сделаем акцент на open-source решениях, которые легко использовать локально, интегрировать в пайплайны и применять даже в небольших командах. Особое внимание уделим Locust — современному инструменту на Python, который легко осваивается и при этом подходит как для обучения, так и для промышленных нагрузочных сценариев.



Инструменты нагрузочного тестирования: подробный обзор и сравнение -



Locust: 

Официальный сайт -
https://locust.io/

Официальная документация -
https://docs.locust.io/en/stable/

Репозиторий -
https://github.com/locustio/locust



JMeter:

Официальный сайт -
https://jmeter.apache.org/

Официальная документация -
https://jmeter.apache.org/usermanual/index.html

Репозиторий -
https://github.com/apache/jmeter



K6:

Официальный сайт -
https://k6.io/

Официальная документация -
https://grafana.com/docs/k6/latest/

Репозиторий -
https://github.com/grafana/k6



Gatling:

Официальный сайт -
https://gatling.io/

Официальная документация -
https://docs.gatling.io/

Репозиторий -
https://github.com/gatling/gatling



Artillery:

Официальный сайт -
https://www.artillery.io/

Официальная документация -
https://www.artillery.io/docs

Репозиторий -
https://github.com/artilleryio/artillery



1. Locust

Locust — это современный инструмент нагрузочного тестирования с открытым исходным кодом, в котором сценарии описываются на чистом Python. Он отлично подходит для моделирования поведения пользователей с высокой степенью реалистичности и гибкости. Благодаря удобному API, простому запуску и поддержке популярных протоколов, Locust стал выбором многих команд разработки и тестирования.



Основные характеристики:

- Язык сценариев: Python

- Подход: Поведение пользователей описывается как Python-классы

- Протоколы: HTTP/HTTPS, WebSocket, gRPC (через сторонние расширения)

- Интерфейс: Web-интерфейс для управления нагрузкой + CLI для автоматизации

- Масштабирование: Поддержка master/worker модели (distributed mode)

- Мониторинг: Встроенная web-панель, интеграция с Prometheus и Grafana

- Установка: pip install locust



Преимущества:

- Написание тестов на чистом Python — просто, читаемо, удобно для разработчиков

- Поддержка реалистичного пользовательского поведения — задержки, веса, последовательности

- Лёгкая интеграция с любыми Python-библиотеками (requests, httpx, grpcio, pydantic и др.)

- Быстрый вход в инструмент — идеален для обучения и прототипирования

- Активное сообщество, расширения и хорошая документация



Ограничения:

- Меньше встроенных визуальных инструментов, чем у JMeter или k6

- Не предназначен для экстремально высоких нагрузок (млн+ RPS), но работает стабильно до сотен тысяч при правильной настройке



Кому подойдёт: Python-разработчикам, QA-инженерам, DevOps-специалистам, которым важна гибкость сценариев, хорошая читаемость и простая интеграция в пайплайны CI/CD.

Пример простого сценария на Locust:
--
from locust import HttpUser, task, between

class WebsiteUser(HttpUser):
    wait_time = between(1, 5)  # Пауза между действиями (в секундах)

    @task
    def load_homepage(self):
        self.client.get("/")

    @task
    def view_products(self):
        self.client.get("/products")

    @task
    def make_purchase(self):
        self.client.post("/purchase", json={"item_id": 42})
----
- В этом примере:

- Класс WebsiteUser описывает поведение виртуального пользователя.

- Методы, помеченные @task, представляют действия, которые он выполняет.

- self.client используется для отправки HTTP-запросов.

- wait_time задаёт паузу между действиями, моделируя поведение настоящего пользователя.



2. Apache JMeter

JMeter — один из самых известных инструментов для нагрузочного тестирования. Он предлагает визуальный интерфейс для создания сценариев без программирования и поддерживает широкий спектр протоколов, включая не только HTTP, но и FTP, SOAP, JDBC, JMS и другие. JMeter активно используется в корпоративной среде, особенно в крупных организациях, где важна поддержка legacy-систем.



Основные характеристики:

- Язык сценариев: GUI-инструмент (визуальная сборка) + JMX/XML-конфигурации (опционально Groovy)

- Подход: Сценарии собираются через графический интерфейс, можно сохранять и редактировать в виде конфигурационных файлов

- Протоколы: HTTP, JDBC, FTP, SOAP, JMS и др.

- Интерфейс: Графический интерфейс (GUI) + командная строка (CLI) для запуска без UI

- Масштабирование: Есть поддержка distributed mode, но настройка сложнее, чем в Locust

- Мониторинг: Через встроенные или сторонние плагины; возможен экспорт метрик в Prometheus, InfluxDB и др.

- Установка: Скачивание с сайта Apache JMeter -
https://jmeter.apache.org/



Преимущества:

- Богатая поддержка различных протоколов и конфигураций — удобно для нестандартных или legacy-сценариев

- Возможность создавать тесты без программирования — через визуальный интерфейс

- Часто используется в больших компаниях, хорошо известен в индустрии

- Поддержка широкого набора плагинов и расширений



Ограничения:

- Интерфейс довольно тяжёлый и устаревший, особенно при работе с большими сценариями

- Сценарии хранятся в JMX/XML, что делает их сложными для чтения, версионирования и code-review

- Ограниченная гибкость при описании логики поведения пользователей

- Не интегрируется нативно с Python — не лучший выбор для Python-ориентированных команд

- Хотя JMeter широко используется и часто встречается в учебных курсах, его архитектура и интерфейс устарели. Он был создан в начале 2000-х, и с тех пор принципы разработки и тестирования сильно изменились.

- Многие компании используют JMeter из-за исторических причин или внутреннего наследия (legacy). Legacy (наследие) — это устаревший код или инструменты, которые тяжело заменить, но продолжают использоваться.

- На практике это означает: JMeter не лучший выбор для новых проектов, особенно если вы работаете с Python, современными API, CI/CD и микросервисами. Есть более лёгкие, гибкие и удобные инструменты — такие как Locust, k6, Gatling, которые лучше отражают текущие подходы в нагрузочном тестировании.

Кому подойдёт: Тестировщикам и инженерам, работающим с широким спектром протоколов, корпоративными сервисами и legacy-системами. Особенно актуален, если требуется безкодовое создание тестов и поддержка старых технологий (SOAP, JMS и др.).



Пример сценария в JMeter (визуально) - 
Хотя JMeter — это в первую очередь GUI-инструмент, можно описать базовую структуру сценария:
--
Test Plan
├── Thread Group (например, 100 пользователей, 10 циклов)
│   ├── HTTP Request (GET https://example.com)
│   ├── HTTP Request (POST https://example.com/login)
│   ├── Assertions (проверка кода ответа, текста)
│   └── Timers (задержки между действиями)
└── Listeners (отчёты: графики, таблицы, лог-файлы)
----

Визуально вы собираете такой сценарий как блок-схему в JMeter GUI, задавая параметры через формы



Почему мы не делаем акцент на JMeter в этом курсе?
Хотя JMeter по-прежнему встречается в крупных компаниях и старых системах, мы намеренно не делаем его основным инструментом. Он плохо подходит для гибкой автоматизации, плохо читается в виде кода, требует ручного конфигурирования и не вписывается в современные пайплайны.

Вместо этого мы сосредоточимся на инструментах нового поколения, которые легко использовать в CI/CD, удобно писать как код и масштабировать — например, Locust и k6.



3. k6

k6 — это современный и лёгкий инструмент для нагрузочного тестирования, ориентированный на автоматизацию, CI/CD и мониторинг. Сценарии пишутся на JavaScript (ES6), а основной упор сделан на тестирование HTTP и WebSocket API. Инструмент активно развивается и используется в DevOps-среде благодаря своей простоте, скорости и глубокой интеграции с системами мониторинга, особенно с Grafana и InfluxDB.



Основные характеристики:

- Язык сценариев: JavaScript (ES6)

- Подход: Сценарии пишутся как код — экспортируются функции default и setup

- Протоколы: HTTP, WebSocket, gRPC (через отдельные модули)

- Интерфейс: CLI + облачная платформа k6 Cloud (опционально)

- Масштабирование: Поддерживает распределённые запуски, интеграцию с Docker, Kubernetes

- Мониторинг: Встроенный экспорт метрик в Grafana, InfluxDB, Prometheus

- Установка: brew install k6 или скачать с официального сайта



Преимущества:

- Современный, удобный CLI-интерфейс

- Отлично вписывается в CI/CD пайплайны

- Гибкий экспорт метрик в системы мониторинга

- Поддержка k6 Cloud для визуального анализа и запуска из облака

- Быстро запускается, минимальные зависимости



Ограничения:

- Сценарии пишутся на JavaScript без строгой типизации, что делает код уязвимым к скрытым ошибкам: undefined, преобразование типов, ловушки null, непредсказуемые логические выражения — всё это может вызвать сбои в нагрузочном тесте, которые тяжело отловить

- Полноценной поддержки TypeScript нет — возможна только через сторонние сборки и конфигурации (xk6, webpack, esbuild), что усложняет разработку

- В отличие от Python в Locust, меньше гибкости при описании пользовательской логики, особенно при сложных сценариях и интеграциях

- Поддержка gRPC реализована, но через дополнительные модули и требует ручной настройки



Кому подойдёт: DevOps-инженерам, QA-специалистам и разработчикам, которые работают с CI/CD, используют Grafana и хотят быстро интегрировать нагрузочное тестирование в пайплайны. Особенно актуален, если команда уже использует JavaScript или хочет запускать тесты в облаке.

Важно! Несмотря на современный облик и интеграции, выбор JavaScript в чистом виде без типизации делает k6 рискованным инструментом для сложных сценариев, особенно при долгосрочной поддержке. При разработке на Python или в командах с высоким требованием к надёжности кода — Locust может быть предпочтительнее.



Пример простого сценария на k6:
--
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  vus: 50,            // Количество виртуальных пользователей
  duration: '30s',    // Продолжительность теста
};

export default function () {
  const res = http.get('https://test-api.k6.io');
  check(res, { 'статус 200': (r) => r.status === 200 });
  sleep(1);  // Пауза между запросами
----
В этом примере:
- Задаётся 50 VU на 30 секунд
- Пользователи делают GET-запрос к сайту
- Выполняется базовая проверка успешности ответа
- Используется sleep(1) для симуляции пользовательской паузы



4. Gatling

Gatling — это высокопроизводительный инструмент нагрузочного тестирования, ориентированный на разработчиков, особенно тех, кто работает со стеком Scala/Java. Он предлагает декларативный DSL для описания сценариев, хорошую масштабируемость и автоматическую генерацию HTML-отчётов. Gatling часто используют для нагрузки на HTTP API, особенно в проектах, где уже есть JVM-экосистема.



Основные характеристики:

- Язык сценариев: Scala (также возможны Kotlin и Java)

- Подход: Сценарии описываются как код с использованием Gatling DSL

- Протоколы: HTTP, WebSocket, JMS, MQTT, gRPC (ограничено)

- Интерфейс: CLI для запуска, HTML-отчёты для анализа

- Мониторинг: Автоматическая генерация подробных графиков (latency, throughput и др.)

- Установка: Через brew, sdkman, Docker или скачивание с gatling.io - https://gatling.io/



Преимущества:

- Очень высокая производительность — подходит для создания серьёзной нагрузки

- Эффективное использование ресурсов благодаря архитектуре на базе Netty

- Чёткие, подробные HTML-отчёты с графиками из коробки

- Хорошо интегрируется с CI/CD и инфраструктурой на базе JVM

- Подходит для стресс-тестирования и длительных soak-тестов



Ограничения:

- Требует знания Scala или Java — для многих команд это барьер

- Меньше гибкости и читаемости, если вы не знакомы с функциональным стилем Scala

- Не так распространён среди Python-сообщества и начинающих QA-инженеров

- Поддержка gRPC и нестандартных протоколов требует дополнительных настроек или расширений



Кому подойдёт: Разработчикам и DevOps-инженерам, работающим в JVM-экосистеме (Java, Scala, Kotlin), которым нужна высокая производительность, строгая структура сценариев и встроенная визуализация результатов. Особенно актуален в крупных продакшн-проектах, где важна скорость генерации нагрузки.

Важно! Gatling — отличный выбор для команд, уже работающих на Scala/Java, или для ситуаций, где нужна максимальная производительность и отчётность, но может быть неудобным для Python- или JavaScript-ориентированных команд из-за высокой кривой обучения.

Пример простого сценария на Gatling (Scala DSL):
--
import io.gatling.core.Predef._
import io.gatling.http.Predef._
import scala.concurrent.duration._

class BasicSimulation extends Simulation {

  val httpProtocol = http
    .baseUrl("https://test-api.gatling.io")

  val scn = scenario("Простой сценарий")
    .exec(http("Загрузка главной страницы")
    .get("/"))
    .pause(1)

  setUp(
    scn.inject(atOnceUsers(50))
  ).protocols(httpProtocol)
}
----
В этом примере:
- Используется 50 виртуальных пользователей
- Каждый выполняет GET-запрос и делает паузу
- Все результаты автоматически попадают в HTML-отчёт после завершения



5. Artillery

Artillery — это лёгкий инструмент для нагрузочного тестирования, ориентированный на разработчиков JavaScript/Node.js. Он позволяет описывать сценарии в YAML-файлах с возможностью подключения кастомной логики на JavaScript. Особенно хорошо подходит для тестирования event-driven систем: WebSocket, Socket.IO, MQTT и REST API.



Основные характеристики:

- Язык сценариев: YAML + JavaScript (Node.js)

- Подход: Конфигурационные сценарии в YAML + логика на JS-функциях

- Протоколы: HTTP, WebSocket, Socket.IO, MQTT

- Интерфейс: CLI

- Мониторинг: JSON-отчёты, интеграция с Prometheus (через плагин)

- Установка: npm install -g artillery



Преимущества:

- Простая и декларативная структура сценариев на YAML

- Возможность добавлять JS-функции для логики, генерации данных и проверки ответов

- Поддержка event-driven протоколов, включая WebSocket и MQTT

- Быстро разворачивается, не требует сложной инфраструктуры

- Хорошо вписывается в проекты на Node.js



Ограничения:

- YAML плохо подходит для больших сценариев с ветвлениями и сложной логикой — сложно отлаживать, нет автокомплита и контроля типов

- JS-функции ограничены в возможностях по сравнению с полноценными Python-классами (как в Locust)

- Менее активное и зрелое сообщество по сравнению с Locust, JMeter или k6

- Интеграция с системами мониторинга требует ручной настройки и дополнительных плагинов



Кому подойдёт: Командам, уже работающим с Node.js, которым нужно протестировать HTTP/WebSocket/MQTT API без лишней сложности. Подходит для небольших или среднеразмерных нагрузок, особенно когда важна поддержка realtime-протоколов и простота конфигурации. 

Пример простого сценария на Artillery (HTTP + JS check):
--
scenario.yaml:
--
config:
  target: "https://test-api.example.com"
  phases:
    - duration: 30
      arrivalRate: 10
  processor: "./logic.js"
scenarios:
  - flow:
      - get:
          url: "/"
          capture:
            - json: "$.status"
              as: "status"
          afterResponse: "checkStatus"
----
+
--
logic.js:
--
module.exports = {
  checkStatus: function (req, res, context, ee, next) {
    if (res.statusCode !== 200) {
      console.error("Ошибка ответа:", res.statusCode);
    }
    return next();
  }
};
----
В этом примере:
- Сценарий задаёт нагрузку в 10 пользователей/секунду
- Каждый пользователь делает GET-запрос к /
- Ответ анализируется в JS-функции checkStatus

Artillery может быть удобен как лёгкий старт, особенно для тех, кто работает в JavaScript-экосистеме. Но при необходимости сложных сценариев, масштабирования или строгой валидации — лучше рассмотреть Locust или k6 как более мощные и расширяемые инструменты. 



Сравнительная таблица нагрузочных инструментов -

Locust:
Язык сценариев - Python
Подход - Код (классы Python)
Протоколы - Любые: HTTP, WS, gRPC и т.д.
Интерфейс - CLI + Web + HTML-отчёт
Мониторинг - Веб-панель, Prometheus
Производительность - Средняя/высокая
Гибкость логики - Очень высокая (Python)
Порог входа - Низкий
Подходит для CI/CD - Да
Основной недостаток - Меньше визуальных отчётов
Кому подойдёт - Python-командам 



JMeter:
Язык сценариев - 	GUI + XML/Groovy
Подход - Конфигурация (JMX)
Протоколы - HTTP, SOAP, JMS и др.
Интерфейс - GUI + CLI
Мониторинг - Плагины, Prometheus
Производительность - Средняя
Гибкость логики - Низкая (конфигурации)
Порог входа - Средний
Подходит для CI/CD - Ограниченно
Основной недостаток - Устаревший, громоздкий
Кому подойдёт - Корпоративным системам



k6:
Язык сценариев - JavaScript (ES6)
Подход - Код (JS-функции)
Протоколы - HTTP, WS, gRPC
Интерфейс - CLI
Мониторинг - InfluxDB, Grafana
Производительность - Высокая
Гибкость логики - Средняя (без типизации)
Порог входа - Средний (JS обязателен)
Подходит для CI/CD - Да (встроено)
Основной недостаток - JS без типизации
Кому подойдёт - DevOps, JS-командам



Gatling:
Язык сценариев - Scala / Java / Kotlin
Подход - Код (DSL на Scala)
Протоколы - HTTP, WS, JMS, MQTT
Интерфейс - CLI + HTML-отчёты
Мониторинг - HTML-отчёты
Производительность - Очень высокая
Гибкость логики - Высокая (DSL)
Порог входа - Высокий (Scala/Java)
Подходит для CI/CD - Да
Основной недостаток - Требует Scala/Java
Кому подойдёт - JVM-разработчикам



Artillery:
Язык сценариев - YAML + JavaScript (Node)
Подход - YAML + JS-функции
Протоколы - HTTP, WS, MQTT
Интерфейс - CLI
Мониторинг - JSON, Prometheus
Производительность - Средняя
Гибкость логики - Ограниченная
Порог входа - Низкий для простых задач
Подходит для CI/CD - Да
Основной недостаток - YAML + слабая отладка
Кому подойдёт - Node.js и простые кейсы



Инструмент нагрузочного тестирования — это лишь 5–10% от всего процесса. Он — как молоток: полезный, но бесполезен без плана, чертежей и строительных навыков. Настоящее нагрузочное тестирование включает гораздо больше:

- генерация и подготовка данных (сидинги),

- создание и использование API-клиентов,

- работа с моками и изоляцией окружений,

- настройка отчётности и аналитики,

- запуск тестов в CI/CD,

- управление инфраструктурой, логами, конфигурациями,
интерпретация результатов, выявление узких мест, подготовка отчётов для бизнеса и архитекторов.



Изучая инструмент (например, Locust или JMeter), вы не изучаете всё нагрузочное тестирование. Вы изучаете лишь его инструментальную часть.

В этом курсе мы пойдём значительно дальше: от простого знакомства с инструментом — к построению зрелого, технически обоснованного процесса производительного тестирования.



Клауд-решения сейчас появляются у многих: это тренд, и даже у Locust теперь есть облачная версия, хотя раньше этого не было.

Мы рассматриваем Locust как один из самых гибких и простых инструментов для нагрузочного тестирования. А если хочется действительно красивые графики и удобный просмотр отчётов - можно использовать load-testing-hub (https://github.com/Nikita-Filonov/load-testing-hub-panel), про который я упоминал ранее. Он легко интегрируется с Locust и полностью работает локально.



00-07-00











































































