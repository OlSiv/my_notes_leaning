
jupyter notebook

Анализ Данных на Python с Глебом Михайловым Мастер-Класс [udemy] [Gleb Mikhaylov]

https://bw10.skladchik.org/threads/analiz-dannyx-na-python-s-glebom-mixajlovym-master-klass-udemy-gleb-mikhaylov.319851/

Все материалы и код -
https://github.com/glebmikha/data-analysis-master-class 

*********************************************************

1 - 1 - Google Colab 

облачный сервис google для анализа данных, аналог jyputer notebook -
colab.research.google.com/notebooks/intro.ipynb 

установить jupyter notebook -
--
pip install jupyter
----

запустить jupyter notebook из командной строки -
--
jupyter notebook
----
- если браузер не открылся автоматически, в командной строке появится URL-адрес, по которому запущен сервер Jupyter. Нужно скопировать этот URL и вставить его в адресную строку браузера

запустить ячейку - SHIFT + ENTER 

python сейчас - это новый excel 

формат файлов ноутбука - ipynb

ноутбук автора по зависимости нахождения работы от количества откликов на hh.ru - 
colab.research.google.com/drive/1vFj-aOVR4sq1Ok2dzp2bCL7_IOwG-GMB

*********************************************************

1 - 2 - Python 

автор рекомендует все интерфейсы програм переключить на английский язык 

*********************************************************

1 - 3 - Pandas 

pandas - эта библиотека больше всего подходит для анализа данных, и библиотека numpy тоже может понадобиться

чтобы установить в notebook сторонюю библиотеку - 
--
! pip install imia_biblioteki
----

импорт библиотек - 
--
import pandas as pd 
import numpy as np
----

numpay и python учить не нужно, нужно хорошо уметь работать с pandas 

--
df = pd.DataFrame({'col1':[1, 2, 3], 'col2':[10, 20, 30]})
----

--
df
----
	col1	col2
0	1	10
1	2	20
2	3	30
------

--
df.mean()
----
col1     2.0
col2    20.0
dtype: float64
------

посмотреть все функции (методы и свойства объекта) для датафрейма (только для Google Colab) - 
--
df. 
----
или так - 
--
pd.DataFrame.
----

pandas это опенсорс, то есть можно смотреть исходный код -
github.com/pandas-dev/pandas 

*********************************************************

2 - 1 - Загрузка данных - Со своего компьютера - 

в Google Colab файлы можно загрузить через интерфейс, но лучше так не делать, это плохая практика 

csv - это формат данных, где данные разделены запятыми 

--
import pandas as pd 

df = pd.read_csv(r'C:\my_proj\analitika_gleb_mihaylov_files\german-credit.csv')

df
----

автор советует называть переменную с датафреймом df, а не длинными названиями, типа avtozapchasti_dataframe 
+
на стековерфлоу в ответах тоже будет df
+
если в одном ноутбуке будет несколько таблиц, вот тогда лучше дать им уже осмысленные имена 

в аналитике если у нас несколько таблиц, то мы объединяем их в одну большую и уже её анализируем, и эту таблицу лучше тоже называть df и с ней работать 

*********************************************************

2 - 2 - Загрузка данных - С Google Drive 

загрузить данные на Google-Диск и уже оттуда открыть их в Google Colab - нажать share и скопировать ссылку 

--
! gdown --id 1pmGSMI2LuvsiBaBG5v7N8xfPedZbF020
----

--
import pandas as pd 

df = pd.read_csv('https://drive.google.com/uc?id=1pmGSMI2LuvsiBaBG5v7N8xfPedZbF020')

df.head()
----

с первого раза ничего запоминать не нужно, это всё потом запомнится постепенно, и самому ничего писать не нужно, нужно всё копипастить 
+
инструкция как скачивать файл с Гугл-диска есть в github автора - 
https://github.com/glebmikha/data-analysis-master-class/blob/main/german_credit_analysis.ipynb

*********************************************************

2 - 3 - Загрузка данных - С Google Sheets - 

тоже понадобится ссылка из Share 

--
import pandas as pd 

url = 'https://docs.google.com/sp..............................'

url.split('/')   
# - посмотреть под каким номером идет id 

id = url.split('/')[5]   
# - так определить id в переменную 

id
# - проверить что в переменной id 

df = pd.read_csv(f'https://docs.google.com/spreadsheets/d/{id}/export?format=csv')

df.head()
----

*********************************************************

2 - 4 - Загрузка данных - Подключение Google Drive - 

примаунтить - это значит подключить 

в Google Colab - вверху слева под Files - значек с черной папкой и трехугольником - потом нажать кнопку Connect to ......

--
! ls '/content/drive/'
----
- тут /content/drive/ - это путь к папке, который можно получить кликнув на папку и нажав Copy 

--
df = pd.read_csv('/content/drive/file-credits.csv')

df.head()
----

файлы excel подгружаются аналогично - 
--
df = pd.read_excel('/content/drive/file-credits.xls')
----

*********************************************************

2 - 5 - Загрузка данных - С базы данных (Из базы данных) - 

--
import pandas as pd 

from sqlalchemy import create_engine 
con = create_engine('postgresql+psycopg2://vozdmin1:RSGY639756fhjsifn@dumbo.db.elephantsql.com:5432/vozdmin')
----
- где - 
- vozdmin1 - имя пользователя 
- RSGY639756fhjsifn - пароль 
- dumbo.db.elephantsql.com - адрес (тут может быть ip-адрес)
- 5432 - порт
- vozdmin - название базы данных 

залить файл (таблицу) в базу данных под именем ger_credit - 
--
df = pd.read_csv('/content/german-credit.csv')

df.to_sql('ger_credit', con, if_exists='replace', index=False  )
----
- тут -
- con - это переменная, созданная выше 
- if_exists='replace' - если уже существует, то перезаписать 
- index=False - не создавать автоматически столбец с индексами 

считать таблицу из базы данных - 
--
sql = '''select * from ger_credit t'''

df = pd.read_sql(sql, con)

df.head()
----

*********************************************************

3 - 1 - Предобработка - Про датасет German Credit Data - 

цель - найти связь между последней колонкой (1 - не вернул кредит, 0 - вернул кредит) и значениями в других колонках 

*********************************************************

3 - 1.1 - Предобработка - Kaggle - 

https://www.kaggle.com/datasets/uciml/german-credit

*********************************************************

3 - 2 - Предобработка - Kак удалять столбцы и как гуглить - 

--
import pandas as pd 
import numpy as np 






























